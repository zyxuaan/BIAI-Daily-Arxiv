---
layout: default
title: 2025-08-14 Arxiv论文摘要
---

# Arxiv论文总结报告

## 基本信息
- 生成时间: 2025-08-14 12:34:03
- 使用模型: gemini-2.5-flash
- 论文数量: 1 篇

---

## 论文总结

### [[E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras]](http://arxiv.org/abs/2508.09912v1)
<!-- 2025-08-13 -->
**📅 发布日期**: 2025-08-13

*   **👥 作者**: Chaoran Feng, Zhenyu Tang, Wangbo Yu, Yatian Pang, Yian Zhao, Jianbin Zhao, Li Yuan, Yonghong Tian
*   **🎯 研究目的**: 当前的新视角合成和4D重建技术主要依赖于RGB相机，但RGB相机存在固有的局限性，如对充足光照的依赖、易受运动模糊影响以及动态范围有限。事件相机因其低功耗、高时间分辨率和高动态范围等优势，为解决高速运动和低光照场景下的场景重建挑战提供了新的视角。本研究旨在利用事件相机的这些优势，提出一种全新的事件驱动方法，以实现从多视角事件流进行高保真动态重建和新视角合成，从而克服传统RGB相机在复杂动态环境下的不足。
*   **⭐ 主要发现**: 本文提出了E-4DGS，这是首个事件驱动的动态高斯泼溅（dynamic Gaussian Splatting）方法，专为从多视角事件流（尤其是在相机快速移动的情况下）进行新视角合成而设计。E-4DGS的核心创新包括：首先，引入了一种基于事件的初始化方案，以确保训练过程的稳定性；其次，提出了一种事件自适应切片泼溅（event-adaptive slicing splatting）技术，用于实现时间感知的精确重建。这些创新使得E-4DGS能够有效利用事件相机的高时间分辨率和高动态范围特性，在高速运动和低光照条件下实现比传统RGB方法更鲁棒和高保真的动态场景重建，对机器人、自动驾驶和虚拟现实等领域具有潜在的深远影响。

---

---

## 生成说明
- 本报告由AI模型自动生成，摘要内容仅供参考。
- 如有错误或遗漏，请以原始论文为准。
