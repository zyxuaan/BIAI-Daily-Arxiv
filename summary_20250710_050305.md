---
layout: default
title: 2025-07-10 Arxiv论文摘要
---

# Arxiv论文总结报告

## 基本信息
- 生成时间: 2025-07-10 13:12:43
- 使用模型: gemini-2.5-flash
- 论文数量: 147 篇

---

## 论文总结

### [EA: An Event Autoencoder for High-Speed Vision Sensing](http://arxiv.org/abs/2507.06459v1)
<!-- 2025-07-09 -->
**📅 发布日期**: 2025-07-09

* **👥 作者**: Riadul Islam, Joey Mulé, Dhandeep Challagundla, Shahmir Rizvi, Sean Carson
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking](http://arxiv.org/abs/2506.23783v1)
<!-- 2025-06-30 -->
**📅 发布日期**: 2025-06-30

* **👥 作者**: Shiao Wang, Ju Huang, Qingchuan Ma, Jinfeng Gao, Chunyi Xu, Xiao Wang, Lan Chen, Bo Jiang
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [An efficient neuromorphic approach for collision avoidance combining Stack-CNN with event cameras](http://arxiv.org/abs/2506.16436v1)
<!-- 2025-06-19 -->
**📅 发布日期**: 2025-06-19

* **👥 作者**: Antonio Giulio Coretti, Mattia Varile, Mario Edoardo Bertaina
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Sparse Convolutional Recurrent Learning for Efficient Event-based Neuromorphic Object Detection](http://arxiv.org/abs/2506.13440v1)
<!-- 2025-06-16 -->
**📅 发布日期**: 2025-06-16

* **👥 作者**: Shenqi Wang, Yingfu Xu, Amirreza Yousefzadeh, Sherif Eissa, Henk Corporaal, Federico Corradi, Guangzhi Tang
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach](http://arxiv.org/abs/2505.12903v1)
<!-- 2025-05-19 -->
**📅 发布日期**: 2025-05-19

* **👥 作者**: Shiao Wang, Xiao Wang, Liye Jin, Bo Jiang, Lin Zhu, Lan Chen, Yonghong Tian, Bin Luo
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Maximizing Asynchronicity in Event-based Neural Networks](http://arxiv.org/abs/2505.11165v1)
<!-- 2025-05-16 -->
**📅 发布日期**: 2025-05-16

* **👥 作者**: Haiqing Hao, Nikola Zubić, Weihua He, Zhipeng Sui, Davide Scaramuzza, Wenhui Wang
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Contactless Cardiac Pulse Monitoring Using Event Cameras](http://arxiv.org/abs/2505.09529v2)
<!-- 2025-05-14 -->
**📅 发布日期**: 2025-05-14

* **👥 作者**: Mohamed Moustafa, Joseph Lemley, Peter Corcoran
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [A Survey of 3D Reconstruction with Event Cameras](http://arxiv.org/abs/2505.08438v2)
<!-- 2025-05-13 -->
**📅 发布日期**: 2025-05-13

* **👥 作者**: Chuanzhi Xu, Haoxian Zhou, Langyi Chen, Haodong Chen, Ying Zhou, Vera Chung, Qiang Qu, Weidong Cai
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Hybrid Spiking Vision Transformer for Object Detection with Event Cameras](http://arxiv.org/abs/2505.07715v1)
<!-- 2025-05-12 -->
**📅 发布日期**: 2025-05-12

* **👥 作者**: Qi Xu, Jie Deng, Jiangrong Shen, Biwu Chen, Huajin Tang, Gang Pan
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Iterative Event-based Motion Segmentation by Variational Contrast Maximization](http://arxiv.org/abs/2504.18447v1)
<!-- 2025-04-25 -->
**📅 发布日期**: 2025-04-25

* **👥 作者**: Ryo Yamaki, Shintaro Shiba, Guillermo Gallego, Yoshimitsu Aoki
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Event-Based Eye Tracking. 2025 Event-based Vision Workshop](http://arxiv.org/abs/2504.18249v1)
<!-- 2025-04-25 -->
**📅 发布日期**: 2025-04-25

* **👥 作者**: Qinyu Chen, Chang Gao, Min Liu, Daniele Perrone, Yan Ru Pei, Zuowen Wang, Zhuo Zou, Shihang Tan, Tao Han, Guorui Lu, Zhen Xu, Junyuan Ding, Ziteng Wang, Zongwei Wu, Han Han, Yuliang Wu, Jinze Chen, Wei Zhai, Yang Cao, Zheng-jun Zha, Nuwan Bandara, Thivya Kandappu, Archan Misra, Xiaopeng Lin, Hongxiang Huang, Hongwei Ren, Bojun Cheng, Hoang M. Truong, Vinh-Thuan Ly, Huy G. Tran, Thuan-Phat Nguyen, Tram T. Doan
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [DERD-Net: Learning Depth from Event-based Ray Densities](http://arxiv.org/abs/2504.15863v1)
<!-- 2025-04-22 -->
**📅 发布日期**: 2025-04-22

* **👥 作者**: Diego de Oliveira Hitzges, Suman Ghosh, Guillermo Gallego
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Event2Vec: Processing neuromorphic events directly by representations in vector space](http://arxiv.org/abs/2504.15371v1)
<!-- 2025-04-21 -->
**📅 发布日期**: 2025-04-21

* **👥 作者**: Wei Fang, Priyadarshini Panda
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework](http://arxiv.org/abs/2504.12576v1)
<!-- 2025-04-17 -->
**📅 发布日期**: 2025-04-17

* **👥 作者**: Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Perturbed State Space Feature Encoders for Optical Flow with Event Cameras](http://arxiv.org/abs/2504.10669v1)
<!-- 2025-04-14 -->
**📅 发布日期**: 2025-04-14

* **👥 作者**: Gokul Raju Govinda Raju, Nikola Zubić, Marco Cannici, Davide Scaramuzza
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework](http://arxiv.org/abs/2504.10018v1)
<!-- 2025-04-14 -->
**📅 发布日期**: 2025-04-14

* **👥 作者**: Xiao Wang, Haiyang Wang, Shiao Wang, Qiang Chen, Jiandong Jin, Haoyu Song, Bo Jiang, Chenglong Li
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset](http://arxiv.org/abs/2504.05830v1)
<!-- 2025-04-08 -->
**📅 发布日期**: 2025-04-08

* **👥 作者**: Shiao Wang, Xiao Wang, Bo Jiang, Lin Zhu, Guoqi Li, Yaowei Wang, Yonghong Tian, Jin Tang
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [Simultaneous Motion And Noise Estimation with Event Cameras](http://arxiv.org/abs/2504.04029v1)
<!-- 2025-04-05 -->
**📅 发布日期**: 2025-04-05

* **👥 作者**: Shintaro Shiba, Yoshimitsu Aoki, Guillermo Gallego
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling](http://arxiv.org/abs/2504.02402v1)
<!-- 2025-04-03 -->
**📅 发布日期**: 2025-04-03

* **👥 作者**: Hao Yin, Shi Guo, Xu Jia, Xudong XU, Lu Zhang, Si Liu, Dong Wang, Huchuan Lu, Tianfan Xue
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [A Survey on Event-driven 3D Reconstruction: Development under Different Categories](http://arxiv.org/abs/2503.19753v3)
<!-- 2025-03-25 -->
**📅 发布日期**: 2025-03-25

* **👥 作者**: Chuanzhi Xu, Haoxian Zhou, Haodong Chen, Vera Chung, Qiang Qu
* **🎯 研究目的**: 由于API调用失败，无法生成详细的研究目的摘要。[摘要生成失败: 'parts']
* **⭐ 主要发现**: 由于API调用失败，无法生成详细的主要发现摘要。[摘要生成失败: 'parts']

---
### [[EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation]](http://arxiv.org/abs/2503.18552v2)
<!-- 2025-03-24 -->
**📅 发布日期**: 2025-03-24

*   **👥 作者**: Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu
*   **🎯 研究目的**: 传统的条件式人体动画通常依赖从视频数据中提取的基于姿态的运动线索来驱动静态参考图像的动画化。然而，这些视频衍生的线索常受限于低时间分辨率、运动模糊以及在挑战性光照条件下性能不可靠等问题。本研究旨在克服这些局限性，提出一种利用事件相机数据作为更鲁棒、更精确运动线索的新方法，以实现高质量的条件式人体图像动画生成。
*   **⭐ 主要发现**: 本文提出了EvAnimate，这是首个利用事件流作为鲁棒且精确运动线索的条件式人体图像动画方法。该方法通过将异步事件数据编码成专门的三通道表示，使其与基于扩散的生成模型完全兼容。与传统方法相比，EvAnimate能够提供更高的运动精度和时间分辨率，并且在运动模糊、低光照环境和曝光变化等挑战性条件下表现出更强的鲁棒性。这一创新为人体动画领域带来了新的范式，有望在虚拟现实、游戏和电影制作等领域产生深远影响。

---

### [[Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras]](http://arxiv.org/abs/2503.17262v1)
<!-- 2025-03-21 -->
**📅 发布日期**: 2025-03-21

*   **👥 作者**: Shuang Guo, Friedhelm Hamann, Guillermo Gallego
*   **🎯 研究目的**: 事件相机依赖运动来获取场景外观信息，这意味着运动和外观是同时被感知或不被感知的，并编码在输出事件流中。然而，以往的研究通常将光流（运动）和图像强度（外观）的恢复视为独立任务，这与事件相机的本质不符，并忽视了这两个任务之间固有的关联。本研究旨在开发一个无监督学习框架，能够同时估计光流和图像强度，从而更充分地利用事件相机数据的特性。
*   **⭐ 主要发现**: 本文提出了一个创新的无监督学习框架，通过单个网络联合估计光流和图像强度。研究从事件生成模型出发，首次推导出了一个基于事件的光度误差，该误差是光流和图像强度的函数，并将其与对比度最大化框架相结合，形成了一个全面的损失函数。实验结果表明，该方法能够有效地在无监督条件下同时恢复场景的运动和外观信息，为事件相机的数据处理提供了新的视角和更高效的解决方案，有望推动事件视觉在机器人导航、自动驾驶等领域的应用。

---

### [[Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition]](http://arxiv.org/abs/2503.17132v3)
<!-- 2025-03-21 -->
**📅 发布日期**: 2025-03-21

*   **👥 作者**: Siyuan Yang, Shilin Lu, Shizheng Wang, Meng Hwa Er, Zengwei Zheng, Alex C. Kot
*   **🎯 研究目的**: 本文旨在探索脉冲神经网络（SNNs）与事件相机在保护隐私的人体行为识别（HAR）方面的协同潜力。事件相机能够仅捕捉运动轮廓的独特特性，与SNNs处理时空数据的能力相结合，为基于事件的HAR提供了高度协同的兼容性。然而，SNNs在处理长期时间信息方面的能力有限，而这对于精确的HAR至关重要。本研究旨在通过引入新颖的框架来解决这一限制。
*   **⭐ 主要发现**: 本文引入了两种新颖的框架来解决SNNs处理长期时间信息的能力限制，从而提升基于事件的人体行为识别性能：时序分段SNN（TS-SNN）和3D卷积SNN（3D-SNN）。TS-SNN通过将动作划分为更短的片段来提取长期时间信息，而3D-SNN则利用3D卷积的优势。这些创新使得SNNs能够更有效地捕捉和利用事件流中的时空动态，显著提高了在隐私保护情境下的人体行为识别准确性，为事件视觉和神经形态计算在智能监控、人机交互等领域的应用开辟了新途径。

---

### [[ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and Spiking Neural Network]](http://arxiv.org/abs/2503.09985v2)
<!-- 2025-03-13 -->
**📅 发布日期**: 2025-03-13

*   **👥 作者**: Qiang Zhang, Jiahang Cao, Jingkai Sun, Yecheng Shao, Gang Han, Wen Zhao, Yijie Guo, Renjing Xu
*   **🎯 研究目的**: 近年来，四足机器人技术取得了显著进展，尤其是在通过强化学习实现的感知和运动控制方面，使其能够在复杂环境中执行复杂动作。然而，深度相机等视觉传感器面临局限性，如相对于关节控制的低操作频率和对光照的敏感性，这些都阻碍了其在户外部署。此外，传感器和控制系统中的深度神经网络增加了计算需求。本研究旨在通过引入脉冲神经网络（SNNs）和事件相机来解决这些问题，以实现具有挑战性的四足机器人跑酷任务。
*   **⭐ 主要发现**: 本文成功将生物启发的事件相机和脉冲神经网络（SNNs）应用于四足机器人跑酷任务，显著提升了机器人在复杂环境下的感知和运动控制能力。事件相机能够捕捉高动态视觉数据，对光照变化和运动模糊具有鲁棒性，而SNNs则能高效处理脉冲序列，模仿生物感知机制，大幅降低了计算需求。实验结果表明，该系统不仅克服了传统视觉传感器和深度神经网络的局限性，还使机器人能够执行此前难以实现的高难度跑酷动作，展示了神经形态计算在机器人领域，尤其是在动态、不可预测环境中的巨大潜力。

---

### [[Helios 2.0: A Robust, Ultra-Low Power Gesture Recognition System Optimised for Event-Sensor based Wearables]](http://arxiv.org/abs/2503.07825v1)
<!-- 2025-03-10 -->
**📅 发布日期**: 2025-03-10

*   **👥 作者**: Prarthana Bhattacharyya, Joshua Mitton, Ryan Page, Owen Morgan, Oliver Powell, Benjamin Menzies, Gabriel Homewood, Kemi Jacobs, Paolo Baesso, Taru Muhonen, Richard Vigars, Louis Berridge
*   **🎯 研究目的**: 尽管计算机视觉中的手势识别技术已取得显著进展，但在创建直观、适应不同用户和环境、且足够节能以满足实际可穿戴应用需求的系统方面，仍存在关键挑战。本研究旨在开发一种针对事件传感器可穿戴设备优化的、鲁棒、超低功耗的手势识别系统，以实现智能眼镜的自然手势控制，从而显著改善用户体验。
*   **⭐ 主要发现**: 本文提出了Helios 2.0，一个针对可穿戴设备优化的移动实时、超低功耗事件相机系统，该系统显著改善了智能眼镜的用户体验，实现了自然手势控制。该方法通过精心选择的微手势来应对挑战，包括拇指在食指上的横向滑动（双向）以及拇指和食指尖之间的双捏合。这些以人为中心的设计利用了自然手部动作，确保了直观可用性，无需用户学习复杂手势。Helios 2.0的成功展示了事件相机在低功耗、高效率手势识别方面的巨大潜力，为下一代可穿戴设备的交互方式提供了创新解决方案。

---

### [[Sign Language Translation using Frame and Event Stream: Benchmark Dataset and Algorithms]](http://arxiv.org/abs/2503.06484v1)
<!-- 2025-03-09 -->
**📅 发布日期**: 2025-03-09

*   **👥 作者**: Xiao Wang, Yuehang Li, Fuling Wang, Bo Jiang, Yaowei Wang, Yonghong Tian, Jin Tang, Bin Luo
*   **🎯 研究目的**: 准确的手语理解对于残障人士的沟通至关重要。目前的手语翻译算法主要依赖于RGB帧，但其受限于固定帧率、可变光照条件以及快速手部运动引起的运动模糊。受事件相机在其他领域成功应用的启发，本研究旨在利用事件流辅助RGB相机捕捉手势数据，以解决上述各种挑战，并为此领域提供一个大规模的基准数据集和相应的算法。
*   **⭐ 主要发现**: 本文提出了VECSL，一个大规模的RGB-事件手语翻译数据集，包含15,676个RGB-事件样本、15,191个手语词汇，涵盖2,568个汉字，并在多样化的光照和背景条件下收集。该数据集的发布填补了该领域多模态数据稀缺的空白。研究还提出了利用事件流辅助RGB相机进行手语翻译的算法，有效解决了传统RGB帧在固定帧率、光照变化和运动模糊方面的局限性。这些贡献为手语翻译领域带来了新的研究方向，并为未来基于事件流和帧融合的手语理解算法提供了坚实的基础。

---

### [[SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks]](http://arxiv.org/abs/2503.08703v2)
<!-- 2025-03-09 -->
**📅 发布日期**: 2025-03-09

*   **👥 作者**: Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao, Jieyuan Zhang, Kexin Shi, Jingzhinan Wang, Jason K. Eshraghian, Haicheng Qu, Jiqing Zhang, Malu Zhang, Yang Yang
*   **🎯 研究目的**: 事件相机以其卓越的时间分辨率、动态范围、能效和像素带宽，为视觉追踪提供了独特优势。脉冲神经网络（SNNs）通过离散的脉冲信号自然地与事件数据互补，使其成为事件追踪的理想选择。然而，当前结合人工神经网络（ANNs）和SNNs的方法以及次优的架构，往往会牺牲能效并限制追踪性能。本研究旨在解决这些局限性，提出一种高效且高性能的事件追踪方法。
*   **⭐ 主要发现**: 本文提出了SDTrack，这是首个基于Transformer的脉冲驱动追踪流水线，为事件追踪领域树立了新的基线。SDTrack引入了全局轨迹提示（Global Trajectory Prompt, GTP）方法，能够有效捕捉全局轨迹信息，并将其与事件流聚合到事件图像中，以增强时空表示。该方法克服了现有ANN/SNN混合方法在能效和追踪性能上的不足，通过纯SNN架构实现了卓越的性能，同时保持了事件相机固有的低功耗优势。SDTrack的提出为未来事件相机与SNNs在高速、低功耗追踪应用中的发展奠定了基础。

---

### [[ERetinex: Event Camera Meets Retinex Theory for Low-Light Image Enhancement]](http://arxiv.org/abs/2503.02484v1)
<!-- 2025-03-04 -->
**📅 发布日期**: 2025-03-04

*   **👥 作者**: Xuejian Guo, Zhiqiang Tian, Yuehang Wang, Siqi Li, Yu Jiang, Shaoyi Du, Yue Gao
*   **🎯 研究目的**: 低光照图像增强旨在恢复在黑暗场景中捕获的曝光不足图像。在这种场景下，传统基于帧的相机由于曝光时间限制，可能无法捕捉到结构和颜色信息。事件相机作为一种仿生视觉传感器，能够异步响应像素级的亮度变化，其高动态范围对于在极端低光照场景下的视觉感知至关重要，超越了传统相机。本研究旨在将Retinex理论与事件相机结合，以解决低光照图像增强的挑战。
*   **⭐ 主要发现**: 本文首次将Retinex理论与事件相机相结合，提出了一种新颖的基于Retinex理论的低光照图像恢复方法ERetinex。该方法充分利用了事件相机在高动态范围和异步响应方面的优势，有效解决了传统相机在低光照环境下图像结构和颜色信息丢失的问题。通过结合Retinex理论对光照和反射的解耦能力，ERetinex能够从事件流中重建出高质量、细节丰富的图像，即使在极低光照条件下也能实现卓越的视觉感知。这一突破为事件相机在夜视、安防监控等极端环境下的应用开辟了新的可能性。

---

### [[EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition]](http://arxiv.org/abs/2502.09020v1)
<!-- 2025-02-13 -->
**📅 发布日期**: 2025-02-13

*   **👥 作者**: Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang
*   **🎯 研究目的**: 当前主流的场景文本识别（STR）算法主要基于RGB相机开发，但它们对低光照、运动模糊和杂乱背景等挑战性因素敏感。本研究旨在利用仿生事件相机来识别场景文本，以克服传统RGB相机的局限性。为此，研究计划收集并标注一个大规模的基准数据集，并为未来的研究提供基线算法。
*   **⭐ 主要发现**: 本文提出了EventSTR，一个大规模的基于事件流的场景文本识别基准数据集，包含9,928个高分辨率（$1280 \times 720$）事件样本，涵盖中文和英文字符，有效解决了传统RGB相机在低光照、运动模糊和杂乱背景下的识别挑战。研究还对多种STR算法进行了基准测试，为后续工作提供了比较基础。此外，本文提出了一种名为SimC-ESTR的新型事件流场景文本识别框架，该框架首先使用视觉编码器提取事件特征，并通过Q-former模块将其投影为tokens。更重要的是，该框架在处理事件流的稀疏性和异步性方面表现出色，显著提升了在复杂场景下的文本识别性能。

---

### [[Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media]](http://arxiv.org/abs/2501.03874v2)
<!-- 2025-01-07 -->
**📅 发布日期**: 2025-01-07

*   **👥 作者**: Ning Zhang, Timothy Shea, Arto Nurmikko
*   **🎯 研究目的**: 跟踪和同时获取被强散射介质遮挡的随机移动目标的图像，仍然是一个具有挑战性的问题，对于许多需要精确物体定位和识别的应用至关重要。本研究旨在开发一种端到端的神经形态光学工程和计算方法，以展示如何通过结合事件检测相机和多阶段神经形态深度学习策略来跟踪和成像通常不可见的物体。
*   **⭐ 主要发现**: 本文开发了一种端到端的神经形态光学工程与计算方法，成功实现了通过强散射介质对随机移动目标的追踪和成像。该方法的核心创新在于将事件检测相机与多阶段神经形态深度学习策略相结合：事件相机检测从散射介质中出现的微弱光子，并将其转换为像素级的异步脉冲序列，这是从主导的无信息背景中分离出物体特定信息的第一步。随后，这些脉冲数据被输入到一个深度脉冲神经网络（SNN）引擎中，该引擎能够从嘈杂的脉冲流中有效地隔离和识别目标信息。实验证明，该系统能够精确地追踪并重建在传统光学方法下不可见的物体图像，为在复杂、高散射环境下的目标感知提供了突破性解决方案，在生物医学成像、水下探测和安全监控等领域具有广阔的应用前景。

---

### [[Spatially-guided Temporal Aggregation for Robust Event-RGB Optical Flow Estimation]](http://arxiv.org/abs/2501.00838v1)
<!-- 2025-01-01 -->
**📅 发布日期**: 2025-01-01

*   **👥 作者**: Qianang Zhou, Junhui Hou, Meiyi Yang, Yongjian Deng, Youfu Li, Junlin Xiong
*   **🎯 研究目的**: 当前的光流方法主要利用帧（或RGB）数据的稳定外观来建立跨时间的鲁棒对应关系。然而，事件相机提供了高时间分辨率的运动线索，并在挑战性场景中表现出色。这两种模态的互补特性突显了整合帧和事件数据进行光流估计的潜力。然而，大多数跨模态方法未能充分利用这些互补优势，而是简单地堆叠信息。本研究旨在提出一种新颖的方法，通过空间密集的模态来引导时间密集的事件模态的聚合，以实现有效的跨模态融合。
*   **⭐ 主要发现**: 本文提出了一种新颖的空间引导时间聚合方法，用于鲁棒的事件-RGB光流估计。核心创新在于利用空间密集的帧模态来引导时间密集的事件模态的有效聚合，从而充分发挥两种传感器的互补优势。具体而言，研究提出了一种事件增强的帧表示，该表示不仅保留了帧丰富的纹理信息，还融入了事件数据的高时间分辨率运动细节。实验结果表明，该方法在各种复杂场景下均能生成更精确、更鲁棒的光流估计，显著优
### [[Frequency-Adaptive Low-Latency Object Detection Using Events and Frames]](http://arxiv.org/abs/2412.04149v2)
<!-- 2024-12-05 -->
**📅 发布日期**: 2024-12-05

*   **👥 作者**: Haitian Zhang, Xiangyuan Wang, Chang Xu, Xinya Wang, Fang Xu, Huai Yu, Lei Yu, Wen Yang
*   **🎯 研究目的**: 本研究旨在解决融合事件相机和RGB图像进行目标检测时面临的两个关键不匹配问题：低延迟事件与高延迟RGB帧之间的不匹配，以及训练中时间稀疏标签与推理中连续流之间的不匹配。这些问题严重阻碍了高频融合目标检测的实现，而融合事件和RGB图像能够结合事件相机在恶劣环境下的鲁棒性与RGB相机丰富的语义信息。
*   **⭐ 主要发现**: 提出了频率自适应低延迟目标检测器（FAOD）。FAOD通过一个对齐模块（Align Module）将低频RGB帧与高频事件对齐，该模块增强了跨模态风格和空间邻近性，从而有效解决了事件-RGB不匹配问题。此外，还提出了一种名为“时间偏移”（Time Shift）的训练策略，进一步提升了模型的性能。

---

### [[ETAP: Event-based Tracking of Any Point]](http://arxiv.org/abs/2412.00133v2)
<!-- 2024-11-28 -->
**📅 发布日期**: 2024-11-28

*   **👥 作者**: Friedhelm Hamann, Daniel Gehrig, Filbert Febryanto, Kostas Daniilidis, Guillermo Gallego
*
### [[Helios: An extremely low power event-based gesture recognition for always-on smart eyewear]](http://arxiv.org/abs/2407.05206v4)
<!-- 2024-07-06 -->
**📅 发布日期**: 2024-07-06

*   **👥 作者**: Prarthana Bhattacharyya, Joshua Mitton, Ryan Page, Owen Morgan, Ben Menzies, Gabriel Homewood, Kemi Jacobs, Paolo Baesso, David Trickett, Chris Mair, Taru Muhonen, Rory Clark, Louis Berridge, Richard Vigars, Iain Wallace
*   **🎯 研究目的**: 随着增强现实(AR)技术的发展，智能眼镜（如Meta Ray-Bans）在视觉和佩戴舒适度方面取得了进展，但在功能性上仍有不足。现有的人机交互(HMI)方式，如电容触控和语音控制，存在人机工程学、隐私和功耗方面的局限性。本研究旨在解决这些挑战，通过利用自然手势交互，为全天候智能眼镜设计一个超低功耗、实时、基于事件的手势识别系统，以提供更直观、舒适的用户体验。
*   **⭐ 主要发现**: 论文提出了Helios系统，这是首个专为全天候智能眼镜设计的超低功耗、实时、基于事件的手势识别系统。Helios利用一个极其紧凑（3mmx4mm）且功耗极低（20mW）的事件相机来捕捉自然手部交互。该系统通过处理事件相机输出，实现了高效的手势识别，解决了传统HMI在人体工程学、隐私和功耗上的痛点。这项创新为智能眼镜提供了更自然、节能的交互方式，有望推动AR设备的功能性发展。

---

### [[Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input]](http://arxiv.org/abs/2406.03439v1)
<!-- 2024-06-05 -->
**📅 发布日期**: 2024-06-05

*   **👥 作者**: Joachim Ott, Zuowen Wang, Shih-Chii Liu
*   **🎯 研究目的**: 事件相机因其低延迟和稀疏输出响应的特性，在需要视觉传感器的任务中具有优势。然而，由于缺乏用于网络训练的大型标注事件相机数据集，基于事件相机的深度网络算法发展缓慢。本研究旨在解决这一数据稀缺问题，提出一种通过文本到X模型（其中X可以是事件流）创建新的标注事件数据集的方法。
*   **⭐ 主要发现**: 论文提出了一种名为Text-to-Events的模型，能够直接从文本提示生成合成事件帧。该模型使用一个自编码器，训练其生成代表事件相机输出的稀疏事件帧。通过将预训练的自编码器与扩散模型架构相结合，Text-to-Events模型能够生成平滑的合成事件流。这一创新性方法为事件相机算法的开发提供了急需的大规模、多样化和标注数据集，极大地加速了该领域的研究进展。

---

### [[EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting]](http://arxiv.org/abs/2405.14959v3)
<!-- 2024-05-23 -->
**📅 发布日期**: 2024-05-23

*   **👥 作者**: Jiaxu Wang, Junhao He, Ziyi Zhang, Mingyuan Sun, Jingkai Sun, Renjing Xu
*   **🎯 研究目的**: 事件相机具有高动态范围和低延迟等优势，非常适用于挑战性光照条件和快速移动场景。然而，由于事件数据稀疏且不包含绝对颜色信息，从原始事件流重建3D场景面临困难。本研究旨在利用事件相机的潜力进行3D重建，并解决传统方法在泛化能力上的不足，提出首个基于事件的通用3D重建框架。
*   **⭐ 主要发现**: 论文提出了EvGGS框架，这是首个基于事件的通用3D重建框架，能够仅从事件输入以端到端（feedforward）方式将场景重建为3D高斯，并且无需重新训练即可泛化到未见过的场景。该框架包含深度估计模块、强度重建模块和高斯回归模块，这些子模块以级联方式连接并进行协同训练。EvGGS的创新性在于其能够克服事件数据缺乏颜色信息的挑战，并实现对新场景的泛化能力，极大地推动了事件相机在3D重建领域的应用。

---

### [[A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation]](http://arxiv.org/abs/2404.17335v3)
<!-- 2024-04-26 -->
**📅 发布日期**: 2024-04-26

*   **👥 作者**: Xin Zhang, Liangxiu Han, Tam Sobeih, Lianghao Han, Darren Dancey
*   **🎯 研究目的**: 深度估计是计算机视觉中的关键任务，广泛应用于自动导航、机器人和增强现实。事件相机具有低延迟、高动态范围和能效高等独特优势，但其非传统的脉冲输出和标注数据集的稀缺性对传统基于图像的深度估计方法提出了重大挑战。本研究旨在克服这些挑战，利用脉冲数据的独特特性，提出一种新颖的、节能的脉冲驱动Transformer网络进行深度估计。
*   **⭐ 主要发现**: 论文提出了一种新颖的节能脉冲驱动Transformer网络（SDT），用于从事件相机数据中进行深度估计。SDT引入了三项关键创新：1) 纯脉冲驱动的Transformer架构，结合了基于脉冲的注意力机制；2) 一种跨模态知识蒸馏策略，利用RGB图像的丰富信息指导SNN的训练；3) 一种新颖的损失函数，以优化深度估计的准确性。实验结果表明，SDT在准确性和能效方面均优于现有方法，为事件相机深度估计提供了一个有前景的解决方案。

---

### [[Event-Based Eye Tracking. AIS 2024 Challenge Survey]](http://arxiv.org/abs/2404.11770v1)
<!-- 2024-04-17 -->
**📅 发布日期**: 2024-04-17

*   **👥 作者**: Zuowen Wang, Chang Gao, Zongwei Wu, Marcos V. Conde, Radu Timofte, Shih-Chii Liu, Qinyu Chen, Zheng-jun Zha, Wei Zhai, Han Han, Bohao Liao, Yuliang Wu, Zengyu Wan, Zhong Wang, Yang Cao, Ganchao Tan, Jinze Chen, Yan Ru Pei, Sasskia Brüers, Sébastien Crouzet, Douglas McLelland, Oliver Coenen, Baoheng Zhang, Yizhao Gao, Jingyuan Li, Hayden Kwok-Hay So, Philippe Bich, Chiara Boretti, Luciano Prono, Mircea Lică, David Dinucu-Jianu, Cătălin Grîu, Xiaopeng Lin, Hongwei Ren, Bojun Cheng, Xinan Zhang, Valentin Vial, Anthony Yezzi, James Tsai
*   **🎯 研究目的**: 本综述旨在回顾AIS 2024事件相机眼动追踪（EET）挑战赛。该挑战赛的核心任务是处理事件相机记录的眼球运动数据，并预测瞳孔中心位置，同时强调在实现良好任务准确性和效率权衡的前提下，进行高效的眼动追踪。
*   **⭐ 主要发现**: 本综述详细分析了AIS 2024 EET挑战赛中提交的8支团队的创新方法。挑战赛吸引了38名参与者注册，并展示了多种新颖且多样化的解决方案。通过对这些方法的审查和分析，本综述旨在推动未来基于事件的眼动追踪研究的发展。它总结了当前领域的技术水平、面临的挑战以及潜在的未来研究方向，为研究人员提供了宝贵的参考。

---

### [[A Lightweight Spatiotemporal Network for Online Eye Tracking with Event Camera]](http://arxiv.org/abs/2404.08858v1)
<!-- 2024-04-13 -->
**📅 发布日期**: 2024-04-13

*   **👥 作者**: Yan Ru Pei, Sasskia Brüers, Sébastien Crouzet, Douglas McLelland, Olivier Coenen
*   **🎯 研究目的**: 事件数据常出现在边缘计算环境中，其中效率和低延迟至关重要。本研究旨在设计一种轻量级的因果时空卷积网络，以有效处理事件数据并利用其丰富的时序特征，特别是在资源受限的边缘硬件上实现高效的在线眼动追踪。
*   **⭐ 主要发现**: 论文提出了一种轻量级的时空卷积网络，专为事件相机在线眼动追踪设计。该方案通过以下三种方式实现边缘设备的效率目标：1) 采用简单的架构和操作（卷积、ReLU激活函数）；2) 可配置为通过缓冲层输出实现高效的在线推理；3) 通过训练期间的正则化实现超过90%的激活稀疏性，从而在基于事件的处理器上显著提高效率。此外，论文还提出了一种直接作用于事件数据的通用仿射增强策略。这些创新使得该网络能够在资源受限的边缘设备上实现高效率和低延迟的眼动追踪。

---

### [[SpikeNVS: Enhancing Novel View Synthesis from Blurry Images via Spike Camera]](http://arxiv.org/abs/2404.06710v3)
<!-- 2024-04-10 -->
**📅 发布日期**: 2024-04-10

*   **👥 作者**: Gaole Dai, Zhenyu Wang, Qinwen Xu, Ming Lu, Wen Chen, Boxin Shi, Shanghang Zhang, Tiejun Huang
*   **🎯 研究目的**: 使用神经场方法（如NeRF和3DGS）实现清晰的新视图合成（NVS）的关键因素之一是训练图像的质量。然而，传统RGB相机容易受到运动模糊的影响。虽然事件相机已被探索用于改善NVS质量，但事件-RGB方法存在训练成本高和背景处理效果不佳等局限性。本研究旨在克服这些限制，引入一种利用脉冲相机来增强模糊图像新视图合成质量的新方法。
*   **⭐ 主要发现**: 论文提出了SpikeNVS，一种利用脉冲相机来增强新视图合成质量的新方法。与传统RGB相机和事件相机不同，脉冲相机能够固有地捕捉更全面的时间信息，提供场景的清晰表示作为额外的训练数据。SpikeNVS克服了现有事件-RGB方法训练成本高和背景处理不足的局限性。通过利用脉冲相机的独特优势，SpikeNVS能够从模糊图像中生成更清晰、更高质量的新视图，为神经渲染领域带来了显著的改进。

---

### [[A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation]](http://arxiv.org/abs/2404.05858v1)
<!-- 2024-04-08 -->
**📅 发布日期**: 2024-04-08

*   **👥 作者**: Ahmed Faisal Abdelrahman, Matias Valdenegro-Toro, Maren Bennewitz, Paul G. Plöger
*   **🎯 研究目的**: 神经形态计算模仿大脑的计算原理，并推动了基于事件的视觉和脉冲神经网络（SNNs）的研究。事件相机（ECs）具有功耗低、响应延迟短和动态范围广等优势，而SNNs在降低能耗和推理时间方面展现了潜力。然而，这些新范式在空中机器人领域之外的应用仍鲜有探索。本研究旨在探索脑启发感知和数据处理在机器人操作中的效用，开发一种神经形态方法用于配备相机的机械臂的障碍物避障。
*   **⭐ 主要发现**: 论文开发了一种新颖的神经形态方法，用于机器人操作中的障碍物避障。该方法利用事件相机和脉冲神经网络的优势，实现了低功耗、低延迟的感知和决策。通过将事件相机捕捉的局部强度变化与SNN的类生物神经元动力学相结合，该系统能够高效地检测和规避障碍物。这项工作首次将神经形态方法应用于机器人操作的障碍物避障任务，展示了其在提高机器人效率和自主性方面的巨大潜力，并为未来脑启发式机器人系统奠定了基础。

---

### [[Hypergraph-based Multi-View Action Recognition using Event Cameras]](http://arxiv.org/abs/2403.19316v1)
<!-- 2024-03-28 -->
**📅 发布日期**: 2024-03-28

*   **👥 作者**: Yue Gao, Jiaxuan Lu, Siqi Li, Yipeng Li, Shaoyi Du
*   **🎯 研究目的**: 视频数据中的动作识别是广泛应用的基础任务。单视图动作识别因依赖单一视角而面临局限性，而多视图方法则通过捕捉不同视角的互补信息来提高准确性。事件相机作为创新的仿生传感器，推动了基于事件的动作识别发展。然而，现有工作主要集中在单视图场景，在多视图事件数据利用方面存在空白，尤其是在信息不足和语义错位等挑战。本研究旨在弥补这一空白，提出一个多视图事件动作识别框架。
*   **⭐ 主要发现**: 论文提出了HyperMV，一个创新的多视图事件动作识别框架，旨在解决多视图事件数据利用中的信息不足和语义错位问题。HyperMV将离散事件数据转换为类帧表示，并引入了基于超图的学习机制来有效融合来自不同视角的事件信息。通过构建超图，HyperMV能够捕捉更复杂的非成对关系和高阶语义关联，从而显著提升多视图动作识别的准确性。实验结果验证了HyperMV在处理多视图事件数据方面的优越性，为事件相机在复杂动作识别任务中的应用开辟了新途径。

---

### [[Tracking-Assisted Object Detection with Event Cameras]](http://arxiv.org/abs/2403.18330v3)
<!-- 2024-03-27 -->
**📅 发布日期**: 2024-03-27

*   **👥 作者**: Ting-Kang Yen, Igor Morawski, Shusil Dangi, Kai He, Chung-Yi Lin, Jia-Fong Yeh, Hung-Ting Su, Winston Hsu
*   **🎯 研究目的**: 基于事件的物体检测因事件相机的高动态范围和无运动模糊特性而受到关注。然而，特征的异步性和稀疏性导致物体在相对于相机无相对运动时变得“不可见”，这给任务带来了重大挑战。现有工作试图通过隐式学习记忆来保留时间线索，但难以有效保存长期特征。本研究旨在将这些“不可见”物体视为伪遮挡物体，并通过追踪遮挡来检测它们。
*   **⭐ 主要发现**: 论文提出了一种追踪辅助的物体检测方法，旨在解决事件相机在物体静止时无法检测到“不可见”物体的问题。首先，研究引入了物体的可见性属性，并贡献了一种自动标注算法，不仅用于清理现有数据集，还用于为静止物体生成标注。其次，提出了一种新颖的追踪辅助检测器，它利用追踪机制来预测和检测在事件流中暂时“消失”的物体。这项工作通过有效结合追踪和检测，显著提高了事件相机在复杂动态场景下物体检测的鲁棒性和完整性。

---

### [[Ev-Edge: Efficient Execution of Event-based Vision Algorithms on Commodity Edge Platforms]](http://arxiv.org/abs/2403.15717v1)
<!-- 2024-03-23 -->
**📅 发布日期**: 2024-03-23

*   **👥 作者**: Shrihari Sridharan, Surya Selvam, Kaushik Roy, Anand Raghunathan
*   **🎯 研究目的**: 事件相机因其高时间分辨率、高动态范围和可忽略的运动模糊，成为自动导航系统中有前景的感知模态。为了处理来自这类传感器的异步时间事件流，现有研究表明，需要结合人工神经网络（ANNs）、脉冲神经网络（SNNs）以及混合SNN-ANN算法才能在各种感知任务中实现高精度。然而，在具有CPU、GPU和神经加速器等异构处理单元的商用边缘平台上执行此类工作负载时，性能往往不佳。本研究旨在解决事件流的不规则性与算法特性及边缘平台多样性之间的不匹配问题，实现事件视觉算法在边缘平台上的高效执行。
*   **⭐ 主要发现**: 论文提出了Ev-Edge，一个用于在商用边缘平台上高效执行基于事件的视觉算法的框架。Ev-Edge通过优化事件流的处理流程和算法的部署策略，解决了事件流的不规则性与异构硬件特性之间的不匹配问题。它可能包含针对不同类型神经网络（ANNs, SNNs, 混合SNN-ANN）的优化，以及跨异构处理单元的任务调度和数据管理策略。Ev-Edge的提出显著提升了事件视觉算法在资源受限的边缘设备上的运行效率和性能，使其更适用于实际的自动导航和实时感知应用。

---

### [[SFOD: Spiking Fusion Object Detector]](http://arxiv.org/abs/2403.15192v1)
<!-- 2024-03-22 -->
**📅 发布日期**: 2024-03-22

*   **👥 作者**: Yimeng Fan, Wei Zhang, Changsong Liu, Mingyang Li, Wenrui Lu
*   **🎯 研究目的**: 事件相机因其高时间分辨率、高动态范围、低功耗和高像素带宽，在特定场景下的物体检测中具有独特优势。然而，事件数据的固有稀疏性和异步性对现有物体检测算法提出了挑战。脉冲神经网络（SNNs）作为一种仿生模型，为解决这些难题提供了潜在方案，但其在事件相机物体检测中的性能仍受限于当前实现。本研究旨在提出一种简单高效的SNN物体检测方法，以提升其在事件数据处理中的表现。
*   **⭐ 主要发现**: 论文提出了SFOD（Spiking Fusion Object Detector），一种简单高效的基于SNN的物体检测方法。SFOD的核心创新在于设计了一个脉冲融合模块（Spiking Fusion Module），首次实现了SNN中特征的融合。该模块能够有效处理事件数据的稀疏性和异步性，并将其转化为丰富的时空特征表示，从而显著提升了物体检测的准确性。SFOD的提出为基于事件相机的物体检测提供了一个有前景的SNN解决方案，有望在低功耗、高实时性要求的场景中发挥重要作用。

---

### [[EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-based Detection with Recurrent Spiking Neural Networks]](http://arxiv.org/abs/2403.12574v2)
<!-- 2024-03-19 -->
**📅 发布日期**: 2024-03-19

*   **👥 作者**: Ziming Wang, Ziling Wang, Huaning Li, Lang Qin, Runhao Jiang, De Ma, Huajin Tang
*   **🎯 研究目的**: 事件相机凭借其高动态范围和时间分辨率，非常适合物体检测，尤其是在运动模糊和挑战性光照条件下。然而，尽管大多数现有方法侧重于通过先进的检测骨干和早期聚合函数优化时空表示，但自适应事件采样这一关键问题仍未得到充分解决。脉冲神经网络（SNNs）以其事件驱动的稀疏脉冲通信范式，自然契合解决这一挑战。本研究旨在利用SNN的特性，提出一种端到端的自适应采样和表示方法，以提升基于事件的检测性能。
*   **⭐ 主要发现**: 论文发现脉冲神经元的神经动力学与理想的时间事件采样器行为高度一致，受此启发，提出了EAS-SNN框架。EAS-SNN引入了一个新颖的自适应采样模块，该模块与循环脉冲神经网络（Recurrent SNNs）相结合，实现了端到端的事件采样和特征表示学习。通过这种方式，EAS-SNN能够根据场景动态自适应地选择和处理事件，有效解决了事件数据稀疏性和不规则性的问题，显著提升了在运动模糊和极端光照条件下的物体检测性能。

---

### [[Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention]](http://arxiv.org/abs/2403.10173v4)
<!-- 2024-03-15 -->
**📅 发布日期**: 2024-03-15

*   **👥 作者**: Soikat Hasan Ahmed, Jan Finkbeiner, Emre Neftci
*   **🎯 研究目的**: 事件相机提供高时间分辨率和动态范围，且运动模糊极小，使其在鲁棒物体检测方面具有广阔前景。尽管脉冲神经网络（SNNs）在神经形态硬件上通常被认为能实现节能和低延迟的事件数据处理，但其在准确性和灵活性上往往不如人工神经网络（ANNs）。本研究旨在结合SNN和ANN的优势，提出一种混合神经网络架构，以实现高效且高准确度的事件相机物体检测。
*   **⭐ 主要发现**: 论文提出了一种基于注意力的混合SNN-ANN骨干网络，用于事件相机物体检测，旨在结合SNN的能效和ANN的准确性。核心创新是一个新颖的基于注意力的SNN-ANN桥接模块，它能够从SNN层捕获稀疏的时空关系，并将其转换为ANN部分所需的密集特征图。此外，论文还提出了一个将DWConvL-STMs集成到ANN块中的变体。实验结果表明，该混合架构在保持较高能效的同时，显著提升了事件相机物体检测的准确性和鲁棒性，为未来事件视觉系统的设计提供了新的范式。

---

### [[State Space Models for Event Cameras]](http://arxiv.org/abs/2402.15584v3)
<!-- 2024-02-23 -->
**📅 发布日期**: 2024-02-23

*   **👥 作者**: Nikola Zubić, Mathias Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 当前处理事件相机数据的最先进深度神经网络通常将一段时间窗口内的事件转换为密集的网格状输入表示。这种方法导致模型在以高于训练频率（即更小的时间窗口）部署时泛化能力较差。本研究旨在解决这一挑战，引入带有可学习时间尺度参数的状态空间模型（SSMs）到事件视觉领域，使其能够适应不同频率而无需重新训练。
*   **⭐ 主要发现**: 论文首次将带有可学习时间尺度参数的状态空间模型（SSMs）引入事件相机视觉领域。这种设计使得模型能够自适应地处理不同推理频率下的事件数据，而无需进行重新训练，显著提升了模型的泛化能力。此外，研究还探讨了两种策略来抵消在更高频率下部署模型时可能出现的混叠效应。通过在各种基准数据集上与基于RNN和Transformer的现有方法进行全面评估，结果表明SSMs在处理事件相机数据方面表现出优越的性能和鲁棒性，为事件视觉处理提供了新的强大工具。

---

### [[Temporal-Spatial Processing of Event Camera Data via Delay-Loop Reservoir Neural Network]](http://arxiv.org/abs/2403.17013v1)
<!-- 2024-02-12 -->
**📅 发布日期**: 2024-02-12

*   **👥 作者**: Richard Lau, Anthony Tylan-Tyler, Lihan Yao, Rey de Castro Roberto, Robert Taylor, Isaiah Jones
*   **🎯 研究目的**: 本文旨在描述一种用于视频处理的时空模型，特别应用于事件相机视频处理。研究提出并探讨了“时空猜想（Temporal-Spatial Conjecture, TSC）”，该猜想认为视频信号的时间表示中包含显著的信息内容，并且机器学习算法将受益于空间和时间分量的单独优化以进行智能处理。为了验证或驳斥TSC，研究提出了一种视觉马尔可夫模型（VMM），将视频分解为空间和时间分量，并估计这些分量的互信息（MI）。
*   **⭐ 主要发现**: 论文提出了一种基于延迟循环储层神经网络（DLR）的时空模型，用于事件相机视频处理。通过引入视觉马尔可夫模型（VMM），该研究能够将视频分解为空间和时间分量，并量化它们的互信息，从而为“时空猜想”提供了理论和实验支持。DLR神经网络在处理时间序列数据方面具有固有优势，结合VMM对时空信息的解耦处理，能够更有效地从事件相机数据中提取和利用丰富的时空特征。这项工作为事件相机数据的智能处理提供了新的视角和方法，有望提升视频理解和分析的性能。

---

### [[E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning]](http://arxiv.org/abs/2401.08117v1)
<!-- 2024-01-16 -->
**📅 发布日期**: 2024-01-16

*   **👥 作者**: Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Tongliang Liu
*   **🎯 研究目的**: 仿生事件相机或动态视觉传感器能够以高时间分辨率和高动态范围异步捕捉每像素亮度变化（称为事件流）。然而，非结构化的时空事件流给提供具有丰富语义信息的直观可视化带来了挑战。这促使了事件到视频（E2V）解决方案的需求，即以事件流作为输入并生成高质量视频帧以进行直观可视化。然而，当前的解决方案大多是数据驱动的，没有考虑事件流和视频帧之间潜在统计关系的先验知识，因此高度依赖深度神经网络的非线性和泛化能力，导致性能受限。
*   **⭐ 主要发现**: 论文提出了E2HQV，一种通过理论启发模型辅助深度学习从事件相机生成高质量视频的方法。与纯数据驱动方法不同，E2HQV将事件流和视频帧之间潜在的统计关系作为先验知识融入到模型中，从而克服了现有方法对深度神经网络非线性和泛化能力的过度依赖。通过结合理论模型和深度学习的优势，E2HQV能够更准确、更鲁棒地从稀疏且非结构化的事件流中重建出具有丰富细节和语义信息的高质量视频帧，极大地提升了事件相机在可视化和视频生成领域的应用潜力。

---

### [[CRSOT: Cross-Resolution Object Tracking using Unaligned Frame and Event Cameras]](http://arxiv.org/abs/2401.02826v1)
<!-- 2024-01-05 -->
**📅 发布日期**: 2024-01-05

*   **👥 作者**: Yabin Zhu, Xiao Wang, Chenglong Li, Bo Jiang, Lin Zhu, Zhixiang Huang, Yonghong Tian, Jin Tang
*   **🎯 研究目的**: 现有的RGB-DVS追踪数据集分辨率较低，不适用于实际应用。在许多实际系统中，仅部署可见光相机，而新设计的神经形态相机可能具有不同分辨率。最新的神经形态传感器可以输出高清事件流，但很难实现事件和帧在空间和时间上的严格对齐。因此，如何使用未对齐的神经形态和可见光传感器实现准确追踪是一个有价值但尚未研究的问题。本研究旨在正式提出并解决使用未对齐帧和事件相机进行物体追踪的任务。
*   **⭐ 主要发现**: 论文首次正式提出了使用未对齐帧和事件相机进行物体追踪的任务，并构建了第一个未对齐帧-事件数据集CRSOT。该数据集使用高分辨率可见光相机和神经形态传感器采集，旨在模拟实际应用中传感器未严格对齐的情况。研究还提出了一种创新的跨分辨率物体追踪方法，能够有效融合来自未对齐传感器的信息，克服了传统方法对严格对齐的依赖。CRSOT数据集和所提出的方法为解决实际场景中多模态传感器融合的挑战提供了重要基础，推动了神经形态相机在鲁棒物体追踪领域的应用。

---

### [[EvPlug: Learn a Plug-and-Play Module for Event and Image Fusion]](http://arxiv.org/abs/2312.16933v1)
<!-- 2023-12-28 -->
**📅 发布日期**: 2023-12-28

*   **👥 作者**: Jianping Jiang, Xinyu Zhou, Peiqi Duan, Boxin Shi
*   **🎯 研究目的**: 事件相机和RGB相机在成像上具有互补特性：前者拥有高动态范围（HDR）和高时间分辨率，后者提供丰富的纹理和颜色信息。这使得将事件相机集成到基于RGB的中高层视觉任务中前景广阔。然而，多模态融合、数据标注和模型架构设计面临挑战。本研究旨在提出EvPlug，一个可学习的即插即用模块，用于事件和图像融合，并从现有基于RGB的模型监督中学习。
*   **⭐ 主要发现**: 论文提出了EvPlug，一个可学习的即插即用事件和图像融合模块。EvPlug通过将事件流与图像特征以插件形式集成，使得基于RGB的模型能够对高动态范围（HDR）和快速运动场景具有鲁棒性，同时实现高时间分辨率推理。该模块的创新之处在于其“即插即用”的特性，可以方便地集成到现有基于RGB的视觉模型中，而无需对其进行大规模修改。EvPlug通过有效融合互补信息，显著提升了模型在复杂动态环境下的感知能力，为多模态视觉系统的设计提供了高效且灵活的解决方案。

---

### [[Low-power, Continuous Remote Behavioral Localization with Event Cameras]](http://arxiv.org/abs/2312.03799v2)
<!-- 2023-12-06 -->
**📅 发布日期**: 2023-12-06

*   **👥 作者**: Friedhelm Hamann, Suman Ghosh, Ignacio Juarez Martinez, Tom Hart, Alex Kacelnik, Guillermo Gallego
*   **🎯 研究目的**: 自然科学研究人员需要可靠的方法来量化动物行为。近年来，出现了许多计算机视觉方法来自动化这一过程。然而，由于困难的光照条件以及对电源和数据存储的限制，在偏远地区观察野生动物仍然是一项具有挑战性的任务。事件相机因其低功耗和高动态范围能力，为依赖电池的远程监测提供了独特优势。本研究旨在利用这种新型传感器来量化南极企鹅的一种行为，即狂喜展示（ecstatic display），将其表述为时间动作检测任务，确定行为的开始和结束时间。
*   **⭐ 主要发现**: 论文首次利用事件相机实现了低功耗、连续的远程动物行为定位。研究团队在南极洲记录了企鹅群落数周的事件数据，并对“狂喜展示”行为进行了标注。通过将问题表述为时间动作检测任务，该研究成功地利用事件相机的独特
### [Retina : Low-Power Eye Tracking with Event Camera and Spiking Hardware]](http://arxiv.org/abs/2312.00425v2)
<!-- 2023-12-01 -->
**📅 发布日期**: 2023-12-01

*   **👥 作者**: Pietro Bonazzi, Sizhen Bian, Giovanni Lippolis, Yawei Li, Sadique Sheik, Michele Magno
*   **🎯 研究目的**: 本研究旨在提出一种基于事件相机的神经形态眼动追踪方法，利用动态视觉传感器（DVS）相机捕获的纯事件数据。核心目标是将直接训练的脉冲神经网络（SNN）回归模型与最先进的低功耗边缘神经形态处理器Speck相结合，以提高眼动追踪系统的精度和效率。
*   **⭐ 主要发现**: 论文首先引入了一个代表性的事件基眼动追踪数据集“Ini-30”，该数据集由30名志愿者佩戴两台眼镜式DVS相机收集。接着，描述了一个名为“Retina”的SNN模型，该模型基于积分放电（IAF）神经元，仅包含64k个参数（比最新模型少6.63倍），在64x64 DVS输入下实现了仅3.24像素的瞳孔追踪误差，显著提升了低功耗眼动追踪的性能。

---

### [GET: Group Event Transformer for Event-Based Vision]](http://arxiv.org/abs/2310.02642v1)
<!-- 2023-10-04 -->
**📅 发布日期**: 2023-10-04

*   **👥 作者**: Yansong Peng, Yueyi Zhang, Zhiwei Xiong, Xiaoyan Sun, Feng Wu
*   **🎯 研究目的**: 现有事件相机骨干网络主要依赖于将事件转换为图像后进行处理，从而忽视了事件本身重要的时间性和极性属性。本研究旨在解决这一问题，提出一种新型的基于组的视觉Transformer骨干网络（GET），用于事件视觉，旨在在特征提取过程中解耦时间-极性信息与空间信息。
*   **⭐ 主要发现**: 论文首先为GET提出了一种新的事件表示方法，命名为“Group Token”，该方法根据事件的时间戳和极性对异步事件进行分组。随后，GET应用了“Event Dual Self-Attention”模块和“Group Token Aggregation”机制，有效地从事件流中提取并处理时空信息，克服了传统方法在处理事件数据固有属性方面的局限性。

---

### [Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline]](http://arxiv.org/abs/2309.14611v1)
<!-- 2023-09-26 -->
**📅 发布日期**: 2023-09-26

*   **👥 作者**: Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang
*   **🎯 研究目的**: 现有事件相机追踪方法要么依赖RGB和事件数据的对齐以实现高精度追踪（但推理成本高），要么直接学习基于事件的追踪器（易受噪声和稀疏空间分辨率影响）。本研究旨在提出一种新颖的分层知识蒸馏框架，在训练阶段充分利用多模态/多视图信息进行知识迁移，从而在测试阶段仅使用事件信号实现高速、低延迟的视觉追踪。
*   **⭐ 主要发现**: 论文首先训练了一个基于Transformer的多模态追踪框架作为教师模型，该模型同时输入RGB帧和事件流。通过这种知识蒸馏方法，研究团队成功地将多模态信息有效地迁移到仅依赖事件信号的追踪器中，实现了在测试时的高速和低延迟性能，同时克服了纯事件追踪器易受噪声影响的缺点。

---

### [Dense Voxel 3D Reconstruction Using a Monocular Event Camera]](http://arxiv.org/abs/2309.00385v1)
<!-- 2023-09-01 -->
**📅 发布日期**: 2023-09-01

*   **👥 作者**: Haodong Chen, Vera Chung, Li Tan, Xiaoming Chen
*   **🎯 研究目的**: 事件相机因其高动态范围、高帧率和极低功耗等优势，在帧插值、语义分割、里程计和SLAM等领域得到广泛应用。然而，其在VR应用的3D重建领域尚未得到充分探索。现有方法主要通过深度图估计进行3D重建，且生成密集3D重建通常需要多台相机，而单事件相机方法只能产生半密集结果。本研究旨在利用单目事件相机实现密集的体素3D重建。
*   **⭐ 主要发现**: 论文探索了利用单目事件相机进行密集体素3D重建的可能性。尽管摘要未详细说明具体的算法或实验结果，但其核心贡献在于提出了使用单一事件相机实现密集3D重建的新方向，这对于VR应用中对实时性、低功耗和高动态范围有严格要求的场景具有重要意义，有望突破现有单目事件相机仅能实现半密集重建的局限。

---

### [3ET: Efficient Event-based Eye Tracking using a Change-Based ConvLSTM Network]](http://arxiv.org/abs/2308.11771v1)
<!-- 2023-08-22 -->
**📅 发布日期**: 2023-08-22

*   **👥 作者**: Qinyu Chen, Zuowen Wang, Shih-Chii Liu, Chang Gao
*   **🎯 研究目的**: 本研究旨在为下一代可穿戴医疗技术（如AR/VR头显）开发高效的事件基眼动追踪系统。研究利用视网膜启发的事件相机在低延迟响应和稀疏输出事件流方面的优势，以克服传统基于帧的相机的局限性。
*   **⭐ 主要发现**: 论文提出了一种稀疏的基于变化卷积长短期记忆（CB-ConvLSTM）模型用于事件基眼动追踪。该CB-ConvLSTM架构能够高效地从事件流中提取时空特征进行瞳孔追踪，性能优于传统的CNN结构。通过利用delta编码的循环路径增强激活稀疏性，CB-ConvLSTM在`v2e`生成的带标签瞳孔事件数据集上测试时，在不损失精度的情况下将算术运算量减少了约4.7倍，显著提升了效率。

---

### [SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition]](http://arxiv.org/abs/2308.04369v3)
<!-- 2023-08-08 -->
**📅 发布日期**: 2023-08-08

*   **👥 作者**: Xiao Wang, Yao Rong, Zongzhen Wu, Lin Zhu, Bo Jiang, Jin Tang, Yonghong Tian
*   **🎯 研究目的**: 当前事件相机模式识别研究通常将事件流转换为图像、图或体素，并采用深度神经网络进行分类。然而，这些方法存在两个主要问题：一是仅使用空间稀疏的事件流进行识别，可能无法很好地捕获颜色和详细纹理信息；二是SNN（能效高但结果次优）和ANN（能耗高但性能高）之间存在权衡。本研究旨在实现能效与高性能之间的平衡，并充分利用帧和事件数据。
*   **⭐ 主要发现**: 论文提出了SSTFormer，一种混合脉冲神经网络（SNN）和人工神经网络（ANN）架构，用于基于帧-事件的识别。SSTFormer通过结合两种模态的数据，旨在捕获更丰富的视觉信息，并利用SNN的能效优势和ANN的高性能优势，实现两者之间的最佳平衡，从而在事件相机模式识别任务中取得更好的综合表现。

---

### [Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems]](http://arxiv.org/abs/2307.13600v1)
<!-- 2023-07-25 -->
**📅 发布日期**: 2023-07-25

*   **👥 作者**: Muhammad Ali Farooq, Waseem Shariff, Mehdi Sefidgar Dilmaghani, Wang Yao, Moazam Soomro, Peter Corcoran
*   **🎯 研究目的**: 光学传感器在为关键应用获取真实世界数据方面发挥了关键作用，这些数据与先进的机器学习算法结合，能够提供有意义的信息，从而增强人类视觉。本论文旨在探讨各种光学技术在设计和开发最先进的车外前向视觉系统和车内驾驶员监控系统中的应用。
*   **⭐ 主要发现**: 论文重点关注了多种光学传感器，包括长波热成像（LWIR）相机、近红外（NIR）相机、神经形态/事件相机、可见光CMOS相机和深度相机。此外，论文还讨论了利用这些光学模态的独特优势在实时环境中可以实现的各种潜在应用，强调了多模态数据融合在提升车载系统性能和可靠性方面的决定性作用。

---

### [Best of Both Worlds: Hybrid SNN-ANN Architecture for Event-based Optical Flow Estimation]](http://arxiv.org/abs/2306.02960v2)
<!-- 2023-06-05 -->
**📅 发布日期**: 2023-06-05

*   **👥 作者**: Shubham Negi, Deepika Sharma, Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 在机器人领域，事件相机作为传统帧相机的一种有前景的低功耗替代品，能够捕捉高速运动和高动态范围场景。脉冲神经网络（SNNs）因其异步事件驱动计算的特性，在从事件流中提取时空特征方面显示出巨大潜力。然而，SNN的训练面临挑战，如额外的可训练参数、深层网络中脉冲消失以及不可微分的二值激活函数。本研究旨在结合SNN和ANN的优势，解决事件基光流估计中的这些挑战。
*   **⭐ 主要发现**: 论文提出了一种混合SNN-ANN架构，旨在融合两种网络的优点。该架构能够有效地处理事件数据，利用SNN的低功耗和事件驱动特性，同时克服了SNN训练的固有困难，从而在事件基光流估计任务中实现高性能和高效率。

---

### [Deformable Convolutions and LSTM-based Flexible Event Frame Fusion Network for Motion Deblurring]](http://arxiv.org/abs/2306.00834v1)
<!-- 2023-06-01 -->
**📅 发布日期**: 2023-06-01

*   **👥 作者**: Dan Yang, Mehmet Yamac
*   **🎯 研究目的**: 事件相机生成异步数据序列，与传统RGB相机不同，它们仅捕捉场景中的亮度变化，导致输出数据稀疏且异步。尽管事件数据包含可用于RGB相机运动去模糊的有用信息，但如何有效整合事件和图像信息仍是一个挑战。现有最先进的基于CNN的去模糊解决方案通常基于事件数据在一段时间内的累积生成多个2D事件帧，但事件帧的数量是固定且预定义的，这会大幅降低时间分辨率，尤其是在存在快速移动物体或长时间曝光的情况下。本研究旨在解决这一问题。
*   **⭐ 主要发现**: 论文提出了一种基于可变形卷积和LSTM的灵活事件帧融合网络，用于运动去模糊。该网络旨在克服现有方法中事件帧数量固定和预定义的问题，从而能够更灵活地处理事件数据，尤其是在快速运动或长曝光场景下，有效提升时间分辨率，从而实现更精确的运动去模糊效果。

---

### [Spiking-Fer: Spiking Neural Network for Facial Expression Recognition With Event Cameras]](http://arxiv.org/abs/2304.10211v1)
<!-- 2023-04-20 -->
**📅 发布日期**: 2023-04-20

*   **👥 作者**: Sami Barchid, Benjamin Allaert, Amel Aissaoui, José Mennesson, Chaabane Djéraba
*   **🎯 研究目的**: 面部表情识别（FER）是一个活跃的研究领域，近年来取得了显著进展，特别是得益于大型深度学习模型的使用。然而，此类方法能耗巨大，难以部署到边缘设备上。为了解决这个问题，本研究提出将脉冲神经网络（SNNs）与事件相机结合，作为一种有前景的替代方案，能够以更低的能耗处理稀疏和异步事件。研究旨在首次将事件相机应用于FER，并建立相关基准。
*   **⭐ 主要发现**: 论文首次提出了“Event-based FER”的概念，即利用事件相机进行面部表情识别，并通过将流行的视频FER数据集转换为事件流，建立了首个相关基准。此外，论文提出了一种名为“Spiking-FER”的深度卷积SNN模型，并与类似的ANN模型进行了比较，结果表明Spiking-FER在处理事件流数据方面表现出色，为低能耗边缘设备上的FER应用提供了可行方案。

---

### [Neuromorphic Optical Flow and Real-time Implementation with Event Cameras]](http://arxiv.org/abs/2304.07139v2)
<!-- 2023-04-14 -->
**📅 发布日期**: 2023-04-14

*   **👥 作者**: Yannick Schnider, Stanislaw Wozniak, Mathias Gehrig, Jules Lecomte, Axel von Arnim, Luca Benini, Davide Scaramuzza, Angeliki Pantazi
*   **🎯 研究目的**: 光流提供相对运动信息，是许多计算机视觉管线中的重要组成部分。神经网络能够提供高精度的光流，但其复杂性对于边缘设备或机器人应用来说往往过高，而这些应用对效率和延迟有严格要求。为应对这一挑战，本研究旨在利用事件相机和脉冲神经网络的最新发展，开发一种高效、低延迟的光流估计方法。
*   **⭐ 主要发现**: 论文提出了一种受Timelens启发的新型网络架构，该架构在脉冲和非脉冲模式下运行时，均能提高最先进的自监督光流精度。为了使用物理事件相机实现实时管线，研究团队提出了一种基于活动和延迟分析的原理性模型简化方法。实验证明，该方法能够实现高速光流估计，为边缘设备和机器人应用提供了高效且精确的解决方案。

---

### [Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution]](http://arxiv.org/abs/2303.13767v2)
<!-- 2023-03-24 -->
**📅 发布日期**: 2023-03-24

*   **👥 作者**: Yunfan Lu, Zipeng Wang, Minjie Liu, Hongjian Wang, Lin Wang
*   **🎯 研究目的**: 事件相机异步感知亮度变化，产生高动态范围和低延迟的事件流，这启发了利用事件指导视频超分辨率（VSR）任务的研究。本研究首次尝试解决利用事件高时间分辨率特性实现任意尺度VSR的新问题。然而，在指导VSR时，事件的时空信息表示面临挑战。
*   **⭐ 主要发现**: 论文提出了一种新颖的框架，将事件的时空插值与VSR统一在一个框架中。其核心思想是，从查询的时空坐标以及RGB帧和事件流的特征中学习隐式神经表示。这种方法有效地利用了事件流的精细时间信息，克服了传统方法在处理任意尺度VSR和事件时空信息表示方面的困难，为事件引导的VSR提供了新的解决方案。

---

### [Unsupervised Domain Adaptation for Training Event-Based Networks Using Contrastive Learning and Uncorrelated Conditioning]](http://arxiv.org/abs/2303.12424v1)
<!-- 2023-03-22 -->
**📅 发布日期**: 2023-03-22

*   **👥 作者**: Dayuan Jian, Mohammad Rostami
*   **🎯 研究目的**: 事件相机为高动态范围环境和快速运动场景下的计算机视觉任务提供了可靠的测量数据。然而，由于事件相机是新兴技术，带标注数据的稀缺性给深度学习在事件视觉中的应用带来了挑战。将从传统相机标注数据中获得的知识进行迁移，为解决这一挑战提供了实用的解决方案。本研究旨在开发一种无监督域适应算法，用于训练事件基
### [[Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking Neural Networks with Learnable Neuronal Dynamics]](http://arxiv.org/abs/2209.11741v2)
<!-- 2022-09-21 -->
**📅 发布日期**: 2022-09-21

*   **👥 作者**: Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 传统相机在高速运动估计中存在局限性，而事件相机因其异步捕获时序丰富信息的能力，在高帧率运动估计方面展现出巨大潜力。脉冲神经网络（SNNs）作为受神经启发的事件驱动处理器，能够高效处理事件相机产生的异步数据，其神经元模型（如LIF）能跟踪输入中的关键时序信息。SNNs通过在神经元记忆中维持动态状态，保留重要信息并随时间遗忘冗余数据，因此有望在序列回归任务上超越同等规模的模拟神经网络（ANNs）。然而，深度SNNs由于“脉冲消失”问题难以训练。本研究旨在开发一种新的SNN架构，以克服深度SNNs的训练挑战，并利用事件相机数据进行高效且高性能的光流估计。
*   **⭐ 主要发现**: 论文提出了一种名为Adaptive-SpikeNet的脉冲神经网络，用于基于事件的光流估计。该网络通过引入可学习的神经元动力学来解决深度SNN训练中的“脉冲消失”问题，从而允许网络自适应地调整其对输入事件的响应。实验结果表明，Adaptive-SpikeNet在处理异步事件数据方面表现出色，能够有效利用事件相机提供的高时间分辨率信息。与传统方法和模拟神经网络相比，该SNN模型在序列回归任务（如光流估计）上展现出更高的性能，验证了SNNs在处理事件数据流方面的优越性及其在高速运动估计领域的应用潜力。

---

### [[EDeNN: Event Decay Neural Networks for low latency vision]](http://arxiv.org/abs/2209.04362v2)
<!-- 2022-09-09 -->
**📅 发布日期**: 2022-09-09

*   **👥 作者**: Celyn Walters, Simon Hadfield
*   **🎯 研究目的**: 尽管神经网络在计算机视觉任务中取得了巨大成功，但数字“神经元”与生物神经元仍有显著差异，且当前学习方法主要针对数字设备和图像帧等数字数据表示。相比之下，生物视觉系统通常比最先进的数字计算机视觉算法更强大、更高效。事件相机作为一种新兴的传感器技术，通过异步触发像素来模仿生物视觉，摒弃了图像帧的概念。然而，为了利用现代学习技术，许多基于事件的算法被迫将事件累积回图像帧，这在一定程度上浪费了事件相机的优势。本研究旨在开发一种新型的神经网络，能够直接处理事件流数据，充分利用事件相机的低延迟特性，以实现更高效的视觉处理。
*   **⭐ 主要发现**: 论文提出了一种名为Event Decay Neural Network (EDeNN) 的新型神经网络，其设计理念与传统方法相反，直接处理事件流数据而无需将其转换回图像帧。EDeNN通过引入事件衰减机制，使得网络能够更好地处理异步和稀疏的事件数据，并保持低延迟的特性。实验结果表明，EDeNN在多种视觉任务上表现出优异的性能，特别是在需要低延迟响应的场景中。该方法避免了将事件数据累积为图像帧的传统做法，从而充分发挥了事件相机在高时间分辨率和低功耗方面的优势，为未来基于事件的视觉系统提供了新的高效处理范式。

---

### [[Visual Odometry with Neuromorphic Resonator Networks]](http://arxiv.org/abs/2209.02000v3)
<!-- 2022-09-05 -->
**📅 发布日期**: 2022-09-05

*   **👥 作者**: Alpha Renner, Lazar Supic, Andreea Danielescu, Giacomo Indiveri, E. Paxon Frady, Friedrich T. Sommer, Yulia Sandamirskaya
*   **🎯 研究目的**: 视觉里程计（VO）是一种利用视觉传感器估计移动机器人自身运动的方法，相比基于差分测量的里程计（如惯性传感器或轮式编码器）不易累积误差。然而，基于图像的VO计算量大，限制了其在低延迟、低内存和低能耗场景中的应用。神经形态硬件为许多视觉和AI问题提供了低功耗解决方案，但设计此类解决方案通常复杂且需要从头构建。本研究旨在探索使用向量符号架构（VSA）作为抽象层来设计与神经形态硬件兼容的算法，并将其应用于视觉里程计任务，以实现低功耗、高效率的自运动估计。
*   **⭐ 主要发现**: 论文提出了一种基于神经形态谐振器网络的视觉里程计解决方案，该方案利用向量符号架构（VSA）作为抽象层来简化神经形态硬件上的算法设计。研究构建了一个从场景分析VSA模型衍生的VO系统，该系统能够高效地处理视觉信息并估计机器人运动。实验结果表明，所提出的方法在神经形态硬件上实现了低功耗和低延迟的视觉里程计功能，克服了传统图像VO计算量大的问题。这一创新性方法为在资源受限的边缘设备上部署复杂的视觉感知任务提供了新的途径，并展示了VSA在神经形态计算领域设计的潜力。

---

### [[Training Robust Spiking Neural Networks on Neuromorphic Data with Spatiotemporal Fragments]](http://arxiv.org/abs/2207.11659v3)
<!-- 2022-07-24 -->
**📅 发布日期**: 2022-07-24

*   **👥 作者**: Haibo Shen, Yihao Luo, Xiang Cao, Liangqi Zhang, Juyu Xiao, Tianjiang Wang
*   **🎯 研究目的**: 神经形态视觉传感器（事件相机）天生适合脉冲神经网络（SNNs），并为这种仿生模型提供了新颖的神经形态视觉数据。然而，由于事件数据的时空特性，需要新的数据增强方法来处理这些非常规的视觉信号，以提高SNNs的鲁棒性。现有数据增强方法主要集中在几何变换上，未能充分模拟实际场景中亮度变化等干扰。本研究旨在提出一种新颖的数据增强方法，能够保留神经形态数据的连续性，并通过模拟亮度变化等扰动来提高SNNs在事件数据上的泛化能力和鲁棒性。
*   **⭐ 主要发现**: 论文提出了一种新颖的事件时空片段（Event SpatioTemporal Fragments, ESTF）数据增强方法，用于训练鲁棒的脉冲神经网络。ESTF通过漂移或反转时空事件流的片段来模拟亮度变化的干扰，从而在保留神经形态数据连续性的同时，生成更多样化的训练样本。在主流神经形态数据集上进行的大量实验表明，ESTF相比纯几何变换提供了显著的性能提升，有效提高了SNNs的鲁棒性。这一方法为神经形态数据的处理和SNNs的训练提供了新的有效策略，有助于推动事件相机在复杂环境中的应用。

---

### [[Fusing Frame and Event Vision for High-speed Optical Flow for Edge Application]](http://arxiv.org/abs/2207.10720v1)
<!-- 2022-07-21 -->
**📅 发布日期**: 2022-07-21

*   **👥 作者**: Ashwin Sanjay Lele, Arijit Raychowdhury
*   **🎯 研究目的**: 基于帧的相机在光流计算中能提供高精度，但其速度受限于算法模型大小或相机帧率，不适用于高速应用。事件相机提供连续异步事件流，克服了帧率限制，但其数据处理算法要么借鉴帧式设置而限制速度，要么精度较低。为了在边缘应用中实现高精度和高速度的光流计算，本研究旨在融合帧相机和事件相机的互补优势，开发一种能够同时提供高速度和低误差率的光流计算方法。
*   **⭐ 主要发现**: 论文提出了一种生物仿生网络，该网络有效地融合了帧相机和事件相机的视觉数据，以实现高速且高精度的光流估计，特别适用于边缘计算设备。该方法结合了帧数据的精确性和事件数据的低延迟与抗运动模糊特性。通过在MVSEC数据集上的验证，该网络在实现4倍加速的同时，误差仅下降19%，显著优于单一模态的方法。研究还通过高速无人机飞行场景演示了该系统的有效性，证明了其在实际高速应用中提供可靠光流的能力，为边缘设备上的实时视觉感知提供了高效解决方案。

---

### [[How Many Events do You Need? Event-based Visual Place Recognition Using Sparse But Varying Pixels]](http://arxiv.org/abs/2206.13673v3)
<!-- 2022-06-28 -->
**📅 发布日期**: 2022-06-28

*   **👥 作者**: Tobias Fischer, Michael Milford
*   **🎯 研究目的**: 事件相机因其高动态范围、低延迟、几乎无运动模糊和高能效等特性而持续受到关注。其中一个潜在应用是机器人定位中的视觉地点识别，即匹配查询观测与数据库中对应的参考地点。传统的地点识别方法通常依赖于密集的图像信息。本研究旨在探索仅使用少量像素（几十到几百个）的事件流在地点识别任务中的独特性和有效性，以验证是否可以通过稀疏但变化显著的像素信息实现可靠的地点识别，从而降低计算和数据传输的开销。
*   **⭐ 主要发现**: 论文研究表明，即使是来自少量像素（几十或几百个）的稀疏事件流，也足以用于视觉地点识别任务。研究发现，当使用在参考集中显示出较大变化的像素时，这些像素位置上累积的事件数量的绝对差异足以完成地点识别。这意味着无需处理整个图像的密集事件数据，通过选择性地关注那些信息量大的稀疏像素，可以实现高效且准确的地点识别。这一发现对于开发低功耗、高效率的机器人定位系统具有重要意义，尤其是在资源受限的边缘设备上。

---

### [[E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations]](http://arxiv.org/abs/2206.07578v2)
<!-- 2022-06-15 -->
**📅 发布日期**: 2022-06-15

*   **👥 作者**: Jongwan Kim, DongJin Lee, Byunggook Na, Seongsik Park, Jeonghee Jo, Sungroh Yoon
*   **🎯 研究目的**: 事件相机能够异步地、独立地响应场景中的亮度变化，具有高动态范围（HDR）、高
### [EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing And Following]](http://arxiv.org/abs/2106.15045v1)
<!-- 2021-06-29 -->
**📅 发布日期**: 2021-06-29

*   **👥 作者**: Nitin J. Sanket, Chahat Deep Singh, Chethan M. Parameshwara, Cornelia Fermüller, Guido C. H. E. de Croon, Yiannis Aloimonos
*   **🎯 研究目的**: 随着无人机（UAVs）的普及，其对公共安全和隐私构成了潜在威胁。大多数商用或定制无人机都是多旋翼飞行器，包含多个螺旋桨。由于螺旋桨高速旋转，传统相机难以捕捉其清晰图像，常出现严重运动模糊。本研究旨在利用事件相机（一种具有高时间分辨率、低延迟和高动态范围的传感器）来克服这一挑战，从而实现对无人机螺旋桨的有效检测，进而支持无人机的空中着陆和跟踪任务。
*   **⭐ 主要发现**: 论文提出了一种名为EVPropNet的深度神经网络，专门用于从事件相机数据中检测螺旋桨。研究人员首先对螺旋桨的几何形状进行建模，并利用此模型生成模拟事件数据，用于训练EVPropNet。事件相机能够“看到”传统相机因运动模糊而无法直接捕捉到的高速旋转螺旋桨。通过利用事件相机独特的特性和提出的网络架构，EVPropNet能够有效地检测无人机螺旋桨，这为无人机在空中进行精确着陆和跟踪提供了关键的感知能力，对于提升无人机安全和管理具有重要意义。

---

### [[Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks]](http://arxiv.org/abs/2106.01862v2)
<!-- 2021-06-03 -->
**📅 发布日期**: 2021-06-03

*   **👥 作者**: Jesse Hagenaars, Federico Paredes-Vallés, Guido de Croon
*   **🎯 研究目的**: 神经形态计算领域有望实现极低功耗和低延迟的传感与处理。然而，将传统人工神经网络（ANNs）的学习算法迁移到脉冲神经网络（SNNs）面临挑战，阻碍了SNNs在大型复杂回归任务中的应用。此外，要实现真正异步和完全神经形态的感知管线，需要重新思考信息输入和累积的方式。对于感知任务，这意味着事件相机产生的脉冲应直接、逐个地传递给SNN，所有时间信息整合都必须在网络内部完成。本研究旨在解决这两个核心问题，专注于事件相机数据的光流估计这一复杂任务。
*   **⭐ 主要发现**: 论文成功地解决了SNNs在复杂回归任务中的应用难题，并实现了事件相机与SNN之间异步、逐个脉冲传递的感知管线。研究人员提出了一种自监督学习方法，用于基于事件的光流估计，该方法能够将事件相机数据直接输入到SNN中进行处理，从而最大限度地发挥神经形态计算的低功耗和低延迟优势。通过在网络内部完成所有时间信息整合，该方法避免了传统方法中对事件数据进行预处理和帧化所带来的延迟和计算开销。这项工作为SNNs在实时、低功耗视觉感知任务中的广泛应用奠定了基础，特别是在需要高时间分辨率和对动态场景快速响应的应用中。

---

### [[Bio-inspired visual attention for silicon retinas based on spiking neural networks applied to pattern classification]](http://arxiv.org/abs/2105.14753v1)
<!-- 2021-05-31 -->
**📅 发布日期**: 2021-05-31

*   **👥 作者**: Amélie Gruel, Jean Martinet
*   **🎯 研究目的**: 视觉注意力机制，特别是显著性检测，在多媒体索引中长期用于引导分析只关注图像或视频的相关部分，以进行后续处理。随着硅视网膜（即事件相机，一种测量像素亮度变化并输出异步事件的传感器）的出现，如何将注意力机制和显著性适应到这种非常规传感器输出数据成为了一个新问题。硅视网膜旨在模仿生物视网膜的行为，产生离散的时间事件，这些事件可以被解释为神经脉冲。本研究旨在为基于脉冲神经网络的硅视网膜开发一种受生物启发的视觉注意力模型，并将其应用于模式分类任务。
*   **⭐ 主要发现**: 论文成功地为事件相机数据设计并实现了一种受生物启发的视觉注意力模型，该模型基于脉冲神经网络。该模型能够有效地从事件流中识别出显著性区域，从而将后续处理的焦点限制在最相关的视觉信息上。通过将这种注意力机制应用于模式分类任务，研究人员证明了其在处理事件相机数据方面的有效性，并显著提升了分类性能。这项工作为事件相机数据处理引入了高效的生物启发式方法，有助于在资源受限或需要快速响应的场景中实现更高效、更准确的模式识别，例如在自主导航或人机交互等领域。

---

### [[Superevents: Towards Native Semantic Segmentation for Event-based Cameras]](http://arxiv.org/abs/2105.06091v1)
<!-- 2021-05-13 -->
**📅 发布日期**: 2021-05-13

*   **👥 作者**: Weng Fei Low, Ankit Sonthalia, Zhi Gao, André van Schaik, Bharath Ramesh
*   **🎯 研究目的**: 大多数成功的计算机视觉模型将低级特征转换为更丰富的中间或中级复杂表示，以用于下游视觉任务。然而，对于事件相机而言，这种中级表示尚未得到充分探索，尽管它对于事件流中视觉稀疏且通常不连续的空间信息尤其重要。本研究旨在通过引入“超事件”（superevents）这一概念，为事件相机数据开发一种原生的语义分割方法，并期望这种局部一致的中间表示能够惠及语义分割、视觉跟踪、深度估计等多种视觉任务。
*   **⭐ 主要发现**: 论文提出了“超事件”的概念，这是一种感知上一致的局部单元，用于描绘场景中对象的各个部分。受最新深度学习架构的启发，研究人员提出了一种新颖的方法，利用“生命周期增强”（lifetime augmentation）技术来生成这些超事件。通过这种方式，他们为事件相机数据构建了一种原生的中级表示，克服了事件流数据稀疏和不连续的挑战。实验结果表明，利用超事件进行语义分割能够取得显著的性能提升，为事件相机在复杂视觉任务中的应用开辟了新的途径。这种方法不仅有助于提高语义分割的准确性，也为其他事件驱动的视觉任务提供了通用的、高效的中间表示框架。

---

### [[Instantaneous Stereo Depth Estimation of Real-World Stimuli with a Neuromorphic Stereo-Vision Setup]](http://arxiv.org/abs/2104.02541v1)
<!-- 2021-04-06 -->
**📅 发布日期**: 2021-04-06

*   **👥 作者**: Nicoletta Risi, Enrico Calabrese, Giacomo Indiveri
*   **🎯 研究目的**: 立体匹配问题，即在两个不同视图中匹配对应特征以重建深度信息，在生物学中得到高效解决，但对于传统机器视觉方法而言仍是计算瓶颈。虽然结合事件相机和脉冲神经网络（SNNs）的立体视觉解决方案已存在，但它们要么在数字硬件上模拟，要么仅在简化刺激下进行测试。本研究旨在利用事件相机的特性，在一个混合信号神经形态硬件上实现一个受大脑启发的事件基立体匹配架构，并使用真实世界的复杂刺激（DHP19数据集）来验证其瞬时深度估计能力。
*   **⭐ 主要发现**: 论文成功地在一个混合信号神经形态处理器上实现了受大脑启发的事件基立体匹配架构，并利用DHP19数据集（一个包含真实世界人体姿态的复杂数据集）验证了其性能。该系统能够利用事件相机异步、低延迟的特性，实现对真实世界刺激的瞬时深度估计。与传统方法相比，这种神经形态方法显著简化了立体匹配问题，并展现出在处理复杂动态场景时的潜力。这项工作不仅验证了事件相机和SNNs在实时深度感知方面的优势，也为开发更高效、更低功耗的自主系统提供了重要的硬件和算法基础。

---

### [[Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor Fusion and Deep Fused Spiking-Analog Network Architectures]](http://arxiv.org/abs/2103.10592v1)
<!-- 2021-03-19 -->
**📅 发布日期**: 2021-03-19

*   **👥 作者**: Chankyu Lee, Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 标准帧基相机在高速运动下容易受到运动模糊影响，且在高动态范围场景中难以准确感知。事件相机通过异步检测单个像素亮度变化来克服这些限制，但其数据稀疏，难以估计像素的整体密集行为。为了解决这些传感器固有的问题，本研究旨在提出一个传感器融合框架Fusion-FlowNet，利用帧基和事件基传感器的互补特性，实现能量高效的光流估计。
*   **⭐ 主要发现**: 论文提出了Fusion-FlowNet，这是一个新颖的传感器融合框架，结合了帧基相机和事件相机的优势，用于能量高效的光流估计。该框架的核心是一个深度融合脉冲-模拟网络架构（Deep Fused Spiking-Analog Network Architectures），它能够有效处理两种不同类型传感器的数据。通过融合两种模态的信息，Fusion-FlowNet克服了单一传感器在运动模糊、高动态范围和数据稀疏性方面的局限性，实现了更鲁棒和准确的密集光流估计。这种混合网络架构的设计不仅提高了性能，还显著降低了能量消耗，使其在需要实时、低功耗视觉感知的应用中具有巨大潜力，例如在自主机器人和边缘计算设备中。

---

### [[Event-based Synthetic Aperture Imaging with a Hybrid Network]](http://arxiv.org/abs/2103.02376v3)
<!-- 2021-03-03 -->
**📅 发布日期**: 2021-03-03

*   **👥 作者**: Xiang Zhang, Wei Liao, Lei Yu, Wen Yang, Gui-Song Xia
*   **🎯 研究目的**: 合成孔径成像（SAI）通过模糊离焦前景遮挡并从多视图图像重建对焦的被遮挡目标，实现“透视”效果。然而，密集的遮挡和极端光照条件可能对基于传统帧基相机的SAI造成显著干扰，导致性能下降。本研究旨在提出一种基于事件相机的新型SAI系统，以解决这些问题，利用事件相机极低延迟和高动态范围的异步事件输出特性。
*   **⭐ 主要发现**: 论文提出了一种新颖的基于事件相机的合成孔径成像（SAI）系统，能够有效应对密集遮挡和极端光照条件下的挑战。事件相机能够以几乎连续的视图进行测量，从而消除密集遮挡的干扰，同时其高动态范围特性也解决了过曝/欠曝问题。为了重建被遮挡的目标，研究人员提出了一种混合编码器-解码器网络架构。该网络能够有效处理事件数据流，并从中提取出重建目标所需的关键信息。实验结果表明，与传统帧基SAI相比，所提出的事件基SAI系统在复杂场景下表现出更强的鲁棒性和更高的重建质量，为透视成像技术开辟了新的可能性。

---

### [[Learning Monocular Dense Depth from Events]](http://arxiv.org/abs/2010.08350v2)
<!-- 2020-10-16 -->
**📅 发布日期**: 2020-10-16

*   **👥 作者**: Javier Hidalgo-Carrió, Daniel Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是一种新型传感器，以异步事件流的形式输出亮度变化，而非传统强度帧。它们具有高时间分辨率、高动态范围、无运动模糊和低带宽等显著优势。近期，基于学习的方法已应用于事件数据，并在单目深度预测等任务中取得进展。然而，大多数现有方法使用标准前馈架构生成网络预测，未能充分利用事件流中固有的时间一致性。本研究旨在提出一种循环架构来解决单目密集深度估计任务，以更好地利用事件流的这种时间特性。
*   **⭐ 主要发现**: 论文提出了一种新颖的循环神经网络架构，用于从事件相机数据中学习单目密集深度。与现有主要采用前馈网络的方法不同，该循环架构能够有效捕捉事件流中固有的时间一致性，从而显著提升深度预测的准确性和鲁棒性。实验结果表明，所提出的循环方法在单目密集深度估计任务上取得了比标准前馈方法显著的改进。这项工作突出了利用事件相机数据时间特性对提升视觉任务性能的重要性，为事件基深度感知领域提供了新的有效方法。

---

### [[Real-Time Face & Eye Tracking and Blink Detection using Event Cameras]](http://arxiv.org/abs/2010.08278v1)
<!-- 2020-10-16 -->
**📅 发布日期**: 2020-10-16

*   **👥 作者**: Cian Ryan, Brian O Sullivan, Amr Elrasad, Joe Lemley, Paul Kielty, Christoph Posch, Etienne Perot
*   **🎯 研究目的**: 事件相机是一种新兴的神经形态视觉传感器，能够捕获每个像素的局部光强度变化，生成异步事件流。这种信息获取方式与传统帧基相机不同，具有低能耗、高时间分辨率、高动态范围和低延迟等显著优势。驾驶员监控系统（DMS）是车内安全系统，旨在感知和理解驾驶员的生理和认知状态。事件相机因其固有优势特别适用于DMS。本研究旨在提出一种新颖的方法，利用事件相机同时检测和跟踪驾驶员的面部和眼睛，并检测眨眼行为。
*   **⭐ 主要发现**: 论文提出了一种独特的、全卷积循环神经网络架构，用于利用事件相机数据进行实时面部和眼睛跟踪以及眨眼检测。该方法充分利用了事件相机的高时间分辨率和低延迟特性，使其能够捕捉到传统相机难以捕捉的快速面部和眼睛运动，例如眨眼。实验结果表明，所提出的系统能够高效且准确地进行实时面部和眼睛跟踪，并可靠地检测眨眼，这对于驾驶员疲劳和注意力分散的监控至关重要。这项工作展示了事件相机在DMS领域的巨大潜力，为开发更安全、更智能的车载系统提供了新的解决方案。

---

### [[Learning to Detect Objects with a 1 Megapixel Event Camera]](http://arxiv.org/abs/2009.13436v2)
<!-- 2020-09-28 -->
**📅 发布日期**: 2020-09-28

*   **👥 作者**: Etienne Perot, Pierre de Tournemire, Davide Nitti, Jonathan Masci, Amos Sironi
*   **🎯 研究目的**: 事件相机以其高时间精度、低数据速率和高动态范围的特性，特别适用于高运动、挑战性光照条件和需要低延迟的场景。然而，由于该领域相对较新，事件基系统在许多视觉任务上的性能仍低于传统帧基解决方案。主要原因包括：事件传感器空间分辨率较低、缺乏大规模训练数据集以及缺乏成熟的事件基深度学习架构。本研究旨在解决这些问题，特别是在事件基目标检测任务中。
*   **⭐ 主要发现**: 论文通过多方面努力显著提升了事件基目标检测的性能。首先，研究人员引入了首个百万像素事件相机，极大地提高了事件数据的空间分辨率。其次，他们构建了一个大规模的事件基目标检测数据集，弥补了训练数据不足的短板。最后，他们提出了一种新颖的深度学习架构，专门用于处理事件流数据，并优化其在目标检测任务中的表现。实验结果表明，结合高分辨率传感器、大规模数据集和优化的网络架构，事件基目标检测的性能得到了显著提升，缩小了与传统帧基方法的差距。这项工作为事件相机在实际应用中实现高性能目标检测奠定了坚实基础。

---

### [[Real-time Classification from Short Event-Camera Streams using Input-filtering Neural ODEs]](http://arxiv.org/abs/2004.03156v1)
<!-- 2020-04-07 -->
**📅 发布日期**: 2020-04-07

*   **👥 作者**: Giorgio Giannone, Asha Anoosheh, Alessio Quaglino, Pierluca D'Oro, Marco Gallieri, Jonathan Masci
*   **🎯 研究目的**: 事件相机是一种受人类视觉系统启发的新型高效传感器，能生成异步、像素级的事件流数据。通常，从这些数据中学习需要进行大量的预处理和事件集成到图像中，这可能需要缓冲长时间序列并限制推理系统的响应时间。本研究旨在提出一种新方法，直接使用DVS相机输出的事件流（亮度变化及其空间坐标）作为输入，用于实时分类，避免繁重的预处理和集成，从而实现更快的响应时间。
*   **⭐ 主要发现**: 论文提出了一种新颖的异步RNN-like架构，名为“输入过滤神经ODE”（Input-filtering Neural ODEs, INODE），可以直接处理事件相机产生的原始事件流数据，而无需进行耗时的预处理或帧化。INODE是神经ODE（NODE）的扩展，允许输入信号持续地馈入网络。这种方法利用了事件数据固有的稀疏性和异步性，实现了从短事件流中进行实时分类。实验结果表明，INODE在分类任务上表现出色，并且能够显著降低推理延迟，这对于需要快速响应的实时应用（如机器人控制或人机交互）至关重要。

---

### [[Exploration of Reinforcement Learning for Event Camera using Car-like Robots]](http://arxiv.org/abs/2004.00801v1)
<!-- 2020-04-02 -->
**📅 发布日期**: 2020-04-02

*   **👥 作者**: Riku Arakawa, Shintaro Shiba
*   **🎯 研究目的**: 本研究旨在首次展示事件相机在机器人强化学习中的应用。由于事件相机极低的延迟，与使用标准相机的现有视觉强化学习应用相比，它有可能实现更快的机器人控制。为了处理事件流数据进行强化学习，研究人员引入了一种图像状特征，并旨在验证在模拟器中训练智能体以完成快速避碰和障碍物跟踪两项任务的可行性。最终目标是将模拟器中训练的智能体迁移到真实世界的事件相机机器人上，以实现对随机抛掷物体的快速避碰。
*   **⭐ 主要发现**: 论文成功地展示了事件相机在机器人强化学习领域的首次应用。研究人员提出了一种将事件流转换为图像状特征的方法，使其能够被现有的强化学习算法处理。在模拟器中，智能体成功学会了快速避碰和障碍物跟踪任务。更重要的是，将模拟器中训练的智能体迁移到配备事件相机的真实世界机器人上后，该机器人能够成功地快速避开随机抛掷的物体。这项工作证明了事件相机结合强化学习在实现超低延迟、高动态机器人控制方面的巨大潜力，为机器人感知和自主导航开辟了新的方向。

---

### [[Learning to Exploit Multiple Vision Modalities by Using Grafted Networks]](http://arxiv.org/abs/2003.10959v3)
<!-- 2020-03-24 -->
**📅 发布日期**: 2020-03-24

*   **👥 作者**: Yuhuang Hu, Tobi Delbruck, Shih-Chii Liu
*   **🎯 研究目的**: 热成像、高光谱、偏振和事件相机等新型视觉传感器提供了传统强度相机无法获取的信息。然而，将这些传感器与当前强大的深度神经网络结合使用面临一个障碍：缺乏大规模的标注训练数据集。本研究旨在提出一种网络嫁接算法（Network Grafting Algorithm, NGA），通过将一个由非常规视觉输入驱动的新前端网络替换预训练深度网络中处理强度帧的前端网络，以克服数据稀缺问题，并利用自监督学习来最大化预训练网络和嫁接网络之间的特征相似性。
*   **⭐ 主要发现**: 论文提出了网络嫁接算法（NGA），这是一种创新的方法，用于在缺乏大规模标注数据集的情况下，将新型视觉传感器（如事件相机）的数据有效整合到现有的深度学习框架中。NGA通过自监督训练，仅利用同步记录的强度帧和新型传感器数据，最大化预训练网络和嫁接网络之间的特征相似性。实验结果表明，通过这种嫁接方法增强的网络，在平均精度（AP50）方面达到了与预训练网络相当甚至更优的性能，证明了NGA在利用多模态视觉信息方面的有效性。这项工作为在数据稀缺场景下，充分利用多种视觉模态的互补信息提供了通用且高效的解决方案。

---

### [[Event-based Asynchronous Sparse Convolutional Networks]](http://arxiv.org/abs/2003.09148v2)
<!-- 2020-03-20 -->
**📅 发布日期**: 2020-03-20

*   **👥 作者**: Nico Messikommer, Daniel Gehrig, Antonio Loquercio, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是受生物启发的传感器，以异步和稀疏的“事件”形式响应像素亮度变化。最近，模式识别算法，如基于学习的方法，通过将事件转换为同步密集、类似图像的表示并应用为标准相机开发的传统机器学习方法，在事件相机领域取得了显著进展。然而，这些方法以更高的计算复杂度和延迟为代价，丢弃了事件数据固有的空间和时间稀疏性。本研究旨在提出一个通用框架，将训练在同步图像状事件表示上的模型转换为具有相同输出的异步模型，从而直接利用事件数据固有的异步和稀疏特性。
*   **⭐ 主要发现**: 论文提出了一个通用框架，用于构建事件基异步稀疏卷积网络。该框架的核心思想是将传统上在同步、密集图像表示上训练的模型，转换成能够直接处理异步、稀疏事件数据的模型，同时保持相同的输出。通过这种转换，模型能够充分利用事件数据固有的空间和时间稀疏性，从而显著降低计算复杂度和处理延迟。实验结果表明，所提出的异步稀疏卷积网络在保持与同步方法相当的性能的同时，展现出更高的效率。这项工作为事件相机数据处理提供了一种更符合其数据特性的深度学习范式，对于开发低功耗、低延迟的实时视觉系统具有重要意义。

---

### [[Spike-FlowNet: Event-based Optical Flow Estimation with Energy-Efficient Hybrid Neural Networks]](http://arxiv.org/abs/2003.06696v3)
<!-- 2020-03-14 -->
**📅 发布日期**: 2020-03-14

*   **👥 作者**: Chankyu Lee, Adarsh Kumar Kosta, Alex Zihao Zhu, Kenneth Chaney, Kostas Daniilidis, Kaushik Roy
*   **🎯 研究目的**: 事件相机在高速运动检测和低光环境导航等任务中显示出巨大潜力，而传统帧基相机在这些场景下表现不佳。这归因于事件相机的高时间分辨率、高动态范围和低功耗。然而，传统的计算机视觉方法以及深度模拟神经网络（ANNs）不适合处理事件相机输出的异步和离散性质。脉冲神经网络（SNNs）是处理事件相机输出的理想范式，但深度SNNs因“脉冲消失”现象而在性能上受限。本研究旨在提出Spike-FlowNet，一个深度混合神经网络架构，整合SNNs和ANNs，以高效估计光流并克服这些问题。
*   **⭐ 主要发现**: 论文提出了Spike-FlowNet，一种新颖的深度混合神经网络架构，它创造性地整合了脉冲神经网络（SNNs）和模拟神经网络（ANNs）的优势，用于高效的事件基光流估计。该架构旨在克服深度SNNs中“脉冲消失”的性能瓶颈，同时充分利用SNNs处理事件相机异步、离散数据的固有优势。通过这种混合设计，Spike-FlowNet能够实现高精度的光流估计，并且显著降低了能量消耗。实验结果表明，Spike-FlowNet在各种场景下都表现出卓越的性能和能效，使其成为高动态、低功耗视觉感知任务的理想选择，例如在自主机器人和可穿戴设备中。

---

### [[Event-Based Angular Velocity Regression with Spiking Networks]](http://arxiv.org/abs/2003.02790v1)
<!-- 2020-03-05 -->
**📅 发布日期**: 2020-03-05

*   **👥 作者**: Mathias Gehrig, Sumit Bam Shrestha, Daniel Mouritzen, Davide Scaramuzza
*   **🎯 研究目的**: 脉冲神经网络（SNNs）是受生物启发的网络，以时间脉冲而非数值传递信息。SNN的脉冲神经元仅在短时间内出现大量脉冲时才产生脉冲。由于其基于脉冲的计算模型，SNNs无需任何预处理即可处理事件基、异步传感器输出，且功耗极低，这得益于在硅中实现高度并行化SNN概念的专用神经形态硬件。然而，SNNs尚未像人工神经网络那样普及，部分原因是其输入格式非传统，也因为训练SNNs存在挑战。本研究旨在探索SNNs在事件基角速度回归任务中的应用，并解决其训练挑战。
*   **⭐ 主要发现**: 论文成功地展示了脉冲神经网络（SNNs）在事件基角速度回归任务中的有效性。研究人员提出了一种方法，使得SNNs能够直接处理事件相机产生的异步事件流，而无需进行传统的预处理或帧化。他们还解决了SNNs训练中的一些关键挑战，使其能够学习从事件数据中准确回归出物体的角速度。这项工作不仅证明了SNNs在处理事件数据方面的固有优势，如极低功耗和实时响应，而且为SNNs在需要高时间分辨率和低延迟的机器人感知和控制任务中的应用提供了新的途径。

---

### [[Matching Neuromorphic Events and Color Images via Adversarial Learning]](http://arxiv.org/abs/2003.00636v1)
<!-- 2020-03-02 -->
**📅 发布日期**: 2020-03-02

*   **👥 作者**: Fang Xu, Shijie Lin, Wen Yang, Lei Yu, Dengxin Dai, Gui-song Xia
*   **🎯 研究目的**: 事件相机具有高动态范围、低延迟、低功耗和低内存使用等吸引人的特性，与传统帧基相机形成互补。它只捕捉场景的动态信息，能够捕捉几乎“连续”的运动。然而，与反映场景整体外观的帧基相机不同，事件相机舍弃了物体的详细特征，如纹理和颜色。为了结合两种模态的优势，事件相机和帧基相机常被结合用于各种机器视觉任务。因此，神经形态事件和彩色图像之间的跨模态匹配变得至关重要。本研究旨在提出事件基图像检索（EBIR）问题，并利用对抗学习来解决这一跨模态匹配挑战。
*   **⭐ 主要发现**: 论文提出了事件基图像检索（EBIR）问题，旨在通过跨模态匹配将神经形态事件数据与传统彩色图像关联起来。为了解决这一挑战，研究人员创新性地引入了对抗学习框架。该框架训练一个生成器来学习事件数据和图像数据之间的映射关系，同时训练一个判别器来区分真实匹配和虚假匹配。通过对抗训练，模型能够学习到两种模态之间潜在的共享表示，从而实现高效准确的跨模态匹配。实验结果表明，所提出的对抗学习方法在EBIR任务上取得了显著的性能，为融合事件相机和传统相机数据以实现更全面、鲁棒的场景理解提供了有效途径，尤其在需要结合动态信息和外观细节的应用中。

---

### [[Inceptive Event Time-Surfaces for Object Classification Using Neuromorphic Cameras]](http://arxiv.org/abs/2002.11656v1)
<!-- 2020-02-26 -->
**📅 发布日期**: 2020-02-26

*   **👥 作者**: R Wes Baldwin, Mohammed Almatrafi, Jason R Kaufman, Vijayan Asari, Keigo Hirakawa
*   **🎯 研究目的**: 本研究旨在提出一种新颖的低级方法融合，用于神经形态相机数据中的高层对象分类，称之为“初始事件时间表面”（Inceptive Event Time-Surfaces, IETS）。IETS旨在克服传统时间表面（time-surfaces）的几个局限性，通过提高对噪声的鲁棒性、促进空间一致性以及改善（移动）边缘的时间定位，从而为事件相机数据中的对象分类提供更有效的方法。
*   **⭐ 主要发现**: 论文提出了“初始事件时间表面”（IETS）这一新颖概念，它通过融合低级方法实现了事件相机数据中高层对象分类的有效提升。IETS克服了传统时间表面在处理噪声、空间一致性和时间定位方面的不足，显著提高了对噪声的鲁棒性，并更好地保持了空间连贯性，同时更精确地定位了移动边缘。研究结果表明，将IETS与迁移学习相结合，在事件相机数据上具有挑战性的对象分类问题上，取得了超越现有技术水平的性能。这项工作为事件相机数据处理提供了一种更鲁棒、更精确的特征表示方法，极大地推动了神经形态视觉在对象识别领域的应用。

---

### [[A Large Scale Event-based Detection Dataset for Automotive]](http://arxiv.org/abs/2001.08499v3)
<!-- 2020-01-23 -->
**📅 发布日期**: 2020-01-23

*   **👥 作者**: Pierre de Tournemire, Davide Nitti, Etienne Perot, Davide Migliore, Amos Sironi
*   **🎯 研究目的**: 尽管事件相机在汽车领域具有巨大潜力，但缺乏大规模、标注完善的事件基数据集是其发展的主要障碍。本研究旨在发布首个用于事件相机的超大规模检测数据集，以促进事件基视觉任务（如目标检测和分类）的重大进展，并期望对光流、运动结构和跟踪等其他任务也带来益处。
*   **⭐ 主要发现**: 论文发布了首个超大规模事件基检测数据集，专门针对汽车应用。该数据集包含超过39小时的汽车行驶记录，由304x240分辨率的ATIS传感器采集，涵盖了城市、高速公路、郊区和乡村等多种驾驶场景，以及不同的天气和光照条件。数据集中提供了超过255,000个汽车和行人边界框标注，标注频率在1到4Hz之间。这一大规模、多样化的标注数据集的发布，极大地弥补了事件相机领域数据稀缺的空白，为研究人员开发和评估事件基目标检测和分类算法提供了前所未有的资源，有望推动事件基视觉在自动驾驶等领域的快速发展。

---

### [[Exploiting Event Cameras for Spatio-Temporal Prediction of Fast-Changing Trajectories]](http://arxiv.org/abs/2001.01248v2)
<!-- 2020-01-05 -->
**📅 发布日期**: 2020-01-05

*   **👥 作者**: Marco Monforte, Ander Arriandiaga, Arren Glover, Chiara Bartolozzi
*   **🎯 研究目的**: 本研究旨在探索轨迹预测在机器人领域的应用，以改善机器人与移动目标（如接住弹跳球）的交互。意外的、高度非线性的轨迹难以通过基于回归的拟合程序进行预测，因此研究人员计划应用最先进的机器学习技术，特别是基于长短期记忆（LSTM）架构。此外，由于事件相机能够产生由空间变化触发的异步输出，而非传统相机那样以固定时间间隔输出，因此它更适合感知快速移动的目标。本研究将探讨如何将LSTM模型适应事件相机数据，并特别关注使用异步采样数据所带来的益处。
*   **⭐ 主要发现**: 论文成功地利用事件相机和长短期记忆（LSTM）网络实现了对快速变化轨迹的时空预测。研究人员证明，事件相机产生的异步数据流非常适合捕捉高速运动目标的动态信息，而LSTM模型能够有效地处理这种时间序列数据。通过将LSTM模型适应事件相机数据，并利用其异步采样的特性，系统能够对高度非线性的轨迹进行准确预测，这对于机器人与动态环境的实时交互至关重要，例如在抓取快速移动物体等任务中。这项工作突出了事件相机在需要高时间分辨率和低延迟的预测任务中的独特优势，为机器人控制和人机协作提供了新的解决方案。

---
### [EvAn: Neuromorphic Event-based Anomaly Detection]](http://arxiv.org/abs/1911.09722v2)
<!-- 2019-11-21 -->
**📅 发布日期**: 2019-11-21

*   **👥 作者**: Lakshmi Annamalai, Anirban Chakraborty, Chetan Singh Thakur
*   **🎯 研究目的**: 事件相机作为一种仿生新型传感器，通过异步记录光照变化来生成事件流，与传统相机相比，具有低功耗、高动态范围和无运动模糊等显著优势。其独特之处在于仅编码场景与传感器之间的相对运动，从而产生非常稀疏的数据结构，这对于各种运动分析任务极具潜力。本研究旨在首次将事件相机的这些优势应用于一个关键的计算机视觉应用——视频异常检测，以克服传统相机在复杂场景下进行异常检测的局限性。
*   **⭐ 主要发现**: 本文首次在事件数据分析领域中，利用事件相机的独特优势进行视频异常检测。研究人员提出了一种新颖的方法，通过双判别器条件生成对抗网络（GAN）来建模事件域中的运动动力学。这种方法能够有效捕捉事件流中蕴含的运动模式，并识别出与正常模式不符的异常行为。实验结果表明，所提出的EvAn模型能够有效利用事件数据的稀疏性和高时间分辨率特性，在低功耗和高动态范围场景下实现鲁棒的异常检测，为基于事件的视觉系统在安全监控和智能交通等领域的应用奠定了基础。

---

### [Event-based Vision: A Survey]](http://arxiv.org/abs/1904.08405v3)
<!-- 2019-04-17 -->
**📅 发布日期**: 2019-04-17

*   **👥 作者**: Guillermo Gallego, Tobi Delbruck, Garrick Orchard, Chiara Bartolozzi, Brian Taba, Andrea Censi, Stefan Leutenegger, Andrew Davison, Joerg Conradt, Kostas Daniilidis, Davide Scaramuzza
*   **🎯 研究目的**: 传统帧相机以固定帧率捕获图像，而事件相机作为一种仿生传感器，则异步测量每个像素的亮度变化，并输出编码时间、位置和亮度变化符号的事件流。这种独特的传感范式赋予了事件相机诸多吸引人的特性，包括微秒级的高时间分辨率、极高的动态范围（140 dB 对比传统相机的 60 dB）、低功耗以及高像素带宽（kHz 级别），从而显著减少运动模糊。本综述旨在全面概述事件相机的工作原理、独特优势及其在机器人和计算机视觉领域中的巨大潜力，尤其是在传统相机难以应对的低延迟、高速运动和高动态范围等挑战性场景。
*   **⭐ 主要发现**: 本文作为事件视觉领域的首篇综合性综述，详细阐述了事件相机与传统帧相机的根本区别及其带来的独特优势。它系统地总结了事件相机的数据表示方式、现有处理方法和应用领域。综述强调，尽管事件相机潜力巨大，但其异步、稀疏的数据流需要全新的处理方法，传统的基于帧的计算机视觉算法无法直接应用。文章深入探讨了事件相机在机器人导航、高速运动估计、低光照环境感知等方面的应用前景，并指出了该领域未来研究的挑战和方向，为研究人员提供了全面的参考框架。

---

### [Focus Is All You Need: Loss Functions For Event-based Vision]](http://arxiv.org/abs/1904.07235v1)
<!-- 2019-04-15 -->
**📅 发布日期**: 2019-04-15

*   **👥 作者**: Guillermo Gallego, Mathias Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是一种新型视觉传感器，其输出不是传统的视频帧，而是像素级的亮度变化（“事件”）。这些异步传感器具有高时间分辨率、极高动态范围和无运动模糊等显著优势。为了充分发挥这类传感器的潜力，近年来研究者们提出了多种运动补偿方法。本研究旨在系统地收集并分类用于分析运动补偿方法中事件对齐效果的客观函数，并深入探讨这些函数的特性、准确性和运行时间，从而为事件相机的数据处理引入成熟的计算机视觉工具。
*   **⭐ 主要发现**: 本文提出并分类了二十二种客观函数，用于分析事件相机运动补偿方法中的事件对齐效果。这些函数被命名为“焦点损失函数”，因为它们与传统“形状-从-焦点”（shape-from-focus）应用中使用的函数具有很强的关联性。通过引入这些损失函数，研究人员能够将传统计算机视觉领域中成熟的优化和评估工具引入到事件相机的数据处理中。论文对这些损失函数的准确性和运行时间进行了详细比较和评估，为事件相机运动补偿算法的设计和优化提供了宝贵的指导，是事件视觉领域从数据采集向高级处理迈进的重要一步。

---

### [Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling]](http://arxiv.org/abs/1904.03375v1)
<!-- 2019-04-06 -->
**📅 发布日期**: 2019-04-06

*   **👥 作者**: Jiancheng Yang, Qiang Zhang, Bingbing Ni, Linguo Li, Jinxian Liu, Mengdie Zhou, Qi Tian
*   **🎯 研究目的**: 随着3D传感器的普及，几何深度学习在处理点云数据方面变得越来越重要。受自然语言处理（NLP）领域中自注意力Transformer最新进展的启发，本研究旨在将自注意力机制引入点云处理，以克服传统方法在处理点云数据时面临的挑战，如点云的无序性、稀疏性和大小可变性。同时，针对现有方法在点云子集采样中依赖启发式规则（如最远点采样）的问题，本研究旨在开发一种端到端可学习且与任务无关的采样操作，以更有效地选择具有代表性的点云子集。
*   **⭐ 主要发现**: 本文提出了点注意力Transformer（PATs），该模型利用参数高效的组混洗注意力（Group Shuffle Attention, GSA）来替代计算成本较高的多头注意力，从而有效地处理大小可变的输入点云，并证明了其置换等变性。更重要的是，研究首次提出了一种端到端可学习且与任务无关的采样操作——Gumbel子集采样（Gumbel Subset Sampling, GSS）。GSS能够通过学习的方式选择具有代表性的输入点子集，克服了以往依赖启发式采样方法的局限性，使得点云处理模型能够更好地适应不同的任务和数据分布。实验结果验证了PATs和GSS在点云分类、分割等任务上的优越性能和泛化能力。

---

### [EventNet: Asynchronous Recursive Event Processing]](http://arxiv.org/abs/1812.07045v2)
<!-- 2018-12-07 -->
**📅 发布日期**: 2018-12-07

*   **👥 作者**: Yusuke Sekikawa, Kosuke Hara, Hideo Saito
*   **🎯 研究目的**: 事件相机是一种仿生视觉传感器，模仿视网膜的工作方式，异步报告每个像素的强度变化，而非以固定间隔输出实际强度图像。这种新的图像传感器范式提供了显著的潜在优势，即稀疏和非冗余的数据表示。然而，大多数现有的神经网络架构，如卷积神经网络（CNN），需要密集的同步输入数据，因此无法有效利用事件数据的稀疏性。本研究旨在提出一种新的神经网络架构，能够以递归和事件级别的方式实时处理异步事件流，从而充分利用事件相机的独特数据特性。
*   **⭐ 主要发现**: 本文提出了EventNet，一个专为实时处理异步事件流而设计的神经网络。EventNet通过一种新颖的时间编码方案，以递归方式建模输出对数万个因果事件的依赖关系。这意味着EventNet能够逐个事件地处理数据，而不是等待积累成帧。这种设计使得EventNet能够充分利用事件数据的稀疏性和高时间分辨率，显著降低计算和内存开销，同时保持高精度。实验结果表明，EventNet在处理事件流数据方面表现出卓越的实时性能和准确性，为基于事件的视觉系统在低延迟、高效率应用中开辟了新的可能性。

---

### [Event-based Vision meets Deep Learning on Steering Prediction for Self-driving Cars]](http://arxiv.org/abs/1804.01310v1)
<!-- 2018-04-04 -->
**📅 发布日期**: 2018-04-04

*   **👥 作者**: Ana I. Maqueda, Antonio Loquercio, Guillermo Gallego, Narciso Garcia, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是一种仿生视觉传感器，能够自然地捕捉场景的动态变化并过滤掉冗余信息，这使其在处理高速运动和极端光照条件方面具有独特优势。自动驾驶汽车的转向角预测是一个极具挑战性的运动估计任务，对感知系统的鲁棒性要求极高。本研究旨在探索将事件相机的独特优势与深度学习技术相结合，以提高自动驾驶汽车在复杂和挑战性场景下的转向预测能力，克服传统相机在这些条件下的局限性。
*   **⭐ 主要发现**: 本文提出了一种深度神经网络方法，将最先进的卷积架构适应于事件传感器的输出，以实现车辆转向角的精确预测。研究团队在一个公开可用的、大规模事件相机数据集（约1000公里）上对所提出的方法进行了广泛的性能评估。通过定性和定量分析，论文详细解释了为什么事件相机能够实现鲁棒的转向预测，即使在传统相机失效的极端情况（如挑战性光照条件和快速运动）下也能表现出色。这项工作首次证明了事件相机在自动驾驶转向预测任务中的巨大潜力，为未来自动驾驶系统在恶劣环境下的感知和决策提供了新的解决方案。

---

### [NullHop: A Flexible Convolutional Neural Network Accelerator Based on Sparse Representations of Feature Maps]](http://arxiv.org/abs/1706.01406v2)
<!-- 2017-06-05 -->
**📅 发布日期**: 2017-06-05

*   **👥 作者**: Alessandro Aimar, Hesham Mostafa, Enrico Calabrese, Antonio Rios-Navarro, Ricardo Tapiador-Morales, Iulia-Alexandra Lungu, Moritz B. Milde, Federico Corradi, Alejandro Linares-Barranco, Shih-Chii Liu, Tobi Delbruck
*   **🎯 研究目的**: 卷积神经网络（CNNs）已成为解决许多最先进视觉处理任务的主导神经网络架构。尽管图形处理单元（GPUs）最常用于CNN的训练和部署，但其单帧运行时推理的能效通常低于10 GOp/s/W，这对于低功耗和低延迟的应用场景来说是一个显著的瓶颈。本研究旨在提出一种灵活高效的CNN加速器架构，能够充分利用CNN中神经元激活的稀疏性，以实现高能效和低延迟的计算，从而满足边缘设备和实时应用的需求。
*   **⭐ 主要发现**: 本文提出了一种名为NullHop的灵活高效CNN加速器架构，专门为低功耗和低延迟应用场景实现最先进的CNN而设计。NullHop的核心创新在于其能够有效利用CNN中神经元激活的稀疏性，从而显著加速计算并减少内存需求。该架构的灵活性允许在从1x1到7x7的各种内核尺寸下实现高计算资源利用率。NullHop能够处理多达128个输入和128个输出特征图，展现出强大的处理能力。实验结果表明，NullHop在能效和延迟方面均优于现有解决方案，为部署在资源受限设备上的实时CNN推理提供了高性能、低功耗的硬件加速方案。

---

---

## 生成说明
- 本报告由AI模型自动生成，摘要内容仅供参考。
- 如有错误或遗漏，请以原始论文为准。
