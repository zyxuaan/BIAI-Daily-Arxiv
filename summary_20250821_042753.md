---
layout: default
title: 2025-08-21 Arxiv论文摘要
---

# Arxiv论文总结报告

## 基本信息
- 生成时间: 2025-08-21 12:28:06
- 使用模型: gemini-2.5-flash
- 论文数量: 2 篇

---

## 论文总结

### [[EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention]](http://arxiv.org/abs/2508.14856v1)
<!-- 2025-08-20 -->
**📅 发布日期**: 2025-08-20

*   **👥 作者**: Lakshmi Annamalai, Chetan Singh Thakur
*   **🎯 研究目的**: 自动驾驶车辆的道路分割是核心技术之一，但使用传统帧式相机实现低延迟和低计算量的解决方案仍面临挑战。事件相机因其独特的低功耗感知特性，提供了一种有前景的替代方案。然而，利用纯事件计算进行道路分割时，难以直接迁移传统相机域的预训练权重，且事件数据标注成本高昂、数据稀缺。本研究旨在开发一种基于事件相机的道路分割方法，克服对大量标注数据的依赖，实现高效、低功耗的道路分割。
*   **⭐ 主要发现**: 本文提出了EventSSEG，一种创新的道路分割方法，它完全基于事件计算并结合了概率注意力机制。为了解决事件数据标注稀缺的问题，EventSSEG引入了基于事件的自监督学习范式，从而显著减少了对大量标注数据的需求。在DSEC-Semantic和DDD17数据集上进行的实验结果表明，EventSSEG在仅使用少量标注事件的情况下，仍能达到最先进（state-of-the-art）的性能。这一方法最大化了事件相机的固有优势，为自动驾驶领域提供了高效、低延迟且数据高效的道路分割解决方案。

---

### [[6-DoF Object Tracking with Event-based Optical Flow and Frames]](http://arxiv.org/abs/2508.14776v1)
<!-- 2025-08-20 -->
**📅 发布日期**: 2025-08-20

*   **👥 作者**: Zhichao Li, Arren Glover, Chiara Bartolozzi, Lorenzo Natale
*   **🎯 研究目的**: 在机器人技术中，实时跟踪物体的空间位置和姿态（即6自由度，6-DoF）是实现环境交互的基础问题。当物体高速移动时，由于传统相机的帧率限制和运动模糊，这一任务变得更具挑战性。事件相机以其高时间分辨率、低延迟和高动态范围的特点，有望克服运动模糊的影响。与此同时，传统RGB相机能够提供丰富的视觉信息，更适合进行单次物体姿态估计的复杂任务。本研究旨在结合这两种视觉传感器的优势，提出一种新的6-DoF物体跟踪方法，以应对高速运动物体的跟踪需求。
*   **⭐ 主要发现**: 本文提出了一种创新的方法，将基于事件的流光流与基于RGB的全局物体姿态估计器相结合，用于高速运动物体的6-DoF姿态跟踪。该方法充分利用了事件相机在处理高速运动和避免运动模糊方面的核心优势，以及RGB相机在提供丰富视觉信息以进行单次姿态估计方面的能力。通过融合这两种传感器的互补特性，所提出的方法能够实现对高速物体的鲁棒、实时的6-DoF跟踪。这一混合视觉感知策略为机器人与环境的精确、高效交互提供了新的解决方案。

---

---

## 生成说明
- 本报告由AI模型自动生成，摘要内容仅供参考。
- 如有错误或遗漏，请以原始论文为准。
