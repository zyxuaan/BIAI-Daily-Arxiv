---
layout: default
title: 2025-07-10 Arxiv论文摘要
---

# Arxiv论文总结报告

## 基本信息
- 生成时间: 2025-07-10 12:42:56
- 使用模型: gemini-2.5-flash
- 论文数量: 147 篇

---

## 论文总结

### 1. [[EA: An Event Autoencoder for High-Speed Vision Sensing]](http://arxiv.org/abs/2507.06459v1)
<!-- 2025-07-09 -->
**📅 发布日期**: 2025-07-09

*   **👥 作者**: Riadul Islam, Joey Mulé, Dhandeep Challagundla, Shahmir Rizvi, Sean Carson
*   **🎯 研究目的**: 高速视觉感知对于机器人、自动驾驶汽车和工业自动化等应用的实时感知至关重要。传统的基于帧的视觉系统存在运动模糊、高延迟和冗余数据处理等问题，限制了它们在动态环境中的性能。事件相机作为一种有前景的替代方案，能够以像素级捕获异步亮度变化，但其稀疏和嘈杂的事件流给目标检测带来了挑战
### 21. [[EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation]](http://arxiv.org/abs/2503.18552v2)
<!-- 2025-03-24 -->
**📅 发布日期**: 2025-03-24

*   **👥 作者**: Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu
*   **🎯 研究目的**: 传统的条件式人体动画通常使用从视频数据中提取的基于姿态的运动线索来驱动静态参考图像的动画化。然而，这些视频衍生的线索常受限于低时间分辨率、运动模糊以及在挑战性光照条件下的不可靠性能。本研究旨在利用事件相机固有的鲁棒、高时间分辨率的运动信息，克服传统方法的这些局限性，首次提出一种基于事件流的条件式人体图像动画生成方法。
*   **⭐ 主要发现**: 本文提出了EvAnimate，这是首个利用事件流作为鲁棒精确运动线索进行条件式人体图像动画的方法。该方法通过将异步事件数据编码为专门的三通道表示，并采用自适应时间窗口策略，使其与基于扩散的生成模型完全兼容。实验证明，EvAnimate在处理运动模糊、低光照环境和曝光变化方面表现出卓越的鲁棒性和性能，显著提升了人体动画的质量和可靠性。

---

### 22. [[Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras]](http://arxiv.org/abs/2503.17262v1)
<!-- 2025-03-21 -->
**📅 发布日期**: 2025-03-21

*   **👥 作者**: Shuang Guo, Friedhelm Hamann, Guillermo Gallego
*   **🎯 研究目的**: 事件相机依赖运动来获取场景外观信息，这意味着运动和外观是同时被捕获或同时缺失的，并编码在输出事件流中。现有工作通常将光流（运动）和图像强度（外观）的恢复视为独立任务，这与事件相机的本质不符，并忽略了两者之间的内在联系。本研究旨在提出一个无监督学习框架，通过单个网络联合估计光流和图像强度，以更好地利用事件相机的特性。
*   **⭐ 主要发现**: 本文从事件生成模型出发，首次推导了基于事件的光度误差，该误差是光流和图像强度的函数，并将其与对比度最大化框架结合，形成了一个全面的损失函数。这一创新性的损失函数使得通过单个网络进行光流和图像强度的联合无监督学习成为可能。实验结果表明，该方法在各种场景下均能有效且准确地估计光流和图像强度，验证了联合学习策略的优越性。

---

### 23. [[Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition]](http://arxiv.org/abs/2503.17132v3)
<!-- 2025-03-21 -->
**📅 发布日期**: 2025-03-21

*   **👥 作者**: Siyuan Yang, Shilin Lu, Shizheng Wang, Meng Hwa Er, Zengwei Zheng, Alex C. Kot
*   **🎯 研究目的**: 本文旨在探索脉冲神经网络（SNNs）与事件相机在隐私保护人体动作识别（HAR）中的协同作用。事件相机捕捉运动轮廓的独特能力与SNN处理时空数据的专长高度兼容。然而，SNNs在处理长期时间信息方面的局限性是实现精确HAR的关键挑战。本研究旨在引入新的框架来解决这一问题，以提升SNNs在事件流HAR中的长期时间信息处理能力。
*   **⭐ 主要发现**: 本文提出了两种新颖的框架来解决SNNs处理长期时间信息的限制：基于时间片段的SNN（TS-SNN）和3D卷积SNN（3D-SNN）。TS-SNN通过将动作划分为更短的片段来提取长期时间信息，而3D-SNN则通过3D卷积层直接处理时空数据。实验结果表明，这些方法显著提升了SNNs在事件流HAR任务上的性能，验证了其在捕捉和利用长期时间依赖性方面的有效性。

---

### 24. [[ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and Spiking Neural Network]](http://arxiv.org/abs/2503.09985v2)
<!-- 2025-03-13 -->
**📅 发布日期**: 2025-03-13

*   **👥 作者**: Qiang Zhang, Jiahang Cao, Jingkai Sun, Yecheng Shao, Gang Han, Wen Zhao, Yijie Guo, Renjing Xu
*   **🎯 研究目的**: 近年来四足机器人技术在感知和运动控制方面取得了显著进展，但视觉传感器如深度相机仍面临操作频率低、对光照敏感等问题，限制了其在户外复杂环境中的部署。此外，深度神经网络计算需求高。本研究旨在引入脉冲神经网络（SNNs）和事件相机，以解决这些挑战，使四足机器人能够执行更具挑战性的跑酷任务。
*   **⭐ 主要发现**: 本文成功将事件相机和SNNs应用于四足机器人跑酷任务。事件相机能够捕捉高动态视觉数据，而SNNs则能高效处理脉冲序列，模拟生物感知。实验结果表明，这种生物启发的方法显著提升了机器人在复杂环境中的感知和运动控制能力，尤其是在低光照和快速运动场景下。这为未来机器人系统在恶劣条件下的鲁棒性和自主性提供了新的方向。

---

### 25. [[Helios 2.0: A Robust, Ultra-Low Power Gesture Recognition System Optimised for Event-Sensor based Wearables]](http://arxiv.org/abs/2503.07825v1)
<!-- 2025-03-10 -->
**📅 发布日期**: 2025-03-10

*   **👥 作者**: Prarthana Bhattacharyya, Joshua Mitton, Ryan Page, Owen Morgan, Oliver Powell, Benjamin Menzies, Gabriel Homewood, Kemi Jacobs, Paolo Baesso, Taru Muhonen, Richard Vigars, Louis Berridge
*   **🎯 研究目的**: 尽管计算机视觉中的手势识别技术取得了显著进展，但在创建直观、适应多样用户和环境、且足够节能以用于实际可穿戴应用方面仍面临关键挑战。本研究旨在开发一种针对事件传感器可穿戴设备优化的、鲁棒、超低功耗的实时手势识别系统，以显著改善智能眼镜的用户体验。
*   **⭐ 主要发现**: 本文提出了Helios 2.0，一个移动优化的实时超低功耗事件相机系统，实现了智能眼镜的自然手势控制。该系统通过精心选择的微手势（如拇指在食指上的横向滑动和拇指与食指尖的双捏）来解决现有挑战，这些手势利用了自然手部动作，确保了直观可用性。Helios 2.0在功耗、延迟和识别准确性之间取得了卓越平衡，展示了其在实际可穿戴设备中实现无缝、节能手势交互的巨大潜力。

---

### 26. [[Sign Language Translation using Frame and Event Stream: Benchmark Dataset and Algorithms]](http://arxiv.org/abs/2503.06484v1)
<!-- 2025-03-09 -->
**📅 发布日期**: 2025-03-09

*   **👥 作者**: Xiao Wang, Yuehang Li, Fuling Wang, Bo Jiang, Yaowei Wang, Yonghong Tian, Jin Tang, Bin Luo
*   **🎯 研究目的**: 准确的手语理解对于残障人士的沟通至关重要。当前的手语翻译算法主要依赖RGB帧，但其受限于固定帧率、可变光照条件和快速手部运动导致的运动模糊。受事件相机在其他领域成功应用的启发，本研究旨在利用事件流辅助RGB相机捕获手势数据，以解决上述挑战，并构建一个大规模RGB-事件手语翻译基准数据集。
*   **⭐ 主要发现**: 本文首次提出了一个大规模RGB-事件手语翻译数据集VECSL，该数据集使用DVS346相机采集，包含15,676个RGB-事件样本、15,191个手语词汇和2,568个汉字，涵盖了多种场景和光照条件。通过结合事件流，VECSL数据集能够有效缓解传统RGB数据在光照变化和运动模糊下的局限性。此外，本文还提供了基线算法，为未来的手语翻译研究提供了新的方向和资源。

---

### 27. [[SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks]](http://arxiv.org/abs/2503.08703v2)
<!-- 2025-03-09 -->
**📅 发布日期**: 2025-03-09

*   **👥 作者**: Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao, Jieyuan Zhang, Kexin Shi, Jingzhinan Wang, Jason K. Eshraghian, Haicheng Qu, Jiqing Zhang, Malu Zhang, Yang Yang
*   **🎯 研究目的**: 事件相机因其卓越的时间分辨率、动态范围、能效和像素带宽，与脉冲神经网络（SNNs）通过离散脉冲信号自然互补，使其成为事件追踪的理想选择。然而，当前结合人工神经网络（ANNs）和SNNs的方法，以及次优的架构，损害了能效并限制了追踪性能。本研究旨在解决这些限制，提出首个基于Transformer的脉冲驱动追踪管线。
*   **⭐ 主要发现**: 本文提出了SDTrack，首个基于Transformer的脉冲驱动追踪管线。其核心创新是“全局轨迹提示”（Global Trajectory Prompt, GTP）方法，该方法能有效捕获全局轨迹信息并将其与事件流聚合到事件图像中，以增强时空表示。SDTrack包含一个基于Transformer的脉冲驱动追踪器，通过优化架构，显著提升了事件追踪的性能，同时保持了SNNs固有的高能效优势。实验结果验证了SDTrack在事件追踪任务上的优越性和鲁棒性。

---

### 28. [[ERetinex: Event Camera Meets Retinex Theory for Low-Light Image Enhancement]](http://arxiv.org/abs/2503.02484v1)
<!-- 2025-03-04 -->
**📅 发布日期**: 2025-03-04

*   **👥 作者**: Xuejian Guo, Zhiqiang Tian, Yuehang Wang, Siqi Li, Yu Jiang, Shaoyi Du, Yue Gao
*   **🎯 研究目的**: 低光照图像增强旨在恢复在黑暗场景中捕获的曝光不足图像。在这些场景下，传统基于帧的相机由于曝光时间限制，可能无法捕获结构和颜色信息。事件相机作为生物启发式视觉传感器，能异步响应像素级亮度变化，其高动态范围对于极端低光照环境下的视觉感知至关重要。本研究旨在将Retinex理论与事件相机结合，提出一种新颖的低光照图像恢复方法。
*   **⭐ 主要发现**: 本文受Retinex理论在传统帧图像低光照恢复中成功的启发，首次提出了将Retinex理论与事件相机结合的方法，并提出了一种新颖的基于Retinex的低光照图像恢复框架ERetinex。该方法充分利用了事件相机在高动态范围和异步特性方面的优势，有效解决了传统相机在低光照下的局限性。实验结果表明，ERetinex能够显著提升低光照图像的质量，恢复出更丰富的结构和颜色信息，为挑战性暗环境下的视觉应用提供了新的解决方案。

---

### 29. [[EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition]](http://arxiv.org/abs/2502.09020v1)
<!-- 2025-02-13 -->
**📅 发布日期**: 2025-02-13

*   **👥 作者**: Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang
*   **🎯 研究目的**: 主流场景文本识别（STR）算法主要基于RGB相机开发，但它们对低光照、运动模糊和杂乱背景等挑战性因素敏感。本研究旨在利用生物启发式事件相机来识别场景文本，通过收集和标注一个大规模基准数据集，并提出新的事件流STR框架，以克服传统方法的局限性。
*   **⭐ 主要发现**: 本文收集并标注了一个大规模基准数据集EventSTR，用于基于事件流的场景文本识别，其中包含9,928个高分辨率（1280*720）事件样本，涵盖中英文文字。EventSTR数据集的发布为未来研究提供了丰富的资源。此外，本文提出了一个新的基于事件的场景文本识别框架SimC-ESTR，它首先使用视觉编码器提取事件特征，并通过Q-former模块将其投影为tokens。SimC-ESTR在EventSTR数据集上进行了基准测试，并展示了其在复杂场景下识别文本的潜力，为事件相机在STR领域的应用奠定了基础。

---

### 30. [[Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media]](http://arxiv.org/abs/2501.03874v2)
<!-- 2025-01-07 -->
**📅 发布日期**: 2025-01-07

*   **👥 作者**: Ning Zhang, Timothy Shea, Arto Nurmikko
*   **🎯 研究目的**: 追踪和同时获取被强散射介质遮挡的随机移动目标的图像，对于许多需要精确物体定位和识别的应用来说，仍然是一个具有挑战性的问题。本研究旨在开发一种端到端的神经形态光学工程和计算方法，结合事件检测相机和多阶段神经形态深度学习策略，以实现对通常不可见物体的追踪和成像。
*   **⭐ 主要发现**: 本文提出了一种创新的神经形态光学工程和计算方法。该方法首先利用事件相机检测从散射介质中发出的光子，并将其转换为像素级的异步脉冲序列，从而初步分离出目标特异性信息。随后，这些脉冲数据被输入到一个深度脉冲神经网络（SNN）引擎中，用于进一步处理和识别目标。实验证明，该系统能够成功追踪并成像被强散射介质遮挡的随机移动目标，显著提升了在复杂光学环境下的目标感知能力，为精密目标定位和识别提供了新的解决方案。

---

### 31. [[Spatially-guided Temporal Aggregation for Robust Event-RGB Optical Flow Estimation]](http://arxiv.org/abs/2501.00838v1)
<!-- 2025-01-01 -->
**📅 发布日期**: 2025-01-01

*   **👥 作者**: Qianang Zhou, Junhui Hou, Meiyi Yang, Yongjian Deng, Youfu Li, Junlin Xiong
*   **🎯 研究目的**: 当前光流方法主要利用帧（或RGB）数据的稳定外观来建立跨时间的鲁棒对应关系。而事件相机则提供高时间分辨率的运动线索，并在挑战性场景中表现出色。这两种互补特性突显了整合帧和事件数据进行光流估计的潜力。然而，大多数跨模态方法未能充分利用这些互补优势，仅简单堆叠信息。本研究旨在提出一种新颖的方法，通过空间密集模态引导时间密集事件模态的聚合，实现有效的跨模态融合。
*   **⭐ 主要发现**: 本文提出了一种新颖的光流估计方法，通过空间密集模态（RGB帧）引导时间密集事件模态的聚合，实现了有效的跨模态融合。具体来说，研究引入了一种事件增强帧表示，该表示保留了帧的丰富纹理，并融入了事件数据的高时间分辨率运动信息。这种方法能够充分利用RGB和事件数据的互补优势，在各种复杂场景下实现了更鲁棒和准确的光流估计，显著优于现有简单堆叠信息的方法。

---

### 32. [[Towards End-to-End Neuromorphic Voxel-based 3D Object Reconstruction Without Physical Priors]](http://arxiv.org/abs/2501.00741v3)
<!-- 2025-01-01 -->
**📅 发布日期**: 2025-01-01

*   **👥 作者**: Chuanzhi Xu, Langyi Chen, Haodong Chen, Vera Chung, Qiang Qu
*   **🎯 研究目的**: 神经形态相机（事件相机）作为异步亮度变化传感器，能够捕获极快运动而无运动模糊，在极端环境下的3D重建方面前景广阔。然而，现有使用单目神经形态相机进行3D重建的研究有限，且大多数方法依赖于估计物理先验并采用复杂的多步骤流程。本研究旨在提出一种端到端的方法，无需估计物理先验，即可实现基于体素的密集3D重建。
*   **⭐ 主要发现**: 本文提出了一种无需物理先验的端到端密集体素3D重建方法，专门针对神经形态相机。该方法引入了一种新颖的事件表示，以增强边缘特征，使所提出的特征增强模型能够更有效地学习。此外，研究还引入了“最优B”策略，进一步优化了重建过程。实验结果表明，该方法在复杂场景下能够生成高质量的3D体素重建，显著简化了重建流程，并提升了在极端环境下的3D感知能力。

---

### 33. [[VELoRA: A Low-Rank Adaptation Approach for Efficient RGB-Event based Recognition]](http://arxiv.org/abs/2412.20064v1)
<!-- 2024-12-28 -->
**📅 发布日期**: 2024-12-28

*   **👥 作者**: Lan Chen, Haoxiang Yang, Pengpeng Shao, Haoyu Song, Xiao Wang, Zhicheng Zhao, Yaowei Wang, Yonghong Tian
*   **🎯 研究目的**: 利用RGB和事件相机进行模式识别可以通过部署深度神经网络并采用微调策略显著提升性能。受大型模型成功应用的启发，引入此类大型模型有望进一步增强多模态任务的性能。然而，对这些模型进行完全微调会导致效率低下。轻量级微调方法如LoRA和Adapter已被提出以在效率和性能之间取得更好的平衡。本研究旨在解决RGB-事件识别领域中缺乏基于预训练基础模型的参数高效微调（PEFT）策略的问题。
*   **⭐ 主要发现**: 本文提出了VELoRA，一种新颖的参数高效微调（PEFT）策略，用于适应预训练的基础模型以进行RGB-事件识别。VELoRA通过低秩适应方法，在保持高性能的同时显著降低了微调的计算成本和存储需求。这是首次将PEFT方法应用于RGB-事件多模态识别任务，为在资源受限设备上部署大型多模态模型提供了有效途径。实验结果验证了VELoRA在效率和性能方面的优越平衡，为未来多模态识别任务的轻量化部署开辟了新路径。

---

### 34. [[Learning Monocular Depth from Events via Egomotion Compensation]](http://arxiv.org/abs/2412.19067v1)
<!-- 2024-12-26 -->
**📅 发布日期**: 2024-12-26

*   **👥 作者**: Haitao Meng, Chonghao Zhong, Sheng Tang, Lian JunJia, Wenwei Lin, Zhenshan Bing, Yi Chang, Gang Chen, Alois Knoll
*   **🎯 研究目的**: 事件相机作为神经形态传感器，以稀疏和异步的方式报告亮度变化，其高时间分辨率、高动态范围和低功耗特性使其非常适合解决单目深度估计中的挑战（如高速或低光照条件）。然而，现有方法大多将事件流视为黑盒学习系统，未融入先验物理原理，导致模型过参数化且未能充分利用事件相机数据中固有的丰富时间信息。本研究旨在通过结合物理运动原理，提出一个可解释的单目深度估计框架。
*   **⭐ 主要发现**: 本文提出了一个可解释的单目深度估计框架，该框架通过引入物理运动原理（特别是自我运动补偿）来充分利用事件相机数据。该方法明确地将不同深度假设的似然性纳入考虑，避免了将事件流作为黑盒处理的局限性。实验结果表明，该框架在高速和低光照等挑战性条件下，能够生成更准确和鲁棒的单目深度图，同时提供了更好的可解释性，为事件相机在深度感知领域的应用提供了新的理论和实践基础。

---

### 35. [[SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks]](http://arxiv.org/abs/2412.12843v2)
<!-- 2024-12-17 -->
**📅 发布日期**: 2024-12-17

*   **👥 作者**: Xiaxin Zhu, Fangming Guo, Xianlei Long, Qingyi Gu, Chao Chen, Fuqiang Gu
*   **🎯 研究目的**: 基于事件的语义分割在自动驾驶和机器人领域具有巨大潜力，得益于事件相机的高动态范围、低延迟和低功耗优势。然而，当前基于人工神经网络（ANN）的分割方法存在计算需求高、需要图像帧以及大量能耗的问题，限制了其在资源受限的边缘/移动平台上的效率和应用。本研究旨在解决这些问题，引入SLTNet，一个脉冲驱动的轻量级Transformer网络，用于事件语义分割。
*   **⭐ 主要发现**: 本文提出了SLTNet，一个用于事件语义分割的脉冲驱动轻量级Transformer网络。SLTNet基于高效的脉冲驱动卷积块（SCBs）构建，能够提取丰富的语义特征，同时显著减少模型参数。此外，为了增强长距离依赖性建模能力，SLTNet集成了Transformer机制。实验结果表明，SLTNet在保持高分割精度的同时，显著降低了计算复杂度和能耗，使其非常适合在资源受限的边缘/移动平台上部署，为事件相机在实时语义分割应用中提供了高效且高性能的解决方案。

---

### 36. [DriveGazen: Event-Based Driving Status Recognition using Conventional Camera](
### 41. [[Frequency-Adaptive Low-Latency Object Detection Using Events and Frames]](http://arxiv.org/abs/2412.04149v2)
<!-- 2024-12-05 -->
**📅 发布日期**: 2024-12-05

*   **👥 作者**: Haitian Zhang, Xiangyuan Wang, Chang Xu, Xinya Wang, Fang Xu, Huai Yu, Lei Yu, Wen Yang
*   **🎯 研究目的**: 本研究旨在解决将事件相机数据与RGB图像融合进行目标检测时面临的两个关键不匹配问题：低延迟事件数据与高延迟RGB帧之间的不一致，以及训练时时间稀疏标签与推理时连续数据流之间的不匹配。这些问题严重阻碍了高频融合目标检测的性能。研究目标是开发一种能够有效融合两种模态数据，并实现低延迟、高频率目标检测的系统。
*   **⭐ 主要发现**: 作者提出了频率自适应低延迟目标检测器（FAOD）。FAOD通过一个对齐模块（Align Module）将低频RGB帧与高频事件数据对齐，该模块通过增强跨模态风格和空间邻近性来解决事件-RGB不匹配问题。此外，论文还提出了一种名为“时间偏移”（Time Shift）的训练策略，旨在解决训练与推理之间的时间稀疏标签与连续数据流的不匹配。这些创新使得FAOD能够有效利用事件相机在恶劣环境下的鲁棒性和RGB相机提供的丰富语义信息，实现高性能的融合目标检测。

---

### 42. [[ETAP: Event-based Tracking of Any Point]](http://arxiv.org/abs/2412.00133v2)
<!-- 2024-11-28 -->
**📅 发布日期**: 2024-11-28

*   **👥 作者**: Friedhelm Hamann, Daniel Gehrig, Filbert Febryanto, Kostas Daniilidis, Guillermo Gallego
*   **🎯 研究目的**: 传统的“跟踪任意点”（TAP）方法在处理复杂光照条件和高速运动场景时，由于传感器本身的局限性，其准确性难以满足需求。本研究旨在克服这些挑战，利用事件相机的高时间分辨率和高动态范围特性，开发首个基于事件相机的TAP方法，以实现对任意点的鲁棒高速跟踪。
*   **⭐ 主要发现**: 本文提出了ETAP，这是首个基于事件相机的“跟踪任意点”方法。ETAP利用事件相机的高时间分辨率和高动态范围，实现了在困难光照条件和高速运动下的鲁棒跟踪。同时，它结合了TAP方法中的全局图像上下文，有效处理了事件测量的异步性和稀疏性。此外，该工作还扩展了TAP框架，使其能够处理由事件特征变化引起的问题，从而进一步提升了在复杂场景下的跟踪性能。

---

### 43. [[Event USKT : U-State Space Model in Knowledge Transfer for Event Cameras]](http://arxiv.org/abs/2411.15276v1)
<!-- 2024-11-22 -->
**📅 发布日期**: 2024-11-22

*   **👥 作者**: Yuhui Lin, Jiahao Zhang, Siyuan Li, Jimin Xiao, Ding Xu, Wenjun Wu, Jiaxuan Lu
*   **🎯 研究目的**: 事件相机作为一种新兴的成像技术，具有低能耗和高帧率等优势，但其可用事件数据量有限，严重阻碍了其广泛发展。本研究旨在解决这一数据稀缺问题，通过知识迁移的方式，使事件数据能够有效利用预训练的RGB模型，从而在有限数据下实现具有竞争力的性能。
*   **⭐ 主要发现**: 作者引入了一种专门为事件到RGB知识迁移设计的U形状态空间模型知识迁移（USKT）框架。该框架能够生成与RGB帧兼容的输入，使得事件数据可以通过最小的参数调整来有效重用预训练的RGB模型，并达到与RGB模型相当的性能。在USKT架构内部，论文还提出了一种双向逆向状态空间模型，与传统的双向扫描机制不同，该模型能够更有效地处理事件数据的时序特性，进一步提升了知识迁移的效率和效果。

---

### 44. [[Noise Filtering Benchmark for Neuromorphic Satellites Observations]](http://arxiv.org/abs/2411.11233v1)
<!-- 2024-11-18 -->
**📅 发布日期**: 2024-11-18

*   **👥 作者**: Sami Arja, Alexandre Marcireau, Nicholas Owen Ralph, Saeed Afshar, Gregory Cohen
*   **🎯 研究目的**: 事件相机因其高时间分辨率、高动态范围、低功耗和稀疏数据输出等优点，被认为是空间态势感知（Space Situational Awareness, SSA）的理想选择，尤其适用于检测望远镜视野内移动的常驻空间物体。然而，事件相机输出数据中常包含大量背景活动噪声，在低光照条件下尤为严重，这些噪声会淹没卫星信号产生的稀疏事件，使检测和跟踪变得更具挑战性。现有噪声过滤算法通常为密集场景设计，对信号丢失的容忍度较高，因此难以在此类稀疏场景中有效应用。本研究旨在解决这一问题，为神经形态卫星观测提供有效的噪声过滤基准。
*   **⭐ 主要发现**: 本文揭示了事件相机在空间态势感知应用中面临的背景噪声挑战，尤其是在低光照条件下，现有噪声过滤算法的局限性被凸显。研究强调了为稀疏事件数据设计专用过滤方法的重要性，以避免信号淹没和丢失。通过建立噪声过滤基准，本研究为未来开发更适用于神经形态卫星观测的噪声过滤算法奠定了基础，旨在提高在复杂太空环境中对卫星信号的检测和跟踪能力。

---

### 45. [[SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition]](http://arxiv.org/abs/2410.16746v1)
<!-- 2024-10-22 -->
**📅 发布日期**: 2024-10-22

*   **👥 作者**: Jiaqi Chen, Yan Yang, Shizhuo Deng, Da Teng, Liyuan Pan
*   **🎯 研究目的**: 人体行为识别（HAR）在视频分析、监控、自动驾驶、机器人和医疗保健等领域扮演着关键角色。然而，大多数基于RGB图像的HAR算法在隐私敏感环境中存在问题，且难以有效处理复杂光照条件。事件相机通过捕捉像素级的场景亮度变化，提供了隐私保护和高动态范围的解决方案。但如何有效建模事件相机产生的空间稀疏且高时间分辨率的数据，是当前事件相机HAR面临的主要挑战。本研究旨在解决这一挑战，提升事件相机HAR的性能。
*   **⭐ 主要发现**: 本文提出了SpikMamba，一个将脉冲神经网络（SNN）与Mamba模型结合的事件相机人体行为识别框架。SpikMamba利用事件相机在隐私保护和复杂光照条件下的优势，并针对事件数据空间稀疏和高时间分辨率的特性进行了优化。通过结合SNN的事件驱动特性和Mamba模型在序列建模上的能力，SpikMamba能够更有效地处理事件流数据，从而在事件相机人体行为识别任务中实现更高的准确性和鲁棒性。

---

### 46. [[Non-Invasive Qualitative Vibration Analysis using Event Camera]](http://arxiv.org/abs/2410.14364v1)
<!-- 2024-10-18 -->
**📅 发布日期**: 2024-10-18

*   **👥 作者**: Dwijay Bane, Anurag Gupta, Manan Suri
*   **🎯 研究目的**: 本技术报告旨在探讨事件相机在非侵入式定性振动分析中的应用潜力，特别关注频率测量和运动放大。事件相机凭借其高时间分辨率和高动态范围，有望为实时结构评估和微弱运动分析提供新的能力。研究目标是通过尖端的事件视觉技术，探索事件相机在振动分析中频率测量和运动放大中强度重建的实际应用场景。
*   **⭐ 主要发现**: 在频率测量方面，事件相机展现出在实时结构评估方面的巨大潜力。它们能够精确捕捉高频振动，为非侵入式振动分析提供了有效手段。然而，在运动放大方面，尤其是在相机静止的场景中，研究发现存在显著挑战。尽管如此，本研究证实了事件相机在某些定性振动分析任务中的可行性和优势，并指出了未来在运动放大等领域需要克服的困难。

---

### 47. [[Leveraging Event Streams with Deep Reinforcement Learning for End-to-End UAV Tracking]](http://arxiv.org/abs/2410.14685v1)
<!-- 2024-10-03 -->
**📅 发布日期**: 2024-10-03

*   **👥 作者**: Ala Souissi, Hajer Fradi, Panagiotis Papadakis
*   **🎯 研究目的**: 本文旨在通过利用事件相机（一种低能耗、在速度和动态范围方面具有显著优势的成像传感器），提出一种主动跟踪方法，以提高无人机（UAV）的自主性。研究目标是设计一个跟踪控制器，使其能够响应来自搭载事件传感器的视觉反馈，从而调整无人机的运动以跟踪目标。为了充分利用四旋翼无人机的运动能力和事件传感器的独特特性，研究旨在开发一个端到端的深度强化学习（DRL）框架。
*   **⭐ 主要发现**: 作者提出了一个端到端的深度强化学习（DRL）框架，该框架能够将事件流的原始传感器数据直接映射到无人机的控制动作，从而实现自主跟踪。为了在高度可变和具有挑战性的条件下学习最优策略，研究采用了具有域随机化的仿真环境进行训练。实验结果表明，该方法能够有效利用事件流的独特优势，实现对目标的鲁棒跟踪，显著提升了无人机在复杂环境下的自主性和适应性。

---

### 48. [[FACET: Fast and Accurate Event-Based Eye Tracking Using Ellipse Modeling for Extended Reality]](http://arxiv.org/abs/2409.15584v1)
<!-- 2024-09-23 -->
**📅 发布日期**: 2024-09-23

*   **👥 作者**: Junyuan Ding, Ziteng Wang, Chang Gao, Min Liu, Qinyu Chen
*   **🎯 研究目的**: 眼动追踪是扩展现实（XR）中基于凝视交互的关键技术，但传统基于帧的系统难以满足XR对高精度、低延迟和高能效的需求。事件相机因其高时间分辨率和低功耗特性，为解决这些问题提供了有前景的替代方案。本研究旨在开发一种快速准确的、基于事件相机的眼动追踪方法，以满足XR应用的实时需求。
*   **⭐ 主要发现**: 本文提出了FACET（Fast and Accurate Event-based Eye Tracking），一个端到端的神经网络，能够直接从事件数据中输出瞳孔椭圆参数，并针对实时XR应用进行了优化。该椭圆输出可以直接用于后续基于椭圆的瞳孔追踪器。为了训练该模型，作者通过扩展标注数据并将原始掩码标签转换为基于椭圆的标注，增强了EV-Eye数据集。此外，论文还采用了一种新颖的三角损失函数，进一步提高了模型的准确性和鲁棒性。

---

### 49. [[EventAug: Multifaceted Spatio-Temporal Data Augmentation Methods for Event-based Learning]](http://arxiv.org/abs/2409.11813v1)
<!-- 2024-09-18 -->
**📅 发布日期**: 2024-09-18

*   **👥 作者**: Yukun Tian, Hao Chen, Yongjian Deng, Feihong Shen, Kepan Liu, Wei You, Ziyang Zhang
*   **🎯 研究目的**: 事件相机因其低时间延迟和高动态范围在许多领域取得了显著成功。然而，事件相机领域面临数据不足和多样性有限的挑战，这通常导致模型过拟合和特征学习不足。事件数据增强技术的研究仍然稀缺。本研究旨在解决这一空白，引入一套系统的增强方案，以丰富事件数据的时空多样性。
*   **⭐ 主要发现**: 本文提出了一套名为EventAug的多方面时空数据增强方案，旨在解决事件数据稀缺和多样性不足的问题。具体而言，EventAug首先提出了多尺度时间积分（Multi-scale Temporal Integration, MSTI）来丰富物体的运动速度多样性；接着引入了空间显著事件掩码（Spatial-salient Event Mask, SSEM）和时间显著事件掩码（Temporal-salient Event Mask, TSEM）来丰富物体变体。EventAug能够帮助模型学习更丰富的特征，有效缓解过拟合问题，并提升基于事件的学习模型的泛化能力和性能。

---

### 50. [[SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation]](http://arxiv.org/abs/2409.04082v1)
<!-- 2024-09-06 -->
**📅 发布日期**: 2024-09-06

*   **👥 作者**: Yi Tian, Juan Andrade-Cetto
*   **🎯 研究目的**: 事件相机生成异步稀疏的事件流，捕捉光强度变化，相较于传统基于帧的相机，具有更高的动态范围和极快的数据速率，特别适用于快速运动或挑战性光照条件下的场景。脉冲神经网络（SNNs）与事件相机数据具有相似的异步和稀疏特性，非常适合处理事件相机数据。受Transformer和Spikeformer在其他计算机视觉任务中潜力的启发，本研究旨在为事件相机提出快速鲁棒的光流估计解决方案。
*   **⭐ 主要发现**: 本文提出了两种针对事件相机快速鲁棒光流估计的解决方案：STTFlowNet和SDformerFlow。STTFlowNet采用U形人工神经网络（ANN）架构，利用其在图像处理中的优势。而SDformerFlow则是一种时空Swin Spikeformer，它将Transformer的强大建模能力与SNN的事件驱动特性相结合，能够有效处理事件流数据的时空信息。这些方法充分利用了事件相机和SNN的优势，在光流估计任务中展现出卓越的性能，尤其适用于高速运动和复杂光照环境。

---

### 51. [[MouseSIS: A Frames-and-Events Dataset for Space-Time Instance Segmentation of Mice]](http://arxiv.org/abs/2409.03358v1)
<!-- 2024-09-05 -->
**📅 发布日期**: 2024-09-05

*   **👥 作者**: Friedhelm Hamann, Hanxiong Li, Paul Mieske, Lars Lewejohann, Guillermo Gallego
*   **🎯 研究目的**: 尽管视频中的物体跟踪和分割算法在大型标注数据集的推动下取得了显著进展，但在恶劣条件和快速运动下，算法性能仍面临挑战。事件相机作为一种新型传感器，具有高时间分辨率和高动态范围，有望解决这些问题。然而，目前缺乏用于开发基于事件的学习型掩码级跟踪算法的标注数据。本研究旨在解决这一数据空白，并提出一项新的任务。
*   **⭐ 主要发现**: 本文引入了一个名为MouseSIS的新数据集，该数据集包含帧和事件数据，用于小鼠的时空实例分割。同时，作者提出了一项名为“时空实例分割”（space-time instance segmentation）的新任务，其目标是在传感器输入（这里是准连续事件和可选对齐帧）的整个持续时间内分割实例。MouseSIS数据集的发布和新任务的提出，为开发和评估基于事件相机的学习型掩码级跟踪算法提供了宝贵的资源，有望推动在复杂动态场景下物体跟踪和分割技术的发展。

---

### 52. [[Optimal OnTheFly Feedback Control of Event Sensors]](http://arxiv.org/abs/2408.12976v1)
<!-- 2024-08-23 -->
**📅 发布日期**: 2024-08-23

*   **👥 作者**: Valery Vishnevskiy, Greg Burman, Sebastian Kozerke, Diederik Paul Moeys
*   **🎯 研究目的**: 事件视觉传感器在像素强度变化超过预设阈值时触发并产生异步事件流，具有数据冗余低、微秒级时间分辨率和低功耗等显著优势，在机器人和计算机视觉应用中具有重要价值。本研究关注从事件数据重建视频的问题，并旨在提出一种动态反馈控制方法，以优化事件传感器的激活阈值，从而提高视频重建的质量和效率。
*   **⭐ 主要发现**: 本文提出了一种用于事件传感器激活阈值动态反馈控制的方法，以解决从事件数据重建视频的问题。在该方法中，一个控制器网络分析过去发出的事件，并预测下一时间段的最佳激活阈值分布。此外，该系统允许用户定义目标峰值事件率，控制器网络将根据此目标进行条件化和优化。这种“即时”（OnTheFly）的反馈控制机制能够自适应地调整传感器行为，从而在保持数据效率的同时，显著改善从事件流重建视频的质量和准确性。

---

### 53. [[MambaEVT: Event Stream based Visual Object Tracking using State Space Model]](http://arxiv.org/abs/2408.10487v1)
<!-- 2024-08-20 -->
**📅 发布日期**: 2024-08-20

*   **👥 作者**: Xiao Wang, Chao wang, Shiao Wang, Xixi Wang, Zhicheng Zhao, Lin Zhu, Bo Jiang
*   **🎯 研究目的**: 基于事件相机的视觉跟踪因其独特的成像原理和低能耗、高动态范围、高时间分辨率等优势，近年来受到越来越多的关注。然而，当前基于事件的跟踪算法在使用Vision Transformer和静态模板进行目标定位时，逐渐达到性能瓶颈。本研究旨在突破这些瓶颈，提出一种新的基于事件流的视觉目标跟踪框架。
*   **⭐ 主要发现**: 本文提出了一种新颖的基于Mamba的视觉跟踪框架MambaEVT，该框架采用线性复杂度的状态空间模型作为骨干网络。搜索区域和目标模板被输入到Vision Mamba网络中，进行同步的特征提取和交互。搜索区域的输出令牌随后被送入跟踪头部进行目标定位。更重要的是，MambaEVT通过引入状态空间模型，克服了传统Vision Transformer在处理长序列事件流时的计算复杂性问题，并避免了静态模板的局限性，从而显著提升了事件相机视觉目标跟踪的性能和效率。

---

### 54. [[Evaluating Image-Based Face and Eye Tracking with Event Cameras]](http://arxiv.org/abs/2408.10395v1)
<!-- 2024-08-19 -->
**📅 发布日期**: 2024-08-19

*   **👥 作者**: Khadija Iddrisu, Waseem Shariff, Noel E. OConnor, Joseph Lemley, Suzanne Little
*   **🎯 研究目的**: 事件相机（或称神经形态传感器）通过像素级捕捉局部光强度变化，生成异步数据流，即“事件”。这种独特的数据格式能够缓解传统相机在捕捉快速移动物体时欠采样等常见问题，从而保留可能丢失的关键信息。然而，利用这些数据通常需要开发专门的手工事件表示，以与传统的卷积神经网络（CNNs）无缝集成，同时考虑事件数据的独特属性。本研究旨在评估基于图像的传统算法与事件相机数据结合进行人脸和眼动追踪的可行性。
*   **⭐ 主要发现**: 本研究评估了将传统图像算法与事件相机数据相结合，用于人脸和眼动追踪的可行性。研究发现，尽管事件数据具有稀疏和异步的独特属性，但通过开发或适应专门的事件表示方法，可以有效地将其集成到传统的CNNs框架中。这表明，事件相机不仅能克服传统相机在快速运动和复杂光照条件下的局限性，还能通过与现有成熟算法的结合，在人脸和眼动追踪等应用中展现出巨大的潜力，为未来相关技术的发展提供了新的方向。

---

### 55. [[Event Stream based Human Action Recognition: A High-Definition Benchmark Dataset and Algorithms]](http://arxiv.org/abs/2408.09764v1)
<!-- 2024-08-19 -->
**📅 发布日期**: 2024-08-19

*   **👥 作者**: Xiao Wang, Shiao Wang, Pengpeng Shao, Bo Jiang, Lin Zhu, Yonghong Tian
*   **🎯 研究目的**: 人体行为识别（HAR）是计算机视觉和人工智能领域的一个核心研究方向，尽管RGB相机在此领域占据主导地位，但在实际应用中，RGB相机面临光照条件、快速运动和隐私问题等诸多挑战。生物启发式事件相机因其低能耗、高动态范围等优势，获得了越来越多的关注。然而，现有的大多数基于事件的HAR数据集分辨率较低（$346 \times 260$）。本研究旨在解决这一数据分辨率和规模的限制，推动事件相机HAR领域的发展。
*   **⭐ 主要发现**: 本文提出了一个大规模、高清晰度（$1280 \times 800$）的基于CeleX-V事件相机的人体行为识别数据集，命名为CeleX-HAR。该数据集涵盖了150种常见的行为，旨在弥补现有事件HAR数据集分辨率低和规模小的不足。CeleX-HAR的发布为事件相机HAR领域提供了高质量的基准，有助于研究人员开发更先进的算法，以应对复杂光照和快速运动等挑战，同时兼顾隐私保护，从而推动事件相机在实际HAR应用中的广泛部署。

---

### 56. [[Retina-Inspired Object Motion Segmentation for Event-Cameras]](http://arxiv.org/abs/2408.09454v2)
<!-- 2024-08-18 -->
**📅 发布日期**: 2024-08-18

*   **👥 作者**: Victoria Clerico, Shay Snyder, Arya Lohia, Md Abdullah-Al Kaiser, Gregory Schwartz, Akhilesh Jaiswal, Maryam Parsa
*   **🎯 研究目的
### 61. [[Helios: An extremely low power event-based gesture recognition for always-on smart eyewear]](http://arxiv.org/abs/2407.05206v4)
<!-- 2024-07-06 -->
**📅 发布日期**: 2024-07-06

*   **👥 作者**: Prarthana Bhattacharyya, Joshua Mitton, Ryan Page, Owen Morgan, Ben Menzies, Gabriel Homewood, Kemi Jacobs, Paolo Baesso, David Trickett, Chris Mair, Taru Muhonen, Rory Clark, Louis Berridge, Richard Vigars, Iain Wallace
*   **🎯 研究目的**: 随着增强现实（AR）技术的发展，智能眼镜（如Meta Ray-Bans）在视觉和佩戴舒适度方面取得了进展，但功能性仍有不足。现有的人机交互（HMI）方式，如电容触控和语音控制，在人体工程学、隐私和功耗方面存在局限性。本研究旨在开发一种超低功耗、实时、基于事件的手势识别系统，专为全天候智能眼镜设计，以解决这些挑战，通过利用自然手部交互提供更直观和舒适的用户体验。
*   **⭐ 主要发现**: 论文提出了Helios系统，这是首个专为全天候智能眼镜设计的超低功耗、实时、基于事件的手势识别系统。该系统利用一个尺寸为3mmx4mm、功耗仅20mW的紧凑型事件相机来执行自然手势识别。Helios通过其创新的事件处理方法，显著降低了功耗，同时保持了高识别准确率，从而实现了智能眼镜的“始终开启”功能。这项技术为AR设备中的直观、私密且节能的用户交互开辟了新途径，有望推动智能眼镜在日常使用中的普及和功能扩展。

---

### 62. [[Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input]](http://arxiv.org/abs/2406.03439v1)
<!-- 2024-06-05 -->
**📅 发布日期**: 2024-06-05

*   **👥 作者**: Joachim Ott, Zuowen Wang, Shih-Chii Liu
*   **🎯 研究目的**: 事件相机因其低延迟和稀疏输出响应的优势，在需要视觉传感器的任务中具有巨大潜力。然而，由于缺乏用于网络训练的大规模标注事件相机数据集，基于事件相机的深度网络算法发展缓慢。本研究旨在解决这一数据稀缺问题，提出一种通过文本到X模型（其中X为一种或多种输出模态，此处特指事件流）来创建新的标注事件数据集的方法。
*   **⭐ 主要发现**: 论文提出了一种新颖的“文本到事件”（Text-to-Events）模型，能够直接从文本提示生成合成事件帧。该模型利用一个自编码器，该自编码器经过训练可以生成代表事件相机输出的稀疏事件帧。通过将预训练的自编码器与扩散模型架构相结合，所提出的文本到事件模型能够生成平滑、逼真的合成事件流。这一创新方法为事件相机领域的数据集生成提供了强大的工具，极大地缓解了标注数据不足的问题，有望加速基于事件相机的深度学习算法的开发和应用。

---

### 63. [[EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting]](http://arxiv.org/abs/2405.14959v3)
<!-- 2024-05-23 -->
**📅 发布日期**: 2024-05-23

*   **👥 作者**: Jiaxu Wang, Junhao He, Ziyi Zhang, Mingyuan Sun, Jingkai Sun, Renjing Xu
*   **🎯 研究目的**: 事件相机具有高动态范围和低延迟等优势，非常适合在挑战性光照条件和快速移动场景下应用。然而，由于事件数据稀疏且不包含绝对颜色信息，从原始事件流重建3D场景面临巨大挑战。本研究旨在释放事件相机在3D重建方面的潜力，提出一个基于事件的通用3D重建框架，使其能够仅从事件输入以前馈方式重建场景，并泛化到未见过的场景而无需重新训练。
*   **⭐ 主要发现**: 论文提出了EvGGS，这是首个基于事件的通用3D重建框架，能够将场景重建为3D高斯点云。该框架包含深度估计模块、强度重建模块和高斯回归模块，这些子模块以级联方式连接并进行协同训练。EvGGS的核心贡献在于其端到端的、可泛化的特性，使其能够仅依赖事件数据就实现高质量的3D场景重建，并能有效处理新场景。实验结果表明，EvGGS在复杂动态场景和挑战性光照条件下表现出色，为事件相机在3D重建领域的应用开辟了新的可能性，尤其是在需要实时、鲁棒重建的机器人和自动驾驶等领域。

---

### 64. [[A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation]](http://arxiv.org/abs/2404.17335v3)
<!-- 2024-04-26 -->
**📅 发布日期**: 2024-04-26

*   **👥 作者**: Xin Zhang, Liangxiu Han, Tam Sobeih, Lianghao Han, Darren Dancey
*   **🎯 研究目的**: 深度估计是计算机视觉中的一项关键任务，广泛应用于自动导航、机器人和增强现实。事件相机以异步二进制脉冲的形式编码光强度的时间变化，具有低延迟、高动态范围和能效高等独特优势。然而，其非传统的脉冲输出和标注数据集的稀缺性对传统的基于图像的深度估计方法提出了重大挑战。本研究旨在利用脉冲数据的独特属性，提出一种新颖的、节能的脉冲驱动Transformer网络（SDT）来解决这些挑战，实现事件相机的深度估计。
*   **⭐ 主要发现**: 论文提出了一种新颖的能量高效脉冲驱动Transformer网络（SDT）用于事件相机的深度估计。SDT引入了三项关键创新：1) 一个纯粹由脉冲驱动的Transformer架构，其中包含基于脉冲的注意力机制，能够直接处理事件数据；2) 跨模态知识蒸馏策略，利用RGB图像的丰富语义信息来指导事件相机的深度学习，从而克服事件数据稀疏性的问题；3) 一种新颖的损失函数，进一步优化了深度估计的精度。实验结果表明，SDT在准确性和能效方面均优于现有方法，为基于事件相机的深度估计提供了新的高效解决方案，对于资源受限的边缘设备和实时应用具有重要意义。

---

### 65. [[Event-Based Eye Tracking. AIS 2024 Challenge Survey]](http://arxiv.org/abs/2404.11770v1)
<!-- 2024-04-17 -->
**📅 发布日期**: 2024-04-17

*   **👥 作者**: Zuowen Wang, Chang Gao, Zongwei Wu, Marcos V. Conde, Radu Timofte, Shih-Chii Liu, Qinyu Chen, Zheng-jun Zha, Wei Zhai, Han Han, Bohao Liao, Yuliang Wu, Zengyu Wan, Zhong Wang, Yang Cao, Ganchao Tan, Jinze Chen, Yan Ru Pei, Sasskia Brüers, Sébastien Crouzet, Douglas McLelland, Oliver Coenen, Baoheng Zhang, Yizhao Gao, Jingyuan Li, Hayden Kwok-Hay So, Philippe Bich, Chiara Boretti, Luciano Prono, Mircea Lică, David Dinucu-Jianu, Cătălin Grîu, Xiaopeng Lin, Hongwei Ren, Bojun Cheng, Xinan Zhang, Valentin Vial, Anthony Yezzi, James Tsai
*   **🎯 研究目的**: 本综述旨在回顾AIS 2024事件相机眼动追踪（EET）挑战赛。该挑战赛的核心任务是处理事件相机记录的眼球运动数据，并预测眼睛的瞳孔中心位置。挑战赛特别强调在实现良好任务准确性的同时，保持高效的眼动追踪性能和效率权衡。通过对参赛团队提交的新颖多样方法的分析和总结，本综述旨在推动未来基于事件的眼动追踪研究的发展。
*   **⭐ 主要发现**: 本综述详细分析了AIS 2024 EET挑战赛中38名注册参与者和8个提交了挑战事实表的团队所提出的方法。挑战赛任务聚焦于从事件数据中预测瞳孔中心，强调准确性和效率。综述总结了各种创新的方法，包括但不限于：利用事件流的稀疏性和高时间分辨率特性、结合深度学习模型进行特征提取和回归、以及优化算法以适应边缘计算环境。这些方法在处理事件数据固有的异步性和稀疏性方面展现了多样化的策略，为未来的事件相机眼动追踪研究提供了宝贵的见解和方向，特别是在低功耗、高动态范围应用场景下的潜力。

---

### 66. [[A Lightweight Spatiotemporal Network for Online Eye Tracking with Event Camera]](http://arxiv.org/abs/2404.08858v1)
<!-- 2024-04-13 -->
**📅 发布日期**: 2024-04-13

*   **👥 作者**: Yan Ru Pei, Sasskia Brüers, Sébastien Crouzet, Douglas McLelland, Olivier Coenen
*   **🎯 研究目的**: 事件相机数据在边缘计算环境中非常常见，其中效率和低延迟是关键要求。为了有效地处理这类数据并利用其丰富的时间特征，本研究旨在提出一种因果时空卷积网络，用于在线眼动追踪。该解决方案特别针对资源有限的边缘硬件，旨在实现高效的实现。
*   **⭐ 主要发现**: 论文提出了一种轻量级因果时空卷积网络，专为事件相机在线眼动追踪设计，并优化了在边缘计算硬件上的实现。该网络通过以下三种方式实现高效性：1) 采用简单的架构和操作（卷积、ReLU激活），降低计算复杂度；2) 可配置为通过缓冲层输出进行高效的在线推理，确保低延迟；3) 通过训练期间的正则化，可实现超过90%的激活稀疏性，从而在基于事件的处理器上实现显著的效率提升。此外，研究还提出了一种直接作用于事件数据的通用仿射增强策略，进一步提升了模型的鲁棒性。这些发现为在资源受限的边缘设备上部署实时、高效的事件相机眼动追踪系统奠定了基础。

---

### 67. [[SpikeNVS: Enhancing Novel View Synthesis from Blurry Images via Spike Camera]](http://arxiv.org/abs/2404.06710v3)
<!-- 2024-04-10 -->
**📅 发布日期**: 2024-04-10

*   **👥 作者**: Gaole Dai, Zhenyu Wang, Qinwen Xu, Ming Lu, Wen Chen, Boxin Shi, Shanghang Zhang, Tiejun Huang
*   **🎯 研究目的**: 使用神经场方法（如NeRF和3D Gaussian Splatting）实现清晰的新视角合成（NVS）的关键因素之一是训练图像的质量。然而，传统RGB相机容易受到运动模糊的影响。与此相反，事件相机和脉冲相机等神经形态相机能够固有地捕获更全面的时间信息，从而提供场景的清晰表示作为额外的训练数据。现有方法已探索集成事件相机来提高NVS质量，但事件-RGB方法存在训练成本高和在背景中效果不佳等局限性。本研究旨在引入一种新方法，利用脉冲相机克服这些限制，从而增强模糊图像的新视角合成质量。
*   **⭐ 主要发现**: 论文提出了SpikeNVS，一种利用脉冲相机增强新视角合成（NVS）质量的新方法，特别针对传统RGB相机易受运动模糊影响的问题。与现有的事件-RGB融合方法相比，SpikeNVS克服了其高训练成本和背景处理能力不足的局限性。脉冲相机能够提供场景的清晰时间表示，作为额外的训练数据，显著提升了NVS的图像质量。通过有效融合脉冲相机数据与传统图像，SpikeNVS能够生成更锐利、更真实的合成视图，即使在原始图像存在运动模糊的情况下也能表现出色。这项工作为高质量NVS提供了一种新的、更高效的解决方案，尤其适用于动态场景。

---

### 68. [[A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation]](http://arxiv.org/abs/2404.05858v1)
<!-- 2024-04-08 -->
**📅 发布日期**: 2024-04-08

*   **👥 作者**: Ahmed Faisal Abdelrahman, Matias Valdenegro-Toro, Maren Bennewitz, Paul G. Plöger
*   **🎯 研究目的**: 神经形态计算模仿大脑的计算原理，并推动了基于事件的视觉和脉冲神经网络（SNNs）的研究。事件相机（ECs）仅捕获局部强度变化，具有卓越的功耗、响应延迟和动态范围。SNNs复制生物神经元动力学，并已证明在降低视觉分类的能耗和推理时间方面具有替代传统人工神经网络（ANNs）的潜力。然而，这些新范式在空中机器人领域之外的应用仍鲜有探索。本研究旨在调查受大脑启发的传感和数据处理在配备摄像头的机械臂上进行障碍物避障的效用。
*   **⭐ 主要发现**: 论文开发了一种新颖的神经形态方法，用于配备摄像头的机械臂进行障碍物避障。研究利用了事件相机（ECs）在功耗、响应延迟和动态范围方面的优势，并结合了脉冲神经网络（SNNs）在能效和推理时间上的潜力。与现有研究主要集中在空中机器人不同，本工作首次将这些神经形态范式应用于机器人操作领域。实验结果表明，该神经形态方法能够有效地检测和避开障碍物，展示了其在复杂动态环境中的鲁棒性和实时性。这项研究为机器人感知和控制提供了一个节能且高效的替代方案，有望推动神经形态技术在更广泛的机器人应用中的发展。

---

### 69. [[Hypergraph-based Multi-View Action Recognition using Event Cameras]](http://arxiv.org/abs/2403.19316v1)
<!-- 2024-03-28 -->
**📅 发布日期**: 2024-03-28

*   **👥 作者**: Yue Gao, Jiaxuan Lu, Siqi Li, Yipeng Li, Shaoyi Du
*   **🎯 研究目的**: 视频数据中的动作识别是具有广泛应用的基础任务。单视角动作识别由于依赖单一视角而面临局限性。相比之下，多视角方法能够从不同视角捕获互补信息以提高准确性。近年来，事件相机作为创新的仿生传感器，推动了基于事件的动作识别的进步。然而，现有工作主要集中在单视角场景，在多视角事件数据利用方面存在空白，特别是在信息不足和语义错位等挑战。本研究旨在弥补这一空白，引入一个多视角事件相机动作识别框架。
*   **⭐ 主要发现**: 论文提出了HyperMV，一个基于超图的多视角事件相机动作识别框架，旨在解决现有单视角事件动作识别的局限性以及多视角事件数据利用中的信息不足和语义错位问题。HyperMV的核心创新在于将离散的事件数据转换为类似帧的表示，并利用超图结构来有效地聚合和建模来自不同视角的互补信息。通过超图，模型能够捕获复杂的非线性关系和高阶依赖性，从而更准确地理解动作。实验结果表明，HyperMV在多视角事件动作识别任务上取得了显著的性能提升，有效利用了事件相机的高时间分辨率和低延迟特性，为未来基于事件的多视角感知提供了新的范式。

---

### 70. [[Tracking-Assisted Object Detection with Event Cameras]](http://arxiv.org/abs/2403.18330v3)
<!-- 2024-03-27 -->
**📅 发布日期**: 2024-03-27

*   **👥 作者**: Ting-Kang Yen, Igor Morawski, Shusil Dangi, Kai He, Chung-Yi Lin, Jia-Fong Yeh, Hung-Ting Su, Winston Hsu
*   **🎯 研究目的**: 基于事件的目标检测因事件相机的高动态范围和无运动模糊等卓越特性而受到计算机视觉界的关注。然而，特征的异步性和稀疏性导致物体在相对于相机没有相对运动时变得“不可见”，这对该任务构成了重大挑战。现有工作研究了各种隐式学习记忆来尽可能保留时间线索，但隐式记忆在有效保留长期特征方面仍然存在困难。本研究旨在将这些“不可见”物体视为伪遮挡物体，并通过跟踪遮挡来检测它们。
*   **⭐ 主要发现**: 论文提出了一种新颖的跟踪辅助目标检测方法，旨在解决事件相机在物体没有相对运动时目标“不可见”的挑战。研究将这些“不可见”物体视为伪遮挡物体，并通过跟踪机制来持续检测它们。首先，论文引入了物体的可见性属性，并贡献了一种自动标注算法，不仅用于清理现有事件数据集，还能够为“不可见”物体生成准确的跟踪标签。其次，该方法通过显式地利用跟踪信息来弥补事件数据在物体静止时的信息缺失，从而显著提高了基于事件的目标检测的鲁棒性和准确性。实验结果验证了该方法在处理复杂动态场景和长时间跟踪方面的优越性。

---

### 71. [[Ev-Edge: Efficient Execution of Event-based Vision Algorithms on Commodity Edge Platforms]](http://arxiv.org/abs/2403.15717v1)
<!-- 2024-03-23 -->
**📅 发布日期**: 2024-03-23

*   **👥 作者**: Shrihari Sridharan, Surya Selvam, Kaushik Roy, Anand Raghunathan
*   **🎯 研究目的**: 事件相机已成为自动导航系统的一种有前景的传感模态，因为它具有高时间分辨率、高动态范围和可忽略的运动模糊。为了处理来自这些传感器的异步时间事件流，最近的研究表明，需要结合人工神经网络（ANNs）、脉冲神经网络（SNNs）以及混合SNN-ANN算法才能在各种感知任务中实现高精度。然而，研究观察到，在具有CPU、GPU和神经加速器等异构处理单元的商用边缘平台上执行此类工作负载会导致性能不佳。这主要是由于事件流的不规则性与算法多样化特性之间的不匹配。本研究旨在解决这一性能瓶颈，实现事件相机算法在边缘平台上的高效执行。
*   **⭐ 主要发现**: 论文提出了Ev-Edge，一个旨在优化事件相机视觉算法在商用边缘平台上的高效执行的框架。研究发现，事件流的不规则性和不同算法（ANNs、SNNs及混合SNN-ANN）的特性导致在异构边缘硬件上性能不佳。Ev-Edge通过提出一种新颖的调度和资源管理策略来解决这一问题，该策略能够智能地将事件处理任务分配给最合适的处理单元（CPU、GPU或神经加速器），从而最大化硬件利用率并最小化延迟。实验结果表明，Ev-Edge显著提高了事件相机算法在各种边缘设备上的吞吐量和能效，为实时、低功耗的边缘智能应用提供了关键支持。

---

### 72. [[SFOD: Spiking Fusion Object Detector]](http://arxiv.org/abs/2403.15192v1)
<!-- 2024-03-22 -->
**📅 发布日期**: 2024-03-22

*   **👥 作者**: Yimeng Fan, Wei Zhang, Changsong Liu, Mingyang Li, Wenrui Lu
*   **🎯 研究目的**: 事件相机以其高时间分辨率、高动态范围、低功耗和高像素带宽等特点，在特定场景下的目标检测中提供了独特的能力。尽管有这些优势，事件数据固有的稀疏性和异步性对现有目标检测算法提出了挑战。受人脑信息编码和处理方式启发的脉冲神经网络（SNNs）为解决这些难题提供了潜在方案。然而，它们在当前实现中利用事件相机进行目标检测的性能有限。本研究旨在提出SFOD（Spiking Fusion Object Detector），一种简单高效的SNNs目标检测方法，以克服这些限制。
*   **⭐ 主要发现**: 论文提出了SFOD（Spiking Fusion Object Detector），一种简单高效的SNNs目标检测方法，旨在克服事件数据稀疏性和异步性对传统算法的挑战。SFOD的核心创新在于设计了一个“脉冲融合模块”（Spiking Fusion Module），首次实现了来自不同时间戳的事件数据的融合。这个模块允许网络有效地聚合跨时间的信息，从而更好地理解动态场景中的物体。通过这种创新的融合机制，SFOD显著提升了SNNs在事件
### 81. [[Retina : Low-Power Eye Tracking with Event Camera and Spiking Hardware]](http://arxiv.org/abs/2312.00425v2)
<!-- 2023-12-01 -->
**📅 发布日期**: 2023-12-01

*   **👥 作者**: Pietro Bonazzi, Sizhen Bian, Giovanni Lippolis, Yawei Li, Sadique Sheik, Michele Magno
*   **🎯 研究目的**: 本研究旨在引入一种基于事件相机和脉冲硬件的神经形态方法，以开发高精度、高效率且低功耗的眼动追踪系统。它利用动态视觉传感器（DVS）相机捕获的纯事件数据，旨在克服传统眼动追踪系统的功耗和效率限制。
*   **⭐ 主要发现**: 论文提出了一种名为“Retina”的神经形态眼动追踪框架，该框架集成了直接训练的脉冲神经网络（SNN）回归模型，并利用了先进的低功耗边缘神经形态处理器Speck。研究还引入了一个代表性的事件基眼动追踪数据集“Ini-30”。“Retina”SNN模型（基于Integrate And Fire神经元）仅有64k参数（比最新模型少6.63倍），在64x64 DVS输入下实现了3.24像素的瞳孔追踪误差，显著提升了眼动追踪的效率和精度。

---

### 82. [[GET: Group Event Transformer for Event-Based Vision]](http://arxiv.org/abs/2310.02642v1)
<!-- 2023-10-04 -->
**📅 发布日期**: 2023-10-04

*   **👥 作者**: Yansong Peng, Yueyi Zhang, Zhiwei Xiong, Xiaoyan Sun, Feng Wu
*   **🎯 研究目的**: 现有基于事件的骨干网络主要依赖于从事件转换而来的图像进行空间信息提取，但往往忽视了事件的重要属性，如时间信息和极性信息。本研究旨在解决这一问题，提出一种新的事件相机视觉骨干网络，能够更好地利用事件的固有特性。
*   **⭐ 主要发现**: 论文提出了一种新颖的基于组的视觉Transformer骨干网络，名为“Group Event Transformer (GET)”，用于事件相机视觉。GET在特征提取过程中将时间-极性信息与空间信息解耦。具体而言，它首先提出了一种新的事件表示方法，称为“Group Token”，该方法根据事件的时间戳和极性对异步事件进行分组。随后，GET应用了“Event Dual Self-Attention”块进行处理，从而更有效地提取事件数据中的时空特征。

---

### 83. [[Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline]](http://arxiv.org/abs/2309.14611v1)
<!-- 2023-09-26 -->
**📅 发布日期**: 2023-09-26

*   **👥 作者**: Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang
*   **🎯 研究目的**: 现有基于事件相机的目标追踪方法存在局限性：要么需要RGB和事件数据对齐以提高精度但推理成本高，要么直接学习事件追踪器但易受噪声事件或稀疏空间分辨率影响。本研究旨在提出一种新的框架，在训练阶段充分利用多模态/多视角信息，以实现测试阶段仅使用事件信号进行高速、低延迟的视觉追踪。
*   **⭐ 主要发现**: 论文提出了一种新颖的分层知识蒸馏框架。该框架首先训练一个基于Transformer的教师多模态追踪器，同时输入RGB帧和事件流。通过这种方式，框架能够在训练期间充分利用多模态信息进行知识迁移，从而在测试时仅使用事件信号即可实现高速、低延迟的视觉追踪。同时，论文还发布了一个高分辨率基准数据集，以促进该领域的研究。

---

### 84. [[Dense Voxel 3D Reconstruction Using a Monocular Event Camera]](http://arxiv.org/abs/2309.00385v1)
<!-- 2023-09-01 -->
**📅 发布日期**: 2023-09-01

*   **👥 作者**: Haodong Chen, Vera Chung, Li Tan, Xiaoming Chen
*   **🎯 研究目的**: 事件相机在帧插值、语义分割、里程计和SLAM等领域得到了广泛应用，但在VR应用的3D重建方面仍未得到充分探索。现有方法主要通过深度图估计进行3D重建，且通常需要多相机才能生成密集结果，而单事件相机方法只能产生半密集结果。本研究旨在探索并实现使用单目事件相机进行密集体素3D重建。
*   **⭐ 主要发现**: 本文致力于使用单目事件相机实现密集的体素3D重建。虽然摘要片段未详细说明具体方法，但它强调了使用单个事件相机实现“密集”重建的新颖性，这在以前是一个挑战。事件相机具有高动态范围、高帧率和极低功耗等优势，本研究旨在利用这些优势，为VR应用提供更高效和高质量的3D重建方案。

---

### 85. [[3ET: Efficient Event-based Eye Tracking using a Change-Based ConvLSTM Network]](http://arxiv.org/abs/2308.11771v1)
<!-- 2023-08-22 -->
**📅 发布日期**: 2023-08-22

*   **👥 作者**: Qinyu Chen, Zuowen Wang, Shih-Chii Liu, Chang Gao
*   **🎯 研究目的**: 眼动追踪是下一代可穿戴医疗技术（如AR/VR头显）的关键组成部分。本研究旨在利用受视网膜启发的事件相机（具有低延迟响应和稀疏输出事件流的优势）开发一种高效的基于事件的眼动追踪模型，以克服传统基于帧的相机在效率和延迟方面的局限性。
*   **⭐ 主要发现**: 论文提出了一种名为“3ET”的稀疏基于变化的卷积长短期记忆（CB-ConvLSTM）模型，用于事件基眼动追踪。该CB-ConvLSTM架构能够高效地从事件流中提取用于瞳孔追踪的时空特征，性能优于传统的CNN结构。通过利用增强激活稀疏性的delta编码循环路径，CB-ConvLSTM在不损失精度的情况下，将算术运算量减少了约4.7倍（在`v2e`生成的数据集上测试），显著提高了效率。

---

### 86. [[SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition]](http://arxiv.org/abs/2308.04369v3)
<!-- 2023-08-08 -->
**📅 发布日期**: 2023-08-08

*   **👥 作者**: Xiao Wang, Yao Rong, Zongzhen Wu, Lin Zhu, Bo Jiang, Jin Tang, Yonghong Tian
*   **🎯 研究目的**: 当前基于事件相机的模式识别方法存在两个主要问题：1) 仅使用空间稀疏的事件流进行识别可能无法很好地捕捉颜色和详细纹理信息；2) 脉冲神经网络（SNN）虽然能效高但性能可能次优，而人工神经网络（ANN）性能高但能耗大。本研究旨在弥合SNN和ANN之间的差距，实现能效与高性能的平衡。
*   **⭐ 主要发现**: 论文提出了“SSTFormer”，一个混合架构，将脉冲神经网络（SNN）与记忆支持Transformer相结合，用于基于帧-事件的识别。该方法旨在结合传统帧的详细信息和事件流的能效优势，从而在性能和能耗之间取得平衡，克服了现有方法在捕捉细节信息和实现高效识别方面的局限性。

---

### 87. [[Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems]](http://arxiv.org/abs/2307.13600v1)
<!-- 2023-07-25 -->
**📅 发布日期**: 20
以下是20篇ArXiv论文的中文总结，严格遵循您指定的Markdown格式：

### 101. [[Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking Neural Networks with Learnable Neuronal Dynamics]](http://arxiv.org/abs/2209.11741v2)
<!-- 2022-09-21 -->
**📅 发布日期**: 2022-09-21

*   **👥 作者**: Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 事件相机因其异步捕捉时间丰富信息的能力，在高速运动估计方面展现出巨大潜力。脉冲神经网络（SNNs）凭借其受神经启发的事件驱动处理机制，能有效处理此类异步数据，而漏积分放电（LIF）等神经元模型能跟踪输入中本质的时序信息。然而，由于“脉冲消失”问题，深度SNNs的训练面临挑战。本研究旨在开发一种能够有效处理事件数据并克服深度SNN训练困难的脉冲神经网络，以实现更优的序列回归任务性能，特别是针对光流估计。
*   **⭐ 主要发现**: 论文提出了Adaptive-SpikeNet，这是一种用于事件光流估计的脉冲神经网络，其核心创新在于引入了可学习的神经元动力学（例如LIF神经元参数）。通过允许神经元参数自适应地学习，该网络能够有效缓解深度SNNs训练中的“脉冲消失”问题。实验结果表明，Adaptive-SpikeNet在序列回归任务上，相比同等规模的模拟神经网络（ANNs），取得了更好的性能，证明了其在处理异步事件数据和克服SNN训练挑战方面的有效性。

---

### 102. [[EDeNN: Event Decay Neural Networks for low latency vision]](http://arxiv.org/abs/2209.04362v2)
<!-- 2022-09-09 -->
**📅 发布日期**: 2022-09-09

*   **👥 作者**: Celyn Walters, Simon Hadfield
*   **🎯 研究目的**: 尽管神经网络在计算机视觉任务中取得了巨大成功，但当前的数字“神经元”只是生物神经元的粗略近似，且学习方法主要为数字设备和图像帧数据设计。生物视觉系统通常比最先进的数字计算机视觉算法更强大和高效。事件相机作为一种新兴的传感器技术，通过异步触发像素来模仿生物视觉，摒弃了图像帧的概念。然而，为了利用现代学习技术，许多事件处理算法被迫将事件累积回图像帧，从而在一定程度上浪费了事件相机的优势。本研究旨在开发一种新型神经网络，能够直接处理事件数据，以实现低延迟视觉，充分发挥事件相机的固有优势。
*   **⭐ 主要发现**: 论文提出了一种名为EDeNN（Event Decay Neural Networks）的新型神经网络。与传统方法不同，EDeNN遵循相反的范式，直接处理事件流，而无需将其累积或转换回图像帧。这种设计使得EDeNN能够更好地利用事件相机的异步特性，从而实现更低的延迟和更高的效率，为事件驱动的计算机视觉任务提供了一种更接近生物视觉处理机制的解决方案。

---

### 103. [[Visual Odometry with Neuromorphic Resonator Networks]](http://arxiv.org/abs/2209.02000v3)
<!-- 2022-09-05 -->
**📅 发布日期**: 2022-09-05

*   **👥 作者**: Alpha Renner, Lazar Supic, Andreea Danielescu, Giacomo Indiveri, E. Paxon Frady, Friedrich T. Sommer, Yulia Sandamirskaya
*   **🎯 研究目的**: 视觉里程计（VO）是一种利用视觉传感器估计移动机器人自身运动的方法，相比基于积分测量的里程计（如惯性传感器或轮式编码器）不会累积漂移误差。然而，基于图像的VO计算量大，限制了其在低延迟、低内存和低能耗场景中的应用。神经拟态硬件为许多视觉和AI问题提供了低功耗解决方案，但设计此类解决方案通常复杂且需从头构建。本研究旨在利用向量符号架构（VSA）作为抽象层，设计与神经拟态硬件兼容的VO算法，以克服传统VO的计算限制和神经拟态算法设计的复杂性。
*   **⭐ 主要发现**: 论文提出了一种利用向量符号架构（VSA）来设计视觉里程计（VO）算法的方法，使其与神经拟态硬件兼容。通过从一个用于场景分析的VSA模型出发，研究人员能够构建出一种能够估计机器人自身运动的系统。这种方法为在低功耗神经拟态硬件上实现VO提供了一条途径，有望解决传统VO计算密集的问题，并简化神经拟态算法的设计流程。

---

### 104. [[Training Robust Spiking Neural Networks on Neuromorphic Data with Spatiotemporal Fragments]](http://arxiv.org/abs/2207.11659v3)
<!-- 2022-07-24 -->
**📅 发布日期**: 2022-07-24

*   **👥 作者**: Haibo Shen, Yihao Luo, Xiang Cao, Liangqi Zhang, Juyu Xiao, Tianjiang Wang
*   **🎯 研究目的**: 神经拟态视觉传感器（事件相机）天生适用于脉冲神经网络（SNNs），并为这种仿生模型提供了新颖的神经拟态视觉数据。由于其时空特性，处理这些非传统视觉信号需要新颖的数据增强方法。现有数据增强方法可能无法充分模拟真实世界中亮度变化等干扰，导致训练出的SNNs鲁棒性不足。本研究旨在提出一种新的数据增强方法，以保留神经拟态数据的连续性，并模拟亮度变化引起的干扰，从而训练出更鲁棒的脉冲神经网络。
*   **⭐ 主要发现**: 论文提出了一种新颖的事件时空碎片（Event SpatioTemporal Fragments, ESTF）增强方法。ESTF通过漂移或反转时空事件流的片段来模拟亮度变化的扰动，同时保留了神经拟态数据的连续性。在主流神经拟态数据集上进行的广泛实验表明，ESTF相比纯几何变换提供了显著的性能提升，证明了其在提高脉冲神经网络鲁棒性方面的有效性。

---

### 105. [[Fusing Frame and Event Vision for High-speed Optical Flow for Edge Application]](http://arxiv.org/abs/2207.10720v1)
<!-- 2022-07-21 -->
**📅 发布日期**: 2022-07-21

*   **👥 作者**: Ashwin Sanjay Lele, Arijit Raychowdhury
*   **🎯 研究目的**: 基于帧的相机计算光流精度高，但速度受限于算法模型大小或相机帧率，不适用于高速应用。事件相机提供连续异步事件流，克服了帧率限制，但其数据处理算法要么借鉴帧式设置限制速度，要么精度较低。本研究旨在融合帧相机和事件相机的互补优势（帧的精度和事件的速度），以实现高速光流计算，同时保持低错误率，特别针对边缘应用场景。
*   **⭐ 主要发现**: 论文提出了一种仿生网络，该网络能够融合帧视觉和事件视觉的互补优势，以实现高速光流计算。该网络在MVSEC数据集上进行了验证，结果显示在速度提升4倍的情况下，错误率仅下降19%。研究还通过高速无人机飞行场景演示了该系统，证明了其在实际边缘应用中提供高速且低错误率光流的能力。

---

### 106. [[How Many Events do You Need? Event-based Visual Place Recognition Using Sparse But Varying Pixels]](http://arxiv.org/abs/2206.13673v3)
<!-- 2022-06-28 -->
**📅 发布日期**: 2022-06-28

*   **👥 作者**: Tobias Fischer, Michael Milford
*   **🎯 研究目的**: 事件相机因其高动态范围、低延迟、几乎无运动模糊和高能效等特性而持续受到关注。其中一个潜在应用是用于机器人定位的视觉地点识别，即匹配查询观测与数据库中对应的参考地点。本研究旨在探索来自一小部分（数十或数百个）像素的事件流的独特性，以确定在地点识别任务中，仅使用稀疏但变化大的像素是否足够，从而提高效率。
*   **⭐ 主要发现**: 论文探索了事件流中一小部分像素（数十或数百个）的独特性，并证明了当使用在参考集中显示出较大变化的像素时，这些像素累积到事件帧中的事件数量的绝对差值足以用于地点识别任务。这项发现表明，即使是稀疏的事件数据，只要选择合适的像素子集，也能有效地用于视觉地点识别，从而可能降低计算和存储需求。

---

### 107. [[E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations]](http://arxiv.org/abs/2206.07578v2)
<!-- 2022-06-15 -->
**📅 发布日期**: 2022-06-15

*   **👥 作者**: Jongwan Kim, DongJin Lee, Byunggook Na, Seongsik Park, Jeonghee Jo, Sung
### 121. [[EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing And Following]](http://arxiv.org/abs/2106.15045v1)
<!-- 2021-06-29 -->
**📅 发布日期**: 2021-06-29

*   **👥 作者**: Nitin J. Sanket, Chahat Deep Singh, Chethan M. Parameshwara, Cornelia Fermüller, Guido C. H. E. de Croon, Yiannis Aloimonos
*   **🎯 研究目的**: 随着无人机（UAVs）的普及，其对安全和隐私构成了潜在威胁。传统的相机在捕捉高速旋转的螺旋桨时会产生严重的运动模糊，难以有效检测。本研究旨在利用事件相机（一种具有高时间分辨率、低延迟和高动态范围的传感器）的优势，开发一种能够从事件数据中检测无人机螺旋桨的方法，以支持无人机在中空降落和跟踪等应用。
*   **⭐ 主要发现**: 论文提出了一种名为EVPropNet的深度神经网络，专门用于从事件相机数据中检测螺旋桨。研究人员通过建模螺旋桨的几何形状并生成模拟事件数据来训练该网络，有效解决了传统相机在高速运动下螺旋桨检测的挑战。事件相机能够“看到”传统相机因运动模糊而无法直接捕捉到的高速旋转部件，为无人机检测提供了一种新颖且高效的解决方案，对空中机器人和安全监控领域具有重要意义。

---

### 122. [[Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks]](http://arxiv.org/abs/2106.01862v2)
<!-- 2021-06-03 -->
**📅 发布日期**: 2021-06-03

*   **👥 作者**: Jesse Hagenaars, Federico Paredes-Vallés, Guido de Croon
*   **🎯 研究目的**: 神经形态计算以其极低的功耗和延迟而备受关注。然而，将传统人工神经网络（ANNs）的学习算法转移到脉冲神经网络（SNNs）中，并将其应用于大规模、复杂的回归任务面临挑战。此外，要实现一个真正异步且完全神经形态的感知流水线，需要重新思考信息输入和累积的方式，特别是对于事件相机和SNN之间直接传递脉冲的场景。本研究旨在解决这两个问题，并专注于事件相机数据的光流估计这一复杂任务。
*   **⭐ 主要发现**: 本文提出了一种自监督学习方法，用于基于事件的脉冲神经网络光流估计。研究人员成功地将传统的ANN学习算法适配到SNN中，并在不依赖外部监督信号的情况下，实现了SNN对复杂回归任务的处理。通过直接将事件相机产生的脉冲作为SNN的输入，并让网络内部完成所有时间信息的整合，该方法最大限度地发挥了神经形态计算的优势，实现了低功耗和低延迟的光流估计，为未来全神经形态感知系统的发展奠定了基础。

---

### 123. [[Bio-inspired visual attention for silicon retinas based on spiking neural networks applied to pattern classification]](http://arxiv.org/abs/2105.14753v1)
<!-- 2021-05-31 -->
**📅 发布日期**: 2021-05-31

*   **👥 作者**: Amélie Gruel, Jean Martinet
*   **🎯 研究目的**: 视觉注意力机制，特别是显著性检测，在生物学中被定义为选择性地关注感官线索的特定方面而忽略其他信息的过程，这在多媒体索引中被广泛用于指导图像或视频分析。随着硅视网膜（事件相机）的出现，它们以异步事件的形式输出像素亮度变化，这与传统相机截然不同。本研究旨在探讨如何将生物启发式的注意力机制和显著性检测方法，应用于这种新型传感器的输出，并将其应用于模式分类任务。
*   **⭐ 主要发现**: 本文提出了一种基于脉冲神经网络（SNNs）的生物启发式视觉注意力模型，专门用于处理硅视网膜（事件相机）产生的异步事件流。该模型能够根据事件数据选择性地聚焦于场景中的相关部分，从而减少后续处理的数据量。研究结果表明，将这种注意力机制应用于模式分类任务，能够有效提升基于事件相机的视觉系统的性能，为低功耗、高效率的事件视觉处理提供了新的思路，并进一步推动了神经形态计算在实际应用中的发展。

---

### 124. [[Superevents: Towards Native Semantic Segmentation for Event-based Cameras]](http://arxiv.org/abs/2105.06091v1)
<!-- 2021-05-13 -->
**📅 发布日期**: 2021-05-13

*   **👥 作者**: Weng Fei Low, Ankit Sonthalia, Zhi Gao, André van Schaik, Bharath Ramesh
*   **🎯 研究目的**: 多数成功的计算机视觉模型通过将低级特征转换为更丰富的中间或中级表示来完成下游任务。然而，对于事件相机而言，其输出的事件流在空间上通常稀疏且不连续，导致中级表示的探索不足。本研究旨在为事件相机引入一种名为“Superevents”的局部一致中间表示，以解决事件数据稀疏性带来的挑战，并为语义分割、视觉跟踪和深度估计等任务提供更有效的原生解决方案。
*   **⭐ 主要发现**: 论文提出了一种新颖的方法，利用“Superevents”作为事件相机数据的感知一致局部单元。Superevents能够有效地描绘场景中对象的局部部分，通过利用局部一致的中间表示，显著改善了事件相机在语义分割等视觉任务上的表现。该方法受到近期深度学习架构的启发，并引入了“生命周期增强”的概念，使得模型能够更好地处理事件流的动态特性。这一创新为事件相机数据的原生语义理解开辟了新途径，有望在多种视觉任务中实现性能提升。

---

### 125. [[Instantaneous Stereo Depth Estimation of Real-World Stimuli with a Neuromorphic Stereo-Vision Setup]](http://arxiv.org/abs/2104.02541v1)
<!-- 2021-04-06 -->
**📅 发布日期**: 2021-04-06

*   **👥 作者**: Nicoletta Risi, Enrico Calabrese, Giacomo Indiveri
*   **🎯 研究目的**: 立体匹配问题，即在两个不同视图中匹配对应特征以重建深度，在生物学中得到高效解决，但在经典机器视觉方法中仍是计算瓶颈。事件相机和脉冲神经网络（SNNs）的结合有望简化这一问题。尽管已有一些结合事件相机和神经形态处理器的解决方案，但它们多在数字硬件上模拟或仅在简化刺激下测试。本研究旨在利用真实世界数据，验证一种基于事件的、脑启发式立体匹配架构在混合信号神经形态处理器上的性能。
*   **⭐ 主要发现**: 本文利用DHP19（Dynamic Vision Sensor 3D Human Pose Dataset）数据集，验证了在混合信号神经形态处理器上实现的脑启发式事件基立体匹配架构。研究结果表明，该系统能够对真实世界刺激进行瞬时立体深度估计，有效利用了事件相机的高时间分辨率和SNN的低延迟特性。这一工作不仅展示了神经形态立体视觉系统在实际应用中的潜力，也为构建更高效、更接近生物视觉系统的深度感知解决方案提供了实验证据。

---

### 126. [[Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor Fusion and Deep Fused Spiking-Analog Network Architectures]](http://arxiv.org/abs/2103.10592v1)
<!-- 2021-03-19 -->
**📅 发布日期**: 2021-03-19

*   **👥 作者**: Chankyu Lee, Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 传统的帧式相机在高速运动下易受运动模糊影响，且在高动态范围场景中感知不准确。事件相机通过异步检测像素强度变化克服了这些限制，但其数据稀疏，难以估计像素的整体密集行为。为了解决这些传感器固有的问题，本研究旨在提出一个传感器融合框架，结合帧式和事件相机两者的互补特性，实现能量高效的光流估计。
*   **⭐ 主要发现**: 论文提出了Fusion-FlowNet，一个利用帧式和事件相机数据进行传感器融合的框架，旨在实现能量高效的光流估计。该网络架构融合了脉冲神经网络（SNNs）和模拟神经网络（ANNs）的优点，通过利用事件相机的高时间分辨率和帧式相机的密集空间信息，克服了单一传感器的局限性。实验结果表明，Fusion-FlowNet能够有效估计光流，并且在能效方面表现出色，为未来自动驾驶、机器人导航等需要高精度和低功耗光流估计的应用提供了新的解决方案。

---

### 127. [[Event-based Synthetic Aperture Imaging with a Hybrid Network]](http://arxiv.org/abs/2103.02376v3)
<!-- 2021-03-03 -->
**📅 发布日期**: 2021-03-03

*   **👥 作者**: Xiang Zhang, Wei Liao, Lei Yu, Wen Yang, Gui-Song Xia
*   **🎯 研究目的**: 合成孔径成像（SAI）通过模糊离焦前景遮挡物并从多视图图像重建对焦的被遮挡目标，实现“透视”效果。然而，密集的遮挡和极端光照条件会严重干扰基于传统帧式相机的SAI性能。本研究旨在提出一种基于事件相机的新型SAI系统，以解决这些挑战，利用事件相机极低的延迟和高动态范围特性，实现对被遮挡目标的鲁棒重建。
*   **⭐ 主要发现**: 本文提出了一种新颖的基于事件相机的合成孔径成像（SAI）系统。事件相机能够生成异步事件，具有极低的延迟和高动态范围，这使得系统能够通过几乎连续的视图消除密集遮挡的干扰，并同时解决过曝/欠曝问题。为了重建被遮挡的目标，研究人员提出了一种混合编码器-解码器网络。实验结果表明，该系统在处理复杂遮挡和极端光照条件下的SAI任务时，表现出优于传统方法的性能，为透视成像和目标重建提供了新的技术途径。

---

### 128. [[Learning Monocular Dense Depth from Events]](http://arxiv.org/abs/2010.08350v2)
<!-- 2020-10-16 -->
**📅 发布日期**: 2020-10-16

*   **👥 作者**: Javier Hidalgo-Carrió, Daniel Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是一种新型传感器，以异步事件流的形式输出亮度变化，而非传统的强度帧。它们具有高时间分辨率、高动态范围、无运动模糊和低带宽等显著优势。近期，基于学习的方法已被应用于事件数据，并在单目深度预测等任务中取得了进展。然而，大多数现有方法使用标准前馈架构生成预测，未能充分利用事件流中固有的时间一致性。本研究旨在通过引入循环架构来解决这一问题，以期在单目稠密深度估计任务上取得显著改进。
*   **⭐ 主要发现**: 论文提出了一种循环神经网络架构，用于从事件相机数据中学习单目稠密深度。与现有主要采用前馈架构的方法不同，该循环架构能够有效利用事件流的时间一致性，从而显著提升了深度预测的性能。实验结果表明，与标准前馈方法相比，所提出的循环架构在单目稠密深度估计任务上取得了显著的改进，证明了利用事件数据固有时间特性进行深度学习的有效性，为事件相机在三维重建和机器人感知领域的应用开辟了新途径。

---

### 129. [[Real-Time Face & Eye Tracking and Blink Detection using Event Cameras]](http://arxiv.org/abs/2010.08278v1)
<!-- 2020-10-16 -->
**📅 发布日期**: 2020-10-16

*   **👥 作者**: Cian Ryan, Brian O Sullivan, Amr Elrasad, Joe Lemley, Paul Kielty, Christoph Posch, Etienne Perot
*   **🎯 研究目的**: 事件相机作为新兴的神经形态视觉传感器，通过捕捉每个像素的局部光强度变化，生成异步事件流，具有低能耗、高时间分辨率、高动态范围和低延迟等优势。这些特性使其特别适用于驾驶员监控系统（DMS），即车内安全系统，旨在感知和理解驾驶员的生理和认知状态。本研究旨在提出一种新颖的方法，利用事件相机实现驾驶员的面部和眼睛的实时跟踪，并检测眨眼行为。
*   **⭐ 主要发现**: 论文提出了一种独特的、全卷积循环神经网络架构，用于实时检测和跟踪驾驶员的面部和眼睛，并检测眨眼。该方法充分利用了事件相机的高时间分辨率和低延迟特性，使其特别适用于对实时性要求高的驾驶员监控系统。通过该架构，系统能够有效处理事件数据流，实现对驾驶员状态的精确感知。这项工作为基于事件相机的驾驶员监控系统提供了高效且鲁棒的解决方案，有望提升车载安全系统的性能。

---

### 130. [[Learning to Detect Objects with a 1 Megapixel Event Camera]](http://arxiv.org/abs/2009.13436v2)
<!-- 2020-09-28 -->
**📅 发布日期**: 2020-09-28

*   **👥 作者**: Etienne Perot, Pierre de Tournemire, Davide Nitti, Jonathan Masci, Amos Sironi
*   **🎯 研究目的**: 事件相机以其高时间精度、低数据率和高动态范围的特性，非常适合高运动、挑战性光照条件和需要低延迟的场景。然而，由于该领域的相对新颖性，事件系统在许多视觉任务上的性能仍低于传统帧式解决方案。这主要归因于事件传感器较低的空间分辨率、缺乏大规模训练数据集以及缺乏成熟的事件处理深度学习架构。本研究旨在解决这些问题，特别是针对事件目标检测任务。
*   **⭐ 主要发现**: 本文在事件目标检测任务上取得了显著进展，主要通过解决该领域面临的三个核心问题：空间分辨率、数据集规模和网络架构。首先，研究人员利用了一款1兆像素的事件相机，显著提升了空间分辨率。其次，他们构建了一个大规模的事件数据集，为模型训练提供了充足数据。最后，他们开发了适合事件数据处理的深度学习架构。这些改进共同使得事件相机在目标检测任务上的性能达到了新的水平，缩小了与传统帧式相机解决方案的差距，为事件视觉在实际应用中的推广奠定了基础。

---

### 131. [[Real-time Classification from Short Event-Camera Streams using Input-filtering Neural ODEs]](http://arxiv.org/abs/2004.03156v1)
<!-- 2020-04-07 -->
**📅 发布日期**: 2020-04-07

*   **👥 作者**: Giorgio Giannone, Asha Anoosheh, Alessio Quaglino, Pierluca D'Oro, Marco Gallieri, Jonathan Masci
*   **🎯 研究目的**: 事件相机是一种新型高效传感器，生成异步、像素级的事件流。通常，从这类数据中学习需要大量的预处理和事件整合，将其转换为图像，这可能需要缓冲长时间序列并限制推理系统的响应时间。本研究旨在提出一种直接使用DVS相机事件流（强度变化及其空间坐标序列）的方法，作为一种新型异步RNN类架构——输入过滤神经ODE（INODE）的输入，以实现实时分类，避免繁重的预处理和数据缓冲。
*   **⭐ 主要发现**: 论文提出了一种名为输入过滤神经ODE（INODE）的新型异步RNN类架构，能够直接处理DVS相机产生的事件流，实现实时分类。INODE是神经ODE（NODE）的扩展，允许输入信号持续馈送到网络，并受到动态系统和滤波理论的启发。与传统方法需要将事件整合为图像再进行处理不同，INODE直接利用事件的异步特性，显著减少了预处理的复杂性和数据缓冲的需求，从而提高了推理系统的响应速度和效率，为事件相机数据的实时处理开辟了新途径。

---

### 132. [[Exploration of Reinforcement Learning for Event Camera using Car-like Robots]](http://arxiv.org/abs/2004.00801v1)
<!-- 2020-04-02 -->
**📅 发布日期**: 2020-04-02

*   **👥 作者**: Riku Arakawa, Shintaro Shiba
*   **🎯 研究目的**: 尽管事件相机具有极低的延迟，但将其应用于机器人强化学习的研究尚处于早期阶段。本研究旨在首次探索将事件相机与强化学习相结合，以实现比现有基于标准相机的视觉强化学习应用更快的机器人控制。具体而言，研究将开发一种处理事件流的图像状特征表示方法，并在模拟器中训练智能体完成快速避碰和障碍物跟踪任务，最终将训练好的智能体迁移到真实世界的机器人上进行验证。
*   **⭐ 主要发现**: 本文首次展示了事件相机在机器人强化学习中的应用。研究人员引入了一种图像状特征来处理事件流，并在模拟器中成功训练了智能体，使其能够执行快速避碰和障碍物跟踪任务。关键的创新在于，利用事件相机极低的延迟特性，实现了比传统相机更快的机器人控制。此外，训练好的智能体能够从模拟器成功迁移到真实世界的机器人上，并实现了对随机抛掷物体的快速避让。这项工作为将事件相机集成到强化学习中开辟了新的可能性，有望在高速、低延迟的机器人控制领域带来突破。

---

### 133. [[Learning to Exploit Multiple Vision Modalities by Using Grafted Networks]](http://arxiv.org/abs/2003.10959v3)
<!-- 2020-03-24 -->
**📅 发布日期**: 2020-03-24

*   **👥 作者**: Yuhuang Hu, Tobi Delbruck, Shih-Chii Liu
*   **🎯 研究目的**: 热成像、高光谱、偏振和事件相机等新型视觉传感器提供了传统强度相机无法获取的信息。然而，将这些传感器与当前强大的深度神经网络结合使用面临一个主要障碍：缺乏大规模的标注训练数据集。本研究旨在提出一种网络嫁接算法（NGA），通过用新型视觉输入驱动的新前端网络替换预训练深度网络的前端网络，解决数据稀缺问题，从而使模型能够利用多模态视觉信息。
*   **⭐ 主要发现**: 论文提出了一种名为网络嫁接算法（NGA）的新方法，用于利用多模态视觉信息。该算法通过将一个由非常规视觉输入（如事件相机数据）驱动的新前端网络，嫁接到一个已在强度帧上预训练的深度网络上。关键在于，嫁接网络的自监督训练仅使用同步记录的强度帧和新型传感器数据，以最大化预训练网络和嫁接网络之间的特征相似性。实验表明，这种增强的嫁接网络在平均精度（AP50）分数上达到了与预训练网络相当的竞争力，证明了在数据稀缺情况下有效利用多模态传感器信息的潜力。

---

### 134. [[Event-based Asynchronous Sparse Convolutional Networks]](http://arxiv.org/abs/2003.09148v2)
<!-- 2020-03-20 -->
**📅 发布日期**: 2020-03-20

*   **👥 作者**: Nico Messikommer, Daniel Gehrig, Antonio Loquercio, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是受生物启发而设计的传感器，以异步和稀疏的“事件”形式响应像素亮度变化。近期，模式识别算法（如基于学习的方法）通过将事件转换为同步密集的图像状表示，并应用传统机器学习方法，在事件相机数据处理方面取得了显著进展。然而，这些方法牺牲了事件数据固有的空间和时间稀疏性，导致计算复杂度和延迟增加。本研究旨在提出一个通用框架，将训练在同步图像状事件表示上的模型转换为具有相同输出的异步模型，从而直接利用事件数据固有的异步和稀疏特性。
*   **⭐ 主要发现**: 论文提出了一种通用框架，用于构建事件基异步稀疏卷积网络。该框架能够将传统上在同步图像状事件表示上训练的模型，转换为直接处理异步和稀疏事件数据的模型，同时保持相同的输出。这意味着可以充分利用事件数据固有的低延迟和低计算复杂度的优势，而无需进行耗时的密集化预处理。这一创新为事件相机数据的实时、高效处理提供了新的范式，有望在需要快速响应和低功耗的机器人和嵌入式系统应用中发挥关键作用。
### 141. [[EvAn: Neuromorphic Event-based Anomaly Detection]](http://arxiv.org/abs/1911.09722v2)
<!-- 2019-11-21 -->
**📅 发布日期**: 2019-11-21

*   **👥 作者**: Lakshmi Annamalai, Anirban Chakraborty, Chetan Singh Thakur
*   **🎯 研究目的**: 传统相机在功耗、动态范围和运动模糊方面存在局限性。事件相机作为仿生传感器，通过异步记录亮度变化，具有低功耗、高动态范围、无运动模糊等显著优势，并能生成稀疏数据结构，非常适用于各种运动分析任务。本研究旨在首次将事件相机的这些独特优势应用于一个关键的视觉应用——视频异常检测，以克服传统方法在复杂场景下的不足。
*   **⭐ 主要发现**: 论文首次在事件数据分析领域提出了利用事件相机进行视频异常检测的方法，并构建了一个名为EvAn的框架。该方法通过双判别器条件生成对抗网络（GAN）来建模事件域中的运动动态。EvAn利用了事件相机固有的稀疏性和对场景运动的敏感性，能够有效地识别出视频流中的异常行为。这一创新性工作为基于事件的异常检测奠定了基础，有望在传统相机难以应对的低光照、高速运动或高动态范围场景下实现更鲁棒、高效的异常检测能力。

---

### 142. [[Event-based Vision: A Survey]](http://arxiv.org/abs/1904.08405v3)
<!-- 2019-04-17 -->
**📅 发布日期**: 2019-04-17

*   **👥 作者**: Guillermo Gallego, Tobi Delbruck, Garrick Orchard, Chiara Bartolozzi, Brian Taba, Andrea Censi, Stefan Leutenegger, Andrew Davison, Joerg Conradt, Kostas Daniilidis, Davide Scaramuzza
*   **🎯 研究目的**: 传统帧相机以固定速率捕获图像，而事件相机作为仿生传感器，异步测量像素级亮度变化，并输出编码时间、位置和亮度变化符号的事件流。事件相机相比传统相机具有高时间分辨率（微秒级）、极高动态范围（140 dB vs. 60 dB）、低功耗和低运动模糊等吸引人的特性。本研究旨在对事件视觉这一新兴领域进行全面的综述，总结其独特属性、当前挑战以及在机器人和计算机视觉领域（尤其是在低延迟、高速和高动态范围等挑战性场景）的巨大潜力。
*   **⭐ 主要发现**: 本文作为事件视觉领域的首个全面综述，系统地阐述了事件相机的工作原理、与传统相机的根本区别及其带来的独特优势。它详细介绍了处理事件数据所需的新颖方法和算法范式，涵盖了从事件数据表示、事件流处理到高级视觉任务（如SLAM、目标跟踪、光流估计、姿态估计等）的最新进展。该综述不仅为研究人员提供了事件视觉领域的基础知识和最新技术概览，还指出了未来的研究方向和未解决的挑战，极大地推动了事件相机在机器人、自动驾驶和工业视觉等领域的应用和发展。

---

### 143. [[Focus Is All You Need: Loss Functions For Event-based Vision]](http://arxiv.org/abs/1904.07235v1)
<!-- 2019-04-15 -->
**📅 发布日期**: 2019-04-15

*   **👥 作者**: Guillermo Gallego, Mathias Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是新型视觉传感器，输出像素级亮度变化（“事件”），而非传统视频帧。这些异步传感器具有高时间分辨率、极高动态范围和无运动模糊等优势。为了充分发挥这些传感器的潜力，运动补偿方法至关重要。本研究旨在为事件视觉中的运动补偿方法提供一套全面且客观的损失函数，用于分析事件对齐的质量，从而将传统计算机视觉领域中成熟的工具引入事件相机的数据处理。
*   **⭐ 主要发现**: 论文提出并分类了22种“焦点损失函数”（Focus Loss Functions），用于评估事件相机运动补偿算法中事件对齐的准确性。这些损失函数与传统“从焦点恢复形状”（shape-from-focus）应用中的函数有很强的关联性，能够将成熟的计算机视觉工具和概念引入事件相机领域。通过对这些损失函数在准确性和运行时性能方面的广泛比较，研究为事件视觉算法的开发和评估提供了一个标准化的工具集和基准。这使得研究人员能够更有效地设计和优化基于事件的运动补偿算法，从而解锁事件相机在各种高速、高动态范围应用中的潜力。

---

### 144. [[Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling]](http://arxiv.org/abs/1904.03375v1)
<!-- 2019-04-06 -->
**📅 发布日期**: 2019-04-06

*   **👥 作者**: Jiancheng Yang, Qiang Zhang, Bingbing Ni, Linguo Li, Jinxian Liu, Mengdie Zhou, Qi Tian
*   **🎯 研究目的**: 随着3D传感器的普及，几何深度学习在点云处理中变得日益重要。受自然语言处理（NLP）领域自注意力机制最新进展的启发，本研究旨在将自注意力变换器引入点云处理，以更有效地建模点云数据。此外，针对现有方法在分层选择输入点子集时依赖启发式方法（如最远点采样）的局限性，本研究旨在提出一种端到端可学习且任务无关的采样操作。
*   **⭐ 主要发现**: 论文提出了点注意力变换器（Point Attention Transformers, PATs），它使用参数高效的组混洗注意力（Group Shuffle Attention, GSA）来替代计算成本较高的多头注意力，并证明了PATs处理大小可变输入的能力及其置换等变性。更具创新性的是，论文首次提出了一种端到端可学习且任务无关的采样操作——Gumbel子集采样（Gumbel Subset Sampling, GSS），用于选择具有代表性的输入点子集。GSS克服了传统启发式采样方法的局限性，使得点云处理流程更加自动化和优化。PATs结合GSS在点云分类、分割等任务上展现出优异的性能，显著提升了点云建模的效率和准确性。

---

### 145. [[EventNet: Asynchronous Recursive Event Processing]](http://arxiv.org/abs/1812.07045v2)
<!-- 2018-12-07 -->
**📅 发布日期**: 2018-12-07

*   **👥 作者**: Yusuke Sekikawa, Kosuke Hara, Hideo Saito
*   **🎯 研究目的**: 事件相机作为仿生视觉传感器，模仿视网膜的工作方式，异步报告像素级强度变化，而非定期输出实际强度图像。这种新型图像传感器范式提供了显著的优势，即稀疏和非冗余的数据表示。然而，大多数现有的人工神经网络架构（如CNN）需要密集同步输入数据，因此无法有效利用事件数据的稀疏性。本研究旨在设计一种能够实时处理异步事件流的神经网络，以充分利用事件相机的固有优势。
*   **⭐ 主要发现**: 论文提出了EventNet，一个专门为实时处理异步事件流而设计的神经网络。EventNet以递归和事件驱动的方式处理数据，通过一种新颖的时间编码方案，递归地建模输出对数万个因果事件的依赖关系。与传统方法将事件累积成帧再处理不同，EventNet直接处理离散的事件流，从而避免了将事件数据转换为密集帧所带来的开销和信息损失。这种设计使得EventNet能够充分利用事件数据的稀疏性和异步特性，实现了高效、实时的事件流处理，为事件相机在各种低延迟、高吞吐量应用中的部署提供了新的可能性。

---

### 146. [[Event-based Vision meets Deep Learning on Steering Prediction for Self-driving Cars]](http://arxiv.org/abs/1804.01310v1)
<!-- 2018-04-04 -->
**📅 发布日期**: 2018-04-04

*   **👥 作者**: Ana I. Maqueda, Antonio Loquercio, Guillermo Gallego, Narciso Garcia, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机作为仿生视觉传感器，能够自然捕捉场景动态并过滤冗余信息。本研究旨在探索事件相机在自动驾驶汽车转向角预测这一挑战性运动估计任务中的潜力，并结合深度学习方法，以克服传统相机在恶劣光照条件和高速运动等场景下的局限性，从而提升自动驾驶系统的鲁棒性和安全性。
*   **⭐ 主要发现**: 论文提出了一种基于深度神经网络的方法，将最先进的卷积架构应用于事件传感器的输出，以预测车辆的转向角。通过在一个大型公开事件相机数据集（约1000公里）上的广泛定性和定量评估，研究表明事件相机即使在传统相机失效的挑战性光照条件（如强逆光、夜间）和快速运动场景下，也能实现可靠的转向预测。这证明了事件相机在自动驾驶感知中的巨大潜力，能够为车辆提供更稳定、更鲁棒的运动信息，从而显著提升自动驾驶系统在复杂环境下的性能和安全性。

---

### 147. [[NullHop: A Flexible Convolutional Neural Network Accelerator Based on Sparse Representations of Feature Maps]](http://arxiv.org/abs/1706.01406v2)
<!-- 2017-06-05 -->
**📅 发布日期**: 2017-06-05

*   **👥 作者**: Alessandro Aimar, Hesham Mostafa, Enrico Calabrese, Antonio Rios-Navarro, Ricardo Tapiador-Morales, Iulia-Alexandra Lungu, Moritz B. Milde, Federico Corradi, Alejandro Linares-Barranco, Shih-Chii Liu, Tobi Delbruck
*   **🎯 研究目的**: 卷积神经网络（CNNs）已成为许多最先进视觉处理任务的主导架构。然而，在训练和部署CNNs时常用的图形处理单元（GPUs）在单帧运行时推理的能效较低（通常低于10 GOp/s/W）。本研究旨在设计一种灵活高效的CNN加速器架构，以满足低功耗和低延迟应用场景的需求，通过利用CNN中神经元激活的稀疏性来加速计算并显著减少内存需求。
*   **⭐ 主要发现**: 论文提出了一种名为NullHop的灵活高效CNN加速器架构。NullHop的核心创新在于其能够有效利用CNN中神经元激活的稀疏性，通过跳过零值操作来加速计算并降低内存带宽需求。其灵活的架构设计使得计算资源在1x1到7x7的各种核尺寸下都能得到高利用率，并且能够处理多达128个输入和128个输出特征图，支持高达16位的数据精度。实验结果表明，NullHop在能效方面表现出色，能够以低功耗和低延迟实现最先进的CNN推理，特别适用于边缘计算、嵌入式系统和移动设备等对功耗和延迟有严格要求的应用场景。

---

---

## 生成说明
- 本报告由AI模型自动生成，摘要内容仅供参考。
- 如有错误或遗漏，请以原始论文为准。
