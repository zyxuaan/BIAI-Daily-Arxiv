---
layout: default
title: 2025-09-05 Arxiv论文摘要
---

# Arxiv论文总结报告

## 基本信息
- 生成时间: 2025-09-05 12:27:43
- 使用模型: gemini-2.5-flash
- 论文数量: 9 篇

---

## 论文总结

### [[Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage]](http://arxiv.org/abs/2509.04370v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Dor Cohen, Inga Efrosman, Yehudit Aperstein, Alexander Apartsin
*   **🎯 研究目的**: 描述了急救人员广泛使用执法记录仪记录事件现场以支持事后分析的背景。然而，在时间紧迫的情况下，审查冗长的视频片段是不切实际的。研究的动机是为了提高态势感知能力，需要一种能够快速解释的简洁视觉摘要。核心目标是开发一个计算机视觉流程，将执法记录仪的视频片段转换为信息丰富的全景图像，以总结事件现场。
*   **⭐ 主要发现**: 提出了一种将执法记录仪视频转换为全景事件摘要图像的计算机视觉流程。该方法利用单目同步定位与建图（SLAM）来估计摄像机轨迹并重建环境的空间布局。通过对轨迹上的摄像机姿态进行聚类来识别关键视角，并从每个聚类中选择代表性帧。这些帧被融合到空间连贯的全景图像中，从而提供事件现场的简洁视觉摘要，大大提高了在时间关键情况下的态势感知和事后分析效率。

---

### [[Characteristic Energy Behavior Profiling of Non-Residential Buildings]](http://arxiv.org/abs/2509.04322v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Haley Dozier, Althea Henslee
*   **🎯 研究目的**: 阐述了气候变化和极端天气事件对美国陆军设施基础设施构成的威胁，强调了气候韧性措施的必要性。研究背景是大多数陆军设施依赖商业能源和水源，因此需要了解独立能源资源（如电网、天然气管道）的脆弱性，并建立设施内部能源使用的基线。核心目标是提出一个数据驱动的行为模型，以确定设施的能源使用行为特征，并利用这些特征来创建基线评估。
*   **⭐ 主要发现**: 提出了一种数据驱动的行为模型，用于确定非住宅建筑（特别是陆军设施）的能源使用行为特征。通过分析能源使用数据，该模型能够生成行为档案，这些档案将用于建立能源使用影响的基线评估。这将有助于识别能源消耗模式、评估能源系统的脆弱性，并为制定更有效的气候韧性策略和能源管理措施提供支持，从而保护关键任务设施资产并提高备战能力。

---

### [[How many patients could we save with LLM priors?]](http://arxiv.org/abs/2509.04250v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Shota Arai, David Selby, Andrew Vargo, Sebastian Vollmer
*   **🎯 研究目的**: 探讨了通过利用大型语言模型（LLM）中编码的知识，大幅减少临床试验所需患者数量的可能性，同时保持相同的统计功效。研究动机在于提高临床试验的效率和伦理性，减少患者负担。核心目标是提出一个新颖的框架，用于多中心临床试验中不良事件的分层贝叶斯建模，该框架利用LLM提供的先验分布。
*   **⭐ 主要发现**: 提出了一个新颖的框架，用于在多中心临床试验中对不良事件进行分层贝叶斯建模，其创新点在于利用大型语言模型（LLM）来获取参数化先验分布。与生成合成数据的数据增强方法不同，该方法直接从LLM中系统地提取分层贝叶斯模型中超参数的信息性先验，从而将外部临床专业知识直接整合到贝叶斯安全性建模中。通过全面的温度敏感性分析和对真实世界临床数据的严格交叉验证，证明了该方法能够显著减少临床试验所需的患者数量，同时保持统计功效，从而加速药物开发过程并降低相关成本和风险。

---

### [[Explicit and Implicit Data Augmentation for Social Event Detection]](http://arxiv.org/abs/2509.04202v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Qing Li, Hu Wang, Preslav Nakov
*   **🎯 研究目的**: 旨在解决社交事件检测（SED）任务中对大量标注数据依赖的问题。社交事件检测涉及从社交媒体中识别和分类重要事件，但标注数据成本高昂且劳动密集。研究动机是为了在数据稀缺的情况下提高SED模型的性能和鲁棒性。核心目标是提出一个即插即用的双重增强框架（SED-Aug），结合显式文本增强和隐式特征空间增强来提升数据多样性和模型鲁棒性。
*   **⭐ 主要发现**: 提出了一个名为SED-Aug的即插即用双重增强框架，用于社交事件检测，有效解决了标注数据稀缺的问题。该框架结合了显式文本增强和隐式特征空间增强。显式增强利用大型语言模型通过五种不同的生成策略来丰富文本信息。隐式增强则设计了五种新颖的扰动技术，在结构融合嵌入的特征空间中进行操作，这些扰动旨在保持嵌入的语义和关系特性。实验结果表明，SED-Aug显著增强了数据多样性，提高了模型的鲁棒性，并在社交事件检测任务中取得了优异的性能。

---

### [[DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset]](http://arxiv.org/abs/2509.04117v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Mustafa Sakhai, Kaung Sithu, Min Khant Soe Oke, Maciej Wielgosz
*   **🎯 研究目的**: 鉴于事件相机（如动态视觉传感器DVS）在低延迟、高动态范围和运动鲁棒性方面的优势，研究旨在利用其特性来改进行人检测和穿越意图分析。核心目标是创建一个名为DVS-PedX的神经形态数据集，专门用于在正常和恶劣天气条件下进行行人检测和穿越意图分析。
*   **⭐ 主要发现**: 发布了DVS-PedX数据集，这是一个结合了合成和真实事件流的神经形态数据集，专为行人检测和穿越意图分析而设计。该数据集包含两个互补来源：1) 在CARLA模拟器中生成的合成事件流，用于在不同天气和光照条件下控制“接近-穿越”场景；2) 使用v2e工具将真实世界的JAAD行车记录仪视频转换为事件流，保留了自然的行人行为和背景。每个序列都包含配对的RGB帧、每帧DVS“事件帧”（33毫秒累积）以及帧级标签（穿越与否），为研究事件相机在复杂环境下的行人感知提供了宝贵资源，并有望推动事件视觉领域的发展。

---

### [[TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph]](http://arxiv.org/abs/2509.04086v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Yaru Chen, Faegheh Sardari, Peiliang Zhang, Ruohao Guo, Yang Xiang, Zhenbo Li, Wenwu Wang
*   **🎯 研究目的**: 旨在解决音频-视觉视频解析（AVVP）任务中的挑战。AVVP的目标是在给定视频中识别事件类别及其发生时间，通常使用弱监督标签。现有方法在处理噪声段级伪标签和无差别注意力传播时，容易导致初始错误在训练过程中被反复放大。研究动机是克服这些局限性，提高AVVP模型的准确性和鲁棒性。核心目标是提出一种结合双向文本融合（BiT）模块和类别感知时间图（CATS）模块的新方法。
*   **⭐ 主要发现**: 提出了一种名为TEn-CATS的新方法，用于音频-视觉视频解析，有效解决了现有方法中噪声伪标签和无差别注意力传播导致错误放大的问题。TEn-CATS结合了双向文本融合（BiT）模块和类别感知时间图（CATS）模块。BiT模块通过引入文本信息丰富了多模态特征表示，而CATS模块则构建了一个多尺度、类别感知的时间图，能够更精确地建模事件的时间关系和类别特异性。通过这种结合，TEn-CATS能够更有效地利用弱监督信息，减少噪声影响，并实现对事件类别和发生时间的精确识别，显著提升了AVVP任务的性能。

---

### [[Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection]](http://arxiv.org/abs/2509.03872v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Nan Yang, Yang Wang, Zhanwen Liu, Yuchao Dai, Yang Liu, Xiangmo Zhao
*   **🎯 研究目的**: 旨在解决现有RGB-事件目标检测方法中存在的计算冗余和性能次优问题。现有方法在特征提取和融合过程中，对两种模态（图像中的背景和事件数据中的非事件区域）的低信息区域进行统一处理，导致计算成本高昂。尽管已有一些针对图像和事件模态的token稀疏化方法，但它们通常采用固定的token选择数量或阈值，这限制了对不同复杂性样本中信息性token的保留。研究动机是为了在准确性和效率之间取得更好的平衡。核心目标是提出一种名为FocusMamba的新方法。
*   **⭐ 主要发现**: 提出了一种名为FocusMamba的新方法，用于高效的RGB-事件协同token稀疏化目标检测。该方法通过执行多模态特征的自适应协同稀疏化，解决了现有方法中计算冗余和信息性token保留不足的问题。FocusMamba能够根据样本的复杂性动态选择和保留最具信息量的token，从而有效整合RGB和事件模态的互补信息。实验结果表明，FocusMamba在显著降低计算成本的同时，保持甚至提升了目标检测的准确性，实现了效率与性能的更好平衡，为实时、低功耗的RGB-事件感知系统提供了新的解决方案。

---

### [[Predicting Traffic Accident Severity with Deep Neural Networks]](http://arxiv.org/abs/2509.03819v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Meghan Bibb, Pablo Rivas, Mahee Tayba
*   **🎯 研究目的**: 旨在通过研究交通事故来降低未来事故的风险。随着机器学习的最新进展，为分析交通事故相关数据提供了新的途径，特别是那些在不平衡数据上仍能实现良好泛化和高预测能力的模型。研究动机是利用这些先进技术来改进交通事故严重程度的预测。核心目标是研究基于神经网络的模型在交通事故数据上的应用，以分类事故严重程度。
*   **⭐ 主要发现**: 研究了基于神经网络的模型在交通事故数据上的应用，以预测事故严重程度。该方法首先分析了相对特征共线性，并通过自编码器进行无监督降维，随后将降维后的特征输入到一个密集网络中。实验结果表明，使用所提出的深度神经网络对事故严重程度进行分类时，交叉验证的准确率高达92%。这一发现证明了深度神经网络在处理交通事故数据和预测其严重程度方面的强大能力，为交通安全管理和风险缓解提供了有效的工具。

---

### [[EGTM: Event-guided Efficient Turbulence Mitigation]](http://arxiv.org/abs/2509.03808v1)
<!-- 2025-09-04 -->
**📅 发布日期**: 2025-09-04

*   **👥 作者**: Huanan Li, Rui Fan, Juntao Guan, Weidong Hao, Lai Rui, Tong Wu, Yikai Wang, Lin Gu
*   **🎯 研究目的**: 旨在解决大气湍流对帧相机引入的随机失真和模糊问题，即湍流缓解（TM）任务。现有最先进的深度学习TM方法通过从多个退化帧中提取湍流线索来寻找“幸运”的未失真补丁进行“幸运融合”。然而，这些方法需要高容量网络来学习同步帧之间粗粒度的湍流动态，且受限于帧率，导致计算和存储效率低下。研究动机是利用事件相机微秒级时间分辨率的优势，从根本上解决这一瓶颈。核心目标是提出一种事件引导的有效湍流缓解方法。
*   **⭐ 主要发现**: 提出了一种名为EGTM（Event-guided Efficient Turbulence Mitigation）的事件引导高效湍流缓解方法。该研究首先提出了基础的“事件-幸运洞察”（"event-lucky insight"），揭示了事件数据与湍流动态之间的相关性。事件相机凭借其微秒级的时间分辨率和高效的稀疏异步成像机制，能够捕捉到传统帧相机无法获得的精细湍流信息。EGTM利用这些事件数据来指导湍流缓解过程，从而避免了高容量网络和粗粒度学习的限制。通过利用事件相机的优势，EGTM在计算和存储效率方面显著优于现有方法，同时有效地消除了大气湍流引起的失真和模糊，为实时、高效的湍流缓解提供了新的范式。

---

---

## 生成说明
- 本报告由AI模型自动生成，摘要内容仅供参考。
- 如有错误或遗漏，请以原始论文为准。
