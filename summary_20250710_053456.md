---
layout: default
title: 2025-07-10 Arxiv论文摘要
---

# Arxiv论文总结报告

## 基本信息
- 生成时间: 2025-07-10 14:05:18
- 使用模型: gemini-2.5-flash
- 论文数量: 147 篇

---

## 论文总结

### [EA: An Event Autoencoder for High-Speed Vision Sensing](http://arxiv.org/abs/2507.06459v1)
**📅 发布日期**: 2025-07-09

*   **👥 作者**: Riadul Islam, Joey Mulé, Dhandeep Challagundla, Shahmir Rizvi, Sean Carson
*   **🎯 研究目的**: 高速视觉感知对于机器人、自动驾驶和工业自动化等应用的实时感知至关重要。传统的基于帧的视觉系统存在运动模糊、高延迟和数据冗余等问题，限制了它们在动态环境中的性能。事件相机作为一种有前景的替代方案，能够异步捕获像素级的亮度变化，但其稀疏且噪声大的事件流给目标检测带来了挑战。为解决这些问题，本文旨在提出一种事件自编码器架构，旨在高效压缩和重建事件数据，同时保留关键的空间和时间特征。
*   **⭐ 主要发现**: 论文的核心贡献是提出了一种名为EA（Event Autoencoder）的事件自编码器架构。该架构能够高效地压缩和重建事件数据，同时有效保留了事件流中至关重要的空间和时间特征。所提出的模型采用了卷积编码（convolutional encoding）机制，并集成了自适应阈值选择（adaptive threshold selection）以及一个轻量级分类器（lightweight classifier）。通过这种设计，EA模型有望克服事件相机数据稀疏和噪声大的挑战，从而提升事件相机在高速动态环境下的感知能力，为实时视觉感知应用提供更高效和鲁棒的解决方案。

---
### [[Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking]](http://arxiv.org/abs/2506.23783v1)
**📅 发布日期**: 2025-06-30

*   **👥 作者**: Shiao Wang, Ju Huang, Qingchuan Ma, Jinfeng Gao, Chunyi Xu, Xiao Wang, Lan Chen, Bo Jiang
*   **🎯 研究目的**: 近年来，结合传统RGB相机与仿生事件相机进行鲁棒目标跟踪的研究日益受到关注。然而，现有的大多数多模态跟踪算法在特征提取和跨模态融合方面严重依赖于高复杂度的Vision Transformer架构。这种依赖不仅导致了巨大的计算开销，还限制了跨模态交互的有效性。本研究旨在解决这些问题，提出一种更高效的帧-事件视觉目标跟踪框架，以降低计算成本并提升跨模态交互的有效性。
*   **⭐ 主要发现**: 本文提出了一种名为Mamba-FETrack V2的、基于线性复杂度Vision Mamba网络的RGB-事件目标跟踪框架，旨在解决现有基于Transformer的方法所面临的计算开销大和跨模态交互受限的问题。Mamba-FETrack V2的核心创新在于其采用了高效的Vision Mamba架构，并引入了一个轻量级的Prompt Generator。该生成器能够利用来自每种模态的嵌入特征以及一个共享的提示池，动态生成模态特定的可学习提示，从而优化跨模态特征的融合与交互。通过引入Vision Mamba，Mamba-FETrack V2有望显著降低计算复杂度，并提升帧-事件视觉目标跟踪的效率和性能，为该领域提供一个高效且高性能的解决方案。

---
### [[An efficient neuromorphic approach for collision avoidance combining Stack-CNN with event cameras]](http://arxiv.org/abs/2506.16436v1)
<!-- 2025-06-19 -->
**📅 发布日期**: 2025-06-19

*   **👥 作者**: Antonio Giulio Coretti, Mattia Varile, Mario Edoardo Bertaina
*   **🎯 研究目的**: 太空碎片对航天活动构成日益增长的重大威胁，这推动了对主动和被动缓解策略的研究。本研究旨在开发一种创新的碰撞规避系统，该系统利用事件相机——一种特别适用于空间态势感知（SSA）和空间交通管理（STM）的新型成像技术，以应对这一挑战。
*   **⭐ 主要发现**: 本研究提出的系统核心在于其采用Stack-CNN算法（该算法此前已成功应用于流星检测），能够实时分析事件相机数据，以高效检测微弱的移动物体。通过在地面数据上进行的测试，结果表明该算法能够显著提升信噪比。这一创新方法为未来的机载空间成像提供了极具前景的解决方案，并有望大幅改进空间交通管理（STM）和空间态势感知（SSA）的效率和准确性。

---
### [[Sparse Convolutional Recurrent Learning for Efficient Event-based Neuromorphic Object Detection]](http://arxiv.org/abs/2506.13440v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2025-06-16

*   **👥 作者**: Shenqi Wang, Yingfu Xu, Amirreza Yousefzadeh, Sherif Eissa, Henk Corporaal, Federico Corradi, Guangzhi Tang
*   **🎯 研究目的**: 事件相机凭借其高时间分辨率和动态范围，在汽车和机器人应用中能显著提升目标检测的性能和安全性。然而，处理稀疏事件数据需要计算密集型的卷积循环单元，这使得它们难以集成到资源受限的边缘应用中。本研究旨在解决这一挑战，提出一种高效的事件目标检测方法，特别适用于神经形态处理器，以降低计算成本并实现高效的时空推理。
*   **⭐ 主要发现**: 本论文提出了稀疏事件高效检测器（Sparse Event-based Efficient Detector, SEED），旨在实现神经形态处理器上的高效事件目标检测。SEED的核心创新在于引入了“稀疏卷积循环学习”（sparse convolutional recurrent learning）机制。该机制在循环处理中实现了超过92%的激活稀疏度，极大地降低了稀疏事件数据时空推理的计算成本。研究人员在Prophesee的1 Mpx和Gen1事件目标检测数据集上验证了所提出方法的有效性，证明了SEED能够显著提升在资源受限环境下处理事件数据的效率，为自动驾驶和机器人技术中的实时、低功耗目标检测提供了新的解决方案。

---
### [[Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach]](http://arxiv.org/abs/2505.12903v1)
**📅 发布日期**: 2025-05-19

*   **👥 作者**: Shiao Wang, Xiao Wang, Liye Jin, Bo Jiang, Lin Zhu, Lan Chen, Yonghong Tian, Bin Luo
*   **🎯 研究目的**: 现有视觉目标跟踪算法普遍依赖低帧率RGB相机和计算密集型深度神经网络，这导致了固有的高延迟问题，并且难以在资源受限的环境中有效运行。为解决这些挑战，基于仿生事件相机的视觉目标跟踪作为一种新兴研究方向，在低延迟应用中展现出显著优势。本文旨在提出一种名为SFTrack的新型慢-快跟踪范式，该范式能够灵活适应不同的操作需求，并支持两种互补的模式，其中包括一种适用于计算资源充足场景的高精度慢速跟踪器。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种新颖的“慢-快跟踪”（SFTrack）范式，旨在解决传统基于帧的跟踪方法在高延迟和资源受限环境下的局限性。SFTrack的创新之处在于其能够灵活适应不同的操作需求，通过支持两种互补的跟踪模式实现：一种是针对计算资源充足场景设计的高精度慢速跟踪器。这种双模态方法为实现基于事件流的低延迟视觉目标跟踪提供了新的解决方案，有望显著提升跟踪系统在多样化应用场景下的性能和适应性。

---
### [[Maximizing Asynchronicity in Event-based Neural Networks]](http://arxiv.org/abs/2505.11165v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2025-05-16

*   **👥 作者**: Haiqing Hao, Nikola Zubić, Weihua He, Zhipeng Sui, Davide Scaramuzza, Wenhui Wang
*   **🎯 研究目的**: 事件相机以其高时间分辨率、低延迟和最小冗余的特点，提供了独特的视觉数据。然而，它们异步、稀疏的序列特性对传统的基于张量的机器学习（ML）方法构成了挑战。尽管最近的异步到同步（A2S）范式旨在通过异步编码事件为学习表示来弥合这一鸿沟，但现有的A2S方法通常牺牲了表示的表达能力和泛化能力，不如密集、同步的方法。本研究旨在解决现有A2S方法的局限性，提出一个新颖的A2S框架，以生成高度表达和泛化能力的逐事件表示，从而更好地利用事件相机的优势。
*   **⭐ 主要发现**: 本文的核心贡献是引入了EVA（事件异步表示学习），这是一个新颖的异步到同步（A2S）框架。EVA旨在克服现有A2S方法在表示表达能力和泛化能力上的不足，通过生成高度表达和泛化能力的逐事件表示来最大化事件相机的异步性优势。其创新之处在于，EVA受到事件与语言之间类比的启发，独特地借鉴并适应了语言建模，特别是在线性注意力方面的最新进展。这一方法有望显著提升基于事件数据的机器学习模型的性能和适用范围。

---
### [[Contactless Cardiac Pulse Monitoring Using Event Cameras]](http://arxiv.org/abs/2505.09529v2)
**📅 发布日期**: 2025-05-14

*   **👥 作者**: Mohamed Moustafa, Joseph Lemley, Peter Corcoran
*   **🎯 研究目的**: 本研究旨在探索利用事件相机（一种具有极低延迟、低功耗、高动态范围和高时间分辨率的新型传感技术）实现非接触式心搏信号监测的可能性。传统的心率监测方法多为接触式，存在一定局限性。本研究的核心目标是开发并评估一个监督式卷积神经网络（CNN）模型，该模型能够从事件相机记录的面部事件流中非接触地重建个体的***心搏信号***，并通过计算心率的准确性来评估模型性能，从而为非接触式生理信号监测提供一种创新且高效的解决方案。
*   **⭐ 主要发现**: 本研究的核心贡献在于首次提出并验证了利用事件相机进行非接触式心搏信号监测的可行性。研究团队开发了一个端到端的监督式卷积神经网络（CNN）模型，该模型能够直接从事件流的二维表示中提取心搏信号。通过对模型性能基于计算心率准确性的评估，实验结果证实了从事件相机数据中有效提取生理心搏信号的能力。这项工作不仅展示了事件相机在生物医学信号处理领域的巨大潜力，也为远程健康监测和无创生理参数监测等应用开辟了新的途径。

---
### [[A Survey of 3D Reconstruction with Event Cameras]](http://arxiv.org/abs/2505.08438v2)
**📅 发布日期**: 2025-05-13

*   **👥 作者**: Chuanzhi Xu, Haoxian Zhou, Langyi Chen, Haodong Chen, Ying Zhou, Vera Chung, Qiang Qu, Weidong Cai
*   **🎯 研究目的**: 事件相机作为一种新兴的视觉传感器，在三维重建领域展现出巨大潜力。它们能够异步捕获像素级的亮度变化，生成稀疏但时间密度高的数据流。相较于传统帧式相机，事件相机在高速运动、低光照和极端动态范围等挑战性条件下，仍能实现鲁棒且精确的三维重建。鉴于其在自动驾驶、机器人、航空导航和虚拟现实等领域的广阔应用前景，本研究旨在提供首个专门针对基于事件相机的三维重建技术的全面综述，系统地分类和回顾现有方法，以推动该领域的发展。
*   **⭐ 主要发现**: 本综述的核心贡献在于它是**首个专门针对基于事件相机的三维重建技术的全面回顾**。论文系统地分类了现有方法（尽管摘要未详细说明分类标准，但明确指出将基于输入等进行分类）。它深入阐述了事件相机在三维重建中的独特优势，包括在高速运动、低光照和高动态范围等传统相机难以应对的极端条件下，依然能够实现高精度和鲁棒性的三维重建。通过对该领域现有研究的系统梳理，本综述为研究人员提供了事件相机三维重建领域的现状概览，并突出了其在自动驾驶、机器人、航空导航和沉浸式虚拟现实等变革性应用中的巨大潜力，为未来的研究和发展奠定了基础。

---
### [[Hybrid Spiking Vision Transformer for Object Detection with Event Cameras]](http://arxiv.org/abs/2505.07715v1)
**📅 发布日期**: 2025-05-12

*   **👥 作者**: Qi Xu, Jie Deng, Jiangrong Shen, Biwu Chen, Huajin Tang, Gang Pan
*   **🎯 研究目的**: 基于事件的物体检测因其高时间分辨率、宽动态范围和异步地址事件表示等优势而日益受到关注。脉冲神经网络（SNNs）作为一种有前景的方法，能耗低且具有丰富的时空动态特性，非常适合利用事件相机的这些优势。本研究旨在进一步提升基于事件的物体检测性能，并为此提出了一种新颖的混合脉冲视觉Transformer（HsVT）模型。
*   **⭐ 主要发现**: 本文提出了一种创新的混合脉冲视觉Transformer（HsVT）模型，旨在有效提升基于事件的物体检测能力。HsVT模型的核心创新在于其集成了两个关键模块：一个专门用于捕获局部和全局特征的空间特征提取模块，以及一个用于建模事件序列中时间依赖性和长期模式的时间特征提取模块。这种独特的结合使得HsVT模型能够高效地捕获事件数据中的时空特征，从而显著增强其处理复杂事件流并进行精确物体检测的能力。

---
### [[Iterative Event-based Motion Segmentation by Variational Contrast Maximization]](http://arxiv.org/abs/2504.18447v1)
**📅 发布日期**: 2025-04-25

*   **👥 作者**: Ryo Yamaki, Shintaro Shiba, Guillermo Gallego, Yoshimitsu Aoki
*   **🎯 研究目的**: 事件相机因其对场景变化的响应特性，能提供丰富的信号，非常适用于运动估计。然而，场景中任何视觉变化都会产生事件数据，因此，将这些数据分类为不同的运动（即“运动分割”）变得至关重要。这项研究旨在解决事件数据中运动分割的挑战，从而为目标检测和视觉伺服等多种下游任务提供基础支持。
*   **⭐ 主要发现**: 本文提出了一种创新的迭代运动分割方法，该方法通过将事件数据分类为背景（主导运动假设）和前景（独立运动残差），从而有效地扩展了现有的对比度最大化（Contrast Maximization）框架。实验结果表明，所提出的方法在公共数据集和自录数据集中均能成功地对事件簇进行分类。它能够生成清晰、经过运动补偿的类边缘图像，显著提升了运动分割的质量。此外，该方法在性能上达到了先进水平，展现了其在事件相机运动分割领域的强大潜力。

---
### [[Event-Based Eye Tracking. 2025 Event-based Vision Workshop]](http://arxiv.org/abs/2504.18249v1)
**📅 发布日期**: 2025-04-25

*   **👥 作者**: Qinyu Chen, Chang Gao, Min Liu, Daniele Perrone, Yan Ru Pei, Zuowen Wang, Zhuo Zou, Shihang Tan, Tao Han, Guorui Lu, Zhen Xu, Junyuan Ding, Ziteng Wang, Zongwei Wu, Han Han, Yuliang Wu, Jinze Chen, Wei Zhai, Yang Cao, Zheng-jun Zha, Nuwan Bandara, Thivya Kandappu, Archan Misra, Xiaopeng Lin, Hongxiang Huang, Hongwei Ren, Bojun Cheng, Hoang M. Truong, Vinh-Thuan Ly, Huy G. Tran, Thuan-Phat Nguyen, Tram T. Doan
*   **🎯 研究目的**: 本综述旨在为2025年CVPR事件相机视觉研讨会中举办的“2025事件相机眼动追踪挑战赛”提供回顾。该挑战赛的核心任务是通过处理事件相机记录的眼球运动数据来预测瞳孔中心。本论文的目的是总结并推广挑战赛中顶尖团队的创新方法，以期推动未来事件相机眼动追踪领域的研究进展。
*   **⭐ 主要发现**: 本论文回顾并总结了在“2025事件相机眼动追踪挑战赛”中排名前列团队所提出的创新方法。对于每种方法，论文详细报告了其准确性、模型大小以及操作次数等关键性能指标，为研究人员提供了量化的参考。此外，本综述还从硬件设计的角度深入探讨了事件相机眼动追踪技术，强调了硬件在提升系统性能和实用性方面的重要性。通过对顶尖算法的分析和硬件层面的讨论，本研究为事件相机眼动追踪领域的未来发展提供了全面的视角和指导，有望加速该领域的技术突破和应用落地。

---
### [[DERD-Net: Learning Depth from Event-based Ray Densities]](http://arxiv.org/abs/2504.15863v1)
<!-- 2025-04-22 -->
**📅 发布日期**: 2025-04-22

*   **👥 作者**: Diego de Oliveira Hitzges, Suman Ghosh, Guillermo Gallego
*   **🎯 研究目的**: 事件相机因其能够在高速和宽泛光照条件下检测无模糊的3D边缘，为多视角立体深度估计和同步定位与建图（SLAM）提供了有前景的途径。然而，为传统相机设计的深度学习框架难以处理事件数据的异步流式特性，因为它们的架构是为离散的图像类输入优化的。本研究旨在解决这一挑战，提出一个可扩展、灵活且适应性强的框架，用于事件相机在单目和立体设置中的像素级深度估计。
*   **⭐ 主要发现**: 论文提出了一种名为DERD-Net的新型深度学习框架，专门用于利用事件相机数据进行像素级深度估计。其核心创新在于将3D场景结构编码为视差空间图像（DSIs）。这些DSIs通过将事件数据通过已知的相机姿态反投影到空间中，从而表示光线的空间密度。所提出的神经网络能够有效处理这种独特的DSI表示，从而实现对事件数据的深度感知。该框架在单目和立体设置下均能进行深度估计，展现了其灵活性和适应性。这项工作为处理事件相机特有的异步数据流提供了一种有效范式，克服了传统深度学习方法在处理此类数据时的局限性，为高速、宽光照范围下的机器人感知和计算机视觉应用开辟了新途径。

---
### [[Event2Vec: Processing neuromorphic events directly by representations in vector space]](http://arxiv.org/abs/2504.15371v1)
**📅 发布日期**: 2025-04-21

*   **👥 作者**: Wei Fang, Priyadarshini Panda
*   **🎯 研究目的**: 神经形态事件相机在时间分辨率、能效和动态范围方面相较于传统相机具有显著优势。然而，它们输出的异步、稀疏和不规则事件与主流计算机视觉及深度学习方法不兼容。现有解决方案通常需要冗长的预处理、牺牲时间分辨率或不兼容大规模并行计算。本研究旨在解决这一核心问题，通过提出一种新的事件表示方法，使神经形态事件能够直接被处理，从而充分利用其优势并与现有深度学习框架兼容。
*   **⭐ 主要发现**: 论文的核心贡献是提出了首个“事件到向量”（Event2Vec）表示方法。受“词到向量”（Word2Vec）成功的启发，作者总结了事件与词之间的相似性，并基于此构建了Event2Vec。这种方法旨在直接处理神经形态事件，避免了传统方法中冗长的预处理、时间分辨率损失以及与大规模并行计算不兼容的问题。通过在ASL-DVS数据集上进行分类验证，Event2Vec展示了令人印象深刻的参数效率和准确性。这项创新为神经形态事件数据的直接处理和与主流深度学习框架的融合开辟了新途径，有望推动事件相机在计算机视觉领域的应用。

---
### [[CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework]](http://arxiv.org/abs/2504.12576v1)
**📅 发布日期**: 2025-04-17

*   **👥 作者**: Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu
*   **🎯 研究目的**: 事件相机因其高动态范围、高时间分辨率、低功耗和低延迟等优势，近年来受到越来越多的关注。尽管一些研究者已开始探索直接在事件数据上进行预训练，但这些努力往往未能与RGB图像建立强有力的连接，从而限制了它们在多模态融合场景中的适用性。为解决这些问题，本文旨在提出一个新颖的CM3AE预训练框架，专为RGB-事件感知而设计。该框架的目标是接受包括RGB图像、事件图像和事件体素在内的多模态/视图数据作为输入，从而为基于事件和基于RGB-事件融合的下游任务提供强大的支持。
*   **⭐ 主要发现**: 本文提出了CM3AE，一个统一的RGB帧和事件体素/帧预训练框架，显著提升了RGB-事件感知能力。CM3AE的核心创新在于其能够处理并融合多种模态数据（包括RGB图像、事件图像和事件体素），从而弥补了现有事件数据预训练方法与RGB帧之间连接不足的缺陷。通过设计一个多模态融合重建模块，CM3AE能够有效学习跨模态的关联性，为事件相机和RGB相机融合的下游任务（如目标检测、语义分割等）提供了强大的基础模型。这一统一的预训练范式有望推动多模态感知领域的发展，特别是在需要高动态、高时间分辨率和低延迟的应用中。

---
### [[Perturbed State Space Feature Encoders for Optical Flow with Event Cameras]](http://arxiv.org/abs/2504.10669v1)
**📅 发布日期**: 2025-04-14

*   **👥 作者**: Gokul Raju Govinda Raju, Nikola Zubić, Marco Cannici, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机因其对运动的响应特性，在光流估计方面相比传统相机具有显著优势。然而，尽管深度学习已改进了传统方法，当前用于事件相机光流估计的神经网络在时空推理方面仍面临局限。本文旨在解决这些挑战，提出了一种名为“扰动状态空间特征编码器”（P-SSE）的新方法，用于事件相机的多帧光流估计。
*   **⭐ 主要发现**: 本文的核心贡献是提出了扰动状态空间特征编码器（P-SSE）。P-SSE能够自适应地处理时空特征，并具有类似于Transformer模型的大感受野。同时，它保持了状态空间模型（SSM）固有的线性计算复杂度，从而兼顾了性能与效率。模型实现最先进性能的关键创新在于其应用于状态动态矩阵的扰动技术。
### [[RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework]](http://arxiv.org/abs/2504.10018v1)
**📅 发布日期**: 2025-04-14

*   **👥 作者**: Xiao Wang, Haiyang Wang, Shiao Wang, Qiang Chen, Jiandong Jin, Haoyu Song, Bo Jiang, Chenglong Li
*   **🎯 研究目的**: 现有行人属性识别方法主要依赖RGB相机，但在低光照、高运动模糊等挑战性环境下性能受限。此外，当前研究多集中于行人外貌和衣着，鲜有涉及情感维度。为解决这些问题，本文旨在提出一种新颖的多模态RGB-事件行人属性识别任务，并利用事件相机在低光、高速和低功耗方面的独特优势，克服传统RGB相机的局限性，从而提升行人属性识别的鲁棒性和准确性。
*   **⭐ 主要发现**: 本文的核心贡献在于：
    *   **首次构建大规模多模态数据集**: 引入了首个大规模多模态行人属性识别数据集EventPAR，该数据集包含10万对RGB-事件数据，为RGB-事件多模态行人属性识别任务提供了开创性的基准。
    *   **提出非对称RWKV融合框架**: 设计了一种新颖的非对称RWKV融合框架，旨在有效融合RGB图像和事件流数据，以充分利用两种模态的互补信息，从而提升行人属性识别的准确性和鲁棒性。
    *   **拓展属性识别维度**: 论文重新审视了现有行人属性识别的局限性，并为未来探索行人情感维度识别奠定了基础，有望推动该领域向更全面、更智能的方向发展。

---
### [[Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset]](http://arxiv.org/abs/2504.05830v1)
**📅 发布日期**: 2025-04-08

*   **👥 作者**: Shiao Wang, Xiao Wang, Bo Jiang, Lin Zhu, Guoqi Li, Yaowei Wang, Yonghong Tian, Jin Tang
*   **🎯 研究目的**: 人类活动识别（HAR）传统上依赖于RGB相机，但在光照不足和快速运动等实际挑战下性能受限。为了克服这些限制，仿生事件相机提供了一种有前景的解决方案。本研究旨在结合RGB和事件相机，重新审视人类活动识别，以提高其在复杂环境下的性能和鲁棒性。
*   **⭐ 主要发现**: 论文的核心贡献在于提出了一个大规模多模态RGB-事件人类活动识别基准数据集HARDVS 2.0，旨在弥补现有数据集的不足。该数据集涵盖了300类日常真实世界动作，包含总计107,646个配对视频，为RGB-事件融合的HAR研究提供了丰富的资源。此外，论文还提出了一种多模态热传导模型，用于结合RGB和事件数据进行活动识别。这些创新为克服传统RGB相机在复杂场景下的局限性提供了新的方向和工具，有望推动多模态HAR领域的发展。

---
### [[Simultaneous Motion And Noise Estimation with Event Cameras]](http://arxiv.org/abs/2504.04029v1)
**📅 发布日期**: 2025-04-05

*   **👥 作者**: Shintaro Shiba, Yoshimitsu Aoki, Guillermo Gallego
*   **🎯 研究目的**: 事件相机作为新兴的视觉传感器，其噪声特性难以准确描述。当前针对事件相机的去噪方法通常将去噪与运动估计等其他任务独立（即顺序地）进行处理。然而，由于场景边缘的感知离不开运动，运动实际上是事件数据固有的组成部分。基于这一认识，本研究的核心目标是提出一种能够同时估计事件相机噪声及其多种形式运动（如相机自身运动、光流）的新方法，以解决现有方法中去噪与运动估计分离的局限性。
*   **⭐ 主要发现**: 本文提出了据作者所知首个能够同时进行事件相机噪声估计和多种形式运动（如相机自身运动、光流）估计的方法。该方法的一大创新点在于其高度的灵活性，允许研究人员将广泛使用的“对比度最大化”框架中原有的单步运动估计替换为任何其他运动估计器，包括先进的深度神经网络，从而极大地扩展了其应用潜力。实验结果表明，所提出的方法在E-MLB去噪基准测试中取得了最先进（state-of-the-art）的性能，这证明了其在解决事件相机噪声和运动估计耦合问题上的有效性和优越性，为未来事件数据处理提供了新的范式。

---
### [[EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling]](http://arxiv.org/abs/2504.02402v1)
**📅 发布日期**: 2025-04-03

*   **👥 作者**: Hao Yin, Shi Guo, Xu Jia, Xudong XU, Lu Zhang, Si Liu, Dong Wang, Huchuan Lu, Tianfan Xue
*   **🎯 研究目的**: 声音波纹撞击物体会引起振动，产生高频且细微的视觉变化，这些变化可以用于恢复声音。早期的研究方法在采样率、带宽、视场和光学路径的简洁性等方面面临权衡取舍。事件相机硬件的最新进展因其捕获高频信号的卓越能力，在视觉声音恢复领域显示出巨大潜力。然而，现有的基于事件的振动恢复方法在声音恢复方面仍未能达到最优效果。本研究旨在提出一种新颖的非接触式声音恢复流程，充分利用事件流中的时空信息，以克服现有方法的局限性，实现更有效的声音恢复。
*   **⭐ 主要发现**: 本文提出了一种名为EvMic的新颖非接触式声音恢复流程，该流程通过有效利用事件流中的时空信息，显著提升了声音恢复的性能。为了解决训练数据不足的问题，研究团队首先开发了一种新颖的仿真管线，用于生成大规模的训练数据集。尽管摘要未完全展开后续的设计细节，但其核心创新在于对事件相机数据时空信息的深度挖掘和利用，以解决现有事件相机方法在声音恢复方面存在的不足，为高频、非接触式声音恢复提供了新的解决方案。

---
### [[A Survey on Event-driven 3D Reconstruction: Development under Different Categories]](http://arxiv.org/abs/2503.19753v3)
**📅 发布日期**: 2025-03-25

*   **👥 作者**: Chuanzhi Xu, Haoxian Zhou, Haodong Chen, Vera Chung, Qiang Qu
*   **🎯 研究目的**: 本研究旨在对事件驱动的3D重建方法进行全面综述。鉴于事件相机因其高时间分辨率、低延迟和高动态范围而在3D重建领域日益受到关注，它们能够异步捕获逐像素亮度变化，从而在快速运动和挑战性光照条件下实现精确重建。本论文旨在系统地回顾现有方法，包括立体、单目和多模态系统，并根据几何、基于学习和混合方法对最新进展进行分类，以梳理该领域的发展脉络并支持未来的研究。
*   **⭐ 主要发现**: 本论文对事件驱动的3D重建方法进行了全面的回顾，这是其核心贡献。研究将现有方法细分为立体、单目和多模态系统，并进一步根据几何方法、基于学习的方法和混合方法对近期发展进行了详细分类。此外，论文还涵盖了与事件数据结合的新兴趋势，例如神经辐射场（Neural Radiance Fields）和3D高斯泼溅（3D Gaussian Splatting）。相关工作按时间顺序进行结构化，清晰地展示了该领域的创新和进展。通过提供一个结构化的综述，本研究为未来的事件驱动3D重建研究提供了宝贵的参考和支持。

---
### [[EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation]](http://arxiv.org/abs/2503.18552v2)
**📅 发布日期**: 2025-03-24

*   **👥 作者**: Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu
*   **🎯 研究目的**: 传统的人体动画方法通常依赖从视频数据中提取的姿态运动线索来驱动静态参考图像的动画生成。然而，这些基于视频的线索存在固有的局限性，例如时间分辨率低、易受运动模糊影响以及在复杂光照条件下性能不可靠。针对这些问题，本研究旨在探索事件相机所提供的独特优势——其固有的高时间分辨率和对运动模糊、低光照及曝光变化的鲁棒性——以开发一种新型的人体图像动画方法。核心目标是首次利用事件流作为稳定且精确的运动线索，实现高质量的条件性人体图像到视频的生成。
*   **⭐ 主要发现**: 本论文提出了EvAnimate，这是首个利用事件流作为运动线索的条件性人体图像动画方法。EvAnimate的核心创新在于其能够充分利用事件相机数据固有的鲁棒性和高时间分辨率特性，克服了传统视频姿态线索在时间分辨率、运动模糊和复杂光照下的不足。技术上，EvAnimate通过将异步事件数据编码成一种专门的三通道表示，使其能够与当前主流的扩散生成模型完全兼容。这一创新性方法为人体动画领域带来了更精确、更稳定的运动驱动能力，预示着在低光照、高速运动等挑战性场景下实现高质量动画生成的巨大潜力。

---
### [[Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras]](http://arxiv.org/abs/2503.17262v1)
**📅 发布日期**: 2025-03-21

*   **👥 作者**: Shuang Guo, Friedhelm Hamann, Guillermo Gallego
*   **🎯 研究目的**: 事件相机通过运动获取场景外观信息，其输出事件流中运动和外观是紧密耦合的。然而，现有研究通常将光流（运动）和图像强度（外观）的恢复视为独立任务，这忽视了两者之间固有的关联，也不符合事件相机的特性。本文旨在提出一个无监督学习框架，利用单个网络同时估计光流和图像强度，以更好地利用事件相机数据的内在关联。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种新颖的无监督学习方法，用于联合估计事件相机的光流和图像强度。研究人员从事件生成模型出发，首次推导出了一个基于事件的光度误差，该误差是光流和图像强度的函数。随后，该误差与对比度最大化框架相结合，形成了一个全面的损失函数，从而实现了运动和外观信息的同步学习。这种方法克服了以往独立处理的局限性，更符合事件相机的物理特性，有望提高事件数据处理的准确性和鲁棒性。

---
### [[Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition]](http://arxiv.org/abs/2503.17132v3)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2025-03-21

*   **👥 作者**: Siyuan Yang, Shilin Lu, Shizheng Wang, Meng Hwa Er, Zengwei Zheng, Alex C. Kot
*   **🎯 研究目的**: 本文旨在探索脉冲神经网络（SNNs）与事件相机在保护隐私的人体行为识别（HAR）方面的协同潜力。事件相机仅捕捉运动轮廓的独特特性，结合SNNs处理时空数据的能力，为基于事件的HAR提供了高度兼容性。然而，现有研究受限于SNNs处理长期时间信息的能力，而这对于精确的人体行为识别至关重要。因此，本研究的核心目标是解决SNNs在处理长期时间信息方面的局限性，从而提升基于事件的HAR的准确性和鲁棒性。
*   **⭐ 主要发现**: 为了克服SNNs在处理长期时间信息方面的挑战，论文提出了两种新颖的框架：
    *   **基于时间分段的SNN (TS-SNN)**：该框架通过将人体动作划分为更短的时间片段来有效提取和处理长期时间信息，从而增强SNNs对复杂时序模式的理解能力。
    *   **3D卷积SNN (3D-SNN)**：虽然摘要未详细展开，但其命名暗示了通过3D卷积操作来同时处理事件数据的空间和时间维度，进一步提升SNNs对时空特征的捕捉能力。
    这些创新框架旨在显著提升SNNs在处理长期时序数据方面的性能，从而有望在基于事件的隐私保护人体行为识别领域取得突破，提高识别的精度和效率。

---
### [[ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and Spiking Neural Network]](http://arxiv.org/abs/2503.09985v2)
**📅 发布日期**: 2025-03-13

*   **👥 作者**: Qiang Zhang, Jiahang Cao, Jingkai Sun, Yecheng Shao, Gang Han, Wen Zhao, Yijie Guo, Renjing Xu
*   **🎯 研究目的**: 近年来，四足机器人在感知和运动控制方面取得了显著进展，尤其是在强化学习的推动下，使其能够在复杂环境中执行高难度动作。然而，传统的视觉传感器（如深度相机）存在操作频率相对关节控制较低以及对光照敏感等局限性，这阻碍了机器人在室外环境的部署。此外，传感器和控制系统中深度神经网络的使用也增加了计算需求。为解决这些问题，本文旨在引入受生物启发的事件相机和脉冲神经网络（SNNs）来执行具有挑战性的四足机器人跑酷任务，利用事件相机捕捉动态视觉数据的能力以及SNNs高效处理脉冲序列的特性，以期克服现有方法的不足。
*   **⭐ 主要发现**: 本文的核心贡献在于创新性地将受生物启发的事件相机与脉冲神经网络（SNNs）相结合，应用于高难度的四足机器人跑酷任务。这一方法有效地解决了传统视觉传感器（如深度相机）在低操作频率和光照敏感性方面的局限，以及深度神经网络带来的高计算负荷问题。事件相机能够高效捕捉动态视觉数据，而SNNs则能以模仿生物感知的机制高效处理这些脉冲序列。尽管摘要内容有限，但研究表明，通过这种集成方案，机器人能够执行复杂的跑酷动作，预示着在提升机器人感知鲁棒性、降低计算资源消耗方面具有巨大潜力，为未来四足机器人在复杂动态环境中的自主运动提供了新的范式。

---
### [[Helios 2.0: A Robust, Ultra-Low Power Gesture Recognition System Optimised for Event-Sensor based Wearables]](http://arxiv.org/abs/2503.07825v1)
**📅 发布日期**: 2025-03-10

*   **👥 作者**: Prarthana Bhattacharyya, Joshua Mitton, Ryan Page, Owen Morgan, Oliver Powell, Benjamin Menzies, Gabriel Homewood, Kemi Jacobs, Paolo Baesso, Taru Muhonen, Richard Vigars, Louis Berridge
*   **🎯 研究目的**: 手势识别在计算机视觉领域虽有显著进展，但为可穿戴设备（如智能眼镜）创建直观、适应性强且能效高的系统仍面临挑战。现有的手势控制方案往往不够自然、耗电且难以适应多样化用户和环境。本研究旨在开发一种针对移动设备优化的、实时、超低功耗的事件相机系统，以实现智能眼镜的自然手势控制，从而大幅提升用户体验，解决当前可穿戴手势识别系统在直观性、跨用户和环境适应性以及能耗方面的关键瓶颈。

*   **⭐ 主要发现**: 本文的核心贡献是推出了Helios 2.0系统，这是一个针对事件传感器可穿戴设备优化的、鲁棒、超低功耗的实时手势识别系统。该系统通过精心挑选的微手势来解决现有挑战，包括拇指在食指上的横向滑动（双向）以及拇指与食指指尖的双击捏合。这些以人为本的交互方式充分利用了自然的手部动作，确保了系统的直观可用性，用户无需额外学习即可掌握。Helios 2.0的低功耗特性和实时性能使其非常适合智能眼镜等可穿戴应用，有望大幅提升用户体验，并推动自然手势控制在移动设备领域的实际应用。

---
### [Sign Language Translation using Frame and Event Stream: Benchmark Dataset and Algorithms](http://arxiv.org/abs/2503.06484v1)
**📅 发布日期**: 2025-03-09

*   **👥 作者**: Xiao Wang, Yuehang Li, Fuling Wang, Bo Jiang, Yaowei Wang, Yonghong Tian, Jin Tang, Bin Luo
*   **🎯 研究目的**: 手语理解作为残障人士的重要沟通渠道，其准确性至关重要。当前的手语翻译算法主要依赖于RGB帧，但这种方法存在固定帧率、光照条件多变以及快速手部运动导致的运动模糊等局限性。受事件相机在其他领域成功应用的启发，本研究旨在利用事件流辅助RGB相机捕捉手势数据，以解决上述挑战，从而提升手语翻译的准确性和鲁棒性。
*   **⭐ 主要发现**: 本文的核心贡献在于开创性地将事件流引入手语翻译领域，以克服传统RGB帧的局限性。具体而言，研究团队利用DVS346事件相机，首次构建了一个大规模的RGB-事件手语翻译基准数据集——VECSL。该数据集包含15,676个RGB-事件样本、15,191个词汇（glosses），涵盖2,568个汉字，且数据采集多样化。这项工作为手语翻译研究提供了新的数据范式和研究方向，有望推动开发出更准确、更鲁棒的手语理解与翻译算法。

---
### [[SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks]](http://arxiv.org/abs/2503.08703v2)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2025-03-09

*   **👥 作者**: Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao, Jieyuan Zhang, Kexin Shi, Jingzhinan Wang, Jason K. Eshraghian, Haicheng Qu, Jiqing Zhang, Malu Zhang, Yang Yang
*   **🎯 研究目的**: 事件相机因其卓越的时间分辨率、动态范围、能效和像素带宽，在机器视觉领域展现出巨大潜力。脉冲神经网络（SNNs）通过离散脉冲信号与事件数据天然契合，使其成为事件基追踪的理想选择。然而，当前结合人工神经网络（ANNs）和SNNs的方法，以及次优的架构，往往会牺牲能效并限制追踪性能。本研究旨在解决这些局限性，提出首个基于Transformer的脉冲驱动追踪管线，以期提升事件基追踪的性能和能效。
*   **⭐ 主要发现**:
    *   **首次提出基于Transformer的脉冲驱动追踪管线：** 论文引入了SDTrack，这是首个将Transformer架构应用于脉冲神经网络（SNNs）进行事件基追踪的完整管线，旨在克服现有方法在能效和追踪性能上的不足。
    *   **创新性的全局轨迹提示（GTP）方法：** 提出了一种名为“全局轨迹提示”（Global Trajectory Prompt, GTP）的新方法。该方法能够有效捕获全局轨迹信息，并将其与事件流聚合到事件图像中，从而显著增强时空表示能力。
    *   **SDTrack架构：** SDTrack本身是一个基于Transformer的脉冲驱动追踪器，其设计理念是充分利用事件相机的特性和SNN的优势，以实现更高效、更高性能的追踪。
    *   **建立事件基追踪新基线：** 作为“A Baseline”的标题所示，SDTrack旨在为事件基追踪领域提供一个强有力的基准模型，推动未来在该领域的研究和发展，尤其是在结合SNN和Transformer方面。

---
### [[ERetinex: Event Camera Meets Retinex Theory for Low-Light Image Enhancement]](http://arxiv.org/abs/2503.02484v1)
**📅 发布日期**: 2025-03-04

*   **👥 作者**: Xuejian Guo, Zhiqiang Tian, Yuehang Wang, Siqi Li, Yu Jiang, Shaoyi Du, Yue Gao
*   **🎯 研究目的**: 低光照图像增强旨在恢复在黑暗场景下拍摄的欠曝光图像。传统基于帧的相机在这种场景下由于曝光时间限制，难以捕获结构和颜色信息。事件相机作为一种仿生视觉传感器，能够异步响应像素级的亮度变化，其高动态范围特性在极端低光照场景下对于视觉感知至关重要，超越了传统相机。本研究的目的是受Retinex理论在传统基于帧的低光照图像恢复中成功的启发，首次将Retinex理论与事件相机结合，以解决传统相机在极暗环境下图像质量差的问题，从而实现挑战性黑暗环境中的视觉感知。
*   **⭐ 主要发现**: 本研究的核心贡献在于首次将经典的Retinex理论与新兴的事件相机技术相结合，提出了一种新颖的基于Retinex的低光照图像恢复方法（ERetinex）。这一创新性结合充分利用了事件相机在高动态范围（HDR）下的独特优势，有效克服了传统相机在极端低光照场景下因曝光时间限制而导致的结构和颜色信息缺失问题。该研究为在挑战性黑暗环境中实现可靠的视觉感知提供了新的途径，有望显著提升低光照图像增强的性能和应用范围。

---
### [[EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition]](http://arxiv.org/abs/2502.09020v1)
**📅 发布日期**: 2025-02-13

* **👥 作者**: Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang
* **🎯 研究目的**: 针对主流场景文本识别（STR）算法在低光照、运动模糊和杂乱背景等挑战性环境下，因依赖RGB相机而表现不佳的问题，本研究提出利用受生物启发的事件相机进行场景文本识别。其核心目标是构建一个大规模的基准数据集，并开发基于事件流的STR算法，以克服传统RGB相机在复杂场景下的局限性，推动事件相机在文本识别领域的应用和发展。
* **⭐ 主要发现**: 本文的核心贡献在于开创性地将生物启发的事件相机应用于场景文本识别（STR）领域，以应对传统RGB相机在复杂环境下的挑战。具体创新点包括：
    * **构建大规模基准数据集EventSTR**: 收集并标注了一个包含9,928个高分辨率（1280x720）事件样本的大型基准数据集EventSTR，涵盖中文和英文字符，为事件流STR研究提供了宝贵的资源。
    * **建立STR算法基线**: 在EventSTR数据集上对多种现有STR算法进行了基准测试，为未来的研究提供了可供比较的基线。
    * **提出新型事件STR框架SimC-ESTR**: 设计并提出了一种名为SimC-ESTR的事件流场景文本识别框架。该框架首先利用视觉编码器提取事件特征，并通过Q-former模块将特征投影为tokens，为事件流STR提供了一种新的解决方案。

---
### [[Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media]](http://arxiv.org/abs/2501.03874v2)
**📅 发布日期**: 2025-01-07

*   **👥 作者**: Ning Zhang, Timothy Shea, Arto Nurmikko
*   **🎯 研究目的**: 在强散射介质中追踪并同时获取随机移动目标的图像是一个长期存在的挑战，对于需要精确物体定位和识别的许多应用至关重要。本研究旨在解决这一难题，开发一种端到端的神经形态光学工程与计算方法，以实现对通常不可见的物体的追踪和成像。
*   **⭐ 主要发现**: 论文提出了一种创新的端到端神经形态光学工程与计算方法，用于追踪和成像被强散射介质遮蔽的随机移动目标。该方法的核心在于结合了事件检测相机和多阶段神经形态深度学习策略。具体而言，从散射介质中出来的光子由事件相机检测，并转换为像素级的异步脉冲序列，这是从主导的无信息背景中分离出物体特定信息的第一步。随后，这些脉冲数据被输入到一个深度脉冲神经网络（SNN）引擎中进行处理，以实现对目标的追踪和成像。这项工作展示了如何有效地追踪和成像在传统方法下通常不可见的物体，为精密物体定位和识别提供了新的可能性。

---
### [[Spatially-guided Temporal Aggregation for Robust Event-RGB Optical Flow Estimation]](http://arxiv.org/abs/2501.00838v1)
**📅 发布日期**: 2025-01-01

*   **👥 作者**: Qianang Zhou, Junhui Hou, Meiyi Yang, Yongjian Deng, Youfu Li, Junlin Xiong
*   **🎯 研究目的**: 光流估计是计算机视觉中的关键任务。传统光流方法主要依赖RGB图像稳定的外观信息来建立时间上的对应关系。然而，事件相机能提供高时间分辨率的运动线索，并在挑战性场景（如高动态范围、快速运动）中表现出色。这两种模态（RGB图像和事件数据）具有互补特性，预示着它们在光流估计中融合的巨大潜力。然而，大多数跨模态融合方法未能充分利用这些互补优势，往往仅停留在简单堆叠信息的层面。本研究旨在提出一种新颖的方法，通过利用空间密集的模态（RGB图像）来引导时间密集的事件模态的聚合，从而实现有效的跨模态融合，最终提升光流估计的鲁棒性。

*   **⭐ 主要发现**: 本论文的核心贡献在于引入了一种新颖的跨模态融合策略，旨在克服现有方法简单堆叠信息的局限性。具体而言，该方法创新性地利用了空间密集的RGB图像信息，来精细地引导高时间分辨率的事件数据的聚合过程，从而实现更有效的跨模态融合。通过这种空间引导的时间聚合机制，论文提出了一种“事件增强的帧表示”（event-enhanced frame representation），该表示能够有效保留帧数据的丰富纹理信息，并融入事件数据的高频运动细节。这种融合方式有望在复杂和挑战性场景下，显著提升光流估计的准确性和鲁棒性，为未来多模态感知系统提供新的思路。

---
### [[Towards End-to-End Neuromorphic Voxel-based 3D Object Reconstruction Without Physical Priors]](http://arxiv.org/abs/2501.00741v3)
**📅 发布日期**: 2025-01-01

*   **👥 作者**: Chuanzhi Xu, Langyi Chen, Haodong Chen, Vera Chung, Qiang Qu
*   **🎯 研究目的**: 神经形态相机（事件相机）作为异步亮度变化传感器，能够捕捉极快的运动而无运动模糊，使其在极端环境下的3D重建中展现出巨大潜力。然而，目前利用单目神经形态相机进行3D重建的研究相对有限，且大多数现有方法依赖于估计物理先验（如相机姿态、深度或速度），并采用复杂的多步骤流程。本研究旨在解决这些局限性，提出一种端到端的密集体素3D重建方法，彻底消除对物理先验估计的需求，从而简化重建流程并提高效率和鲁棒性。
*   **⭐ 主要发现**: 本文提出了一种创新的端到端方法，实现了基于神经形态相机的密集体素3D物体重建，显著地摆脱了对传统物理先验估计的依赖，从而简化了复杂的重建流程。该方法的核心贡献包括：
    *   引入了一种新颖的事件表示方法，旨在增强边缘特征，使得所提出的特征增强模型能够更有效地学习和提取关键信息。
    *   通过这种创新的事件表示和端到端的设计，该方法能够从事件数据中直接学习并重建3D体素，无需中间步骤来估计相机运动或场景深度等物理量。
    *   （由于摘要截断，无法详细阐述“Optimal B...”的具体贡献，但整体方法旨在通过优化事件处理和模型学习，提升重建的准确性和鲁棒性。）
    *   该研究为在高速运动、低光照等挑战性极端环境下进行鲁棒、高效的3D重建提供了新的范式，有望推动神经形态相机在机器人、自动驾驶和AR/VR等领域的实际应用。

---
### [[VELoRA: A Low-Rank Adaptation Approach for Efficient RGB-Event based Recognition]](http://arxiv.org/abs/2412.20064v1)
**📅 发布日期**: 2024-12-28

*   **👥 作者**: Lan Chen, Haoxiang Yang, Pengpeng Shao, Haoyu Song, Xiao Wang, Zhicheng Zhao, Yaowei Wang, Yonghong Tian
*   **🎯 研究目的**: RGB和事件相机结合的模式识别技术，通过深度神经网络的微调，能够显著提升性能。受大型模型在其他领域成功应用的启发，将这些大型模型引入多模态任务有望进一步增强识别能力。然而，对这些大型模型进行全量微调会导致效率低下。尽管已存在LoRA和Adapter等轻量级微调方法，旨在平衡效率与性能，但据作者所知，目前尚未有针对基于预训练基础模型的RGB-事件识别任务进行参数高效微调（PEFT）的研究。因此，本文的研究目的在于填补这一空白，提出一种新颖的PEFT策略，以高效地适应预训练模型，从而提升RGB-事件识别的效率和性能。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种名为VELoRA的新型参数高效微调（PEFT）策略，专为高效的RGB-事件识别而设计。VELoRA采用低秩适应方法，有效解决了在利用大型预训练模型进行RGB-事件识别时，全量微调所导致的效率低下问题。据作者所知，这是首次将PEFT方法应用于基于预训练基础模型的RGB-事件识别领域，填补了该研究方向的空白。这一创新方法有望在保持甚至提升识别性能的同时，显著降低模型适应的计算资源和时间成本，为多模态模式识别领域，特别是RGB-事件融合任务，提供了一条更具可行性和可持续性的发展路径。

---
### [[Learning Monocular Depth from Events via Egomotion Compensation]](http://arxiv.org/abs/2412.19067v1)
**📅 发布日期**: 2024-12-26

*   **👥 作者**: Haitao Meng, Chonghao Zhong, Sheng Tang, Lian JunJia, Wenwei Lin, Zhenshan Bing, Yi Chang, Gang Chen, Alois Knoll
*   **🎯 研究目的**: 事件相机作为一种受神经形态学启发的传感器，能够稀疏且异步地报告亮度变化，其高时间分辨率、高动态范围和低功耗的独特特性使其非常适合解决单目深度估计中的挑战（例如高速或低光照条件）。然而，当前现有方法主要将事件流视为“黑箱”学习系统，未能充分融入先验物理原理，导致模型参数过多，并且未能完全利用事件相机数据中固有的丰富时间信息。为解决这一局限性，本研究旨在引入物理运动原理，提出一个可解释的单目深度估计框架。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种可解释的单目深度估计框架，该框架创新性地将物理运动原理融入到事件相机数据处理中。与现有将事件流视为“黑箱”的方法不同，本框架通过显式地评估不同深度假设的似然性，旨在充分利用事件相机数据固有的丰富时间信息。这种基于物理原理的方法有望解决现有模型参数过多、对时间信息利用不足的问题，从而在高速或低光照等复杂场景下实现更准确、更鲁棒的单目深度估计。

---
### [[SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks]](http://arxiv.org/abs/2412.12843v2)
**📅 发布日期**: 2024-12-17

*   **👥 作者**: Xiaxin Zhu, Fangming Guo, Xianlei Long, Qingyi Gu, Chao Chen, Fuqiang Gu
*   **🎯 研究目的**: 事件相机因其高动态范围、低延迟和低功耗等固有优势，使得基于事件的语义分割在自动驾驶和机器人领域展现出巨大的应用潜力。然而，当前主流的基于人工神经网络（ANN）的分割方法普遍存在计算需求高、依赖传统图像帧输入以及能耗巨大的问题，这些局限性严重阻碍了它们在资源受限的边缘或移动平台上的高效部署和实际应用。本研究旨在解决这些挑战，开发一种高效、低功耗且适用于事件数据的语义分割网络，以推动事件相机在实时感知任务中的应用。
*   **⭐ 主要发现**: 论文提出了SLTNet（Spike-driven Lightweight Transformer-based Networks），这是一种专为事件驱动语义分割设计的新型高效轻量级网络。SLTNet的核心创新在于其构建于高效的脉冲驱动卷积块（SCBs）之上，这些模块能够有效地从事件流中提取丰富的语义特征，同时显著减少模型的参数量，从而降低了计算复杂度和能耗。通过采用脉冲驱动架构，SLTNet能够更好地利用事件相机固有的稀疏性和异步性优势，实现更低的功耗和更高的处理效率。这种设计使得SLTNet特别适合在资源受限的边缘/移动平台上进行部署，为自动驾驶和机器人等需要实时、高效感知的应用提供了新的解决方案，有望克服传统ANN方法在效率和能耗方面的瓶颈。
### [[DriveGazen: Event-Based Driving Status Recognition using Conventional Camera]](http://arxiv.org/abs/2412.11753v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2024-12-16

*   **👥 作者**: Xiaoyin Yang
*   **🎯 研究目的**: 本研究旨在解决使用传统摄像头识别驾驶员驾驶状态的挑战。尽管传统摄像头具有信息完整和硬件成本低的优势，但其缺乏时间信息，难以有效捕捉驾驶状态的动态变化。为此，论文提出了一种实时且对光照变化鲁棒的新方法，通过观察驾驶员的眼睛来识别其驾驶状态。此外，研究还推出了一个配套的可穿戴设备和开放源代码数据集，以促进该领域的研究和应用。
*   **⭐ 主要发现**: 本研究引入了名为DriveGazen的创新系统，包括一个可穿戴设备、一个开放源代码数据集，以及一种基于传统摄像头识别驾驶员驾驶状态的实时新方法。该方法的核心创新点在于：1) 能够从传统的强度帧中生成事件帧，从而弥补传统摄像头在时间信息上的不足；2) 采用新设计的注意力驾驶状态网络（ADSN）进行高效识别。通过这种方式，DriveGazen充分利用了传统摄像头提供完整信息和硬件成本低的优势，同时解决了其缺乏时间信息导致识别困难的问题。实验结果表明，该方法对光照变化具有高度鲁棒性，并能实现实时驾驶状态识别。论文从多个角度（例如利用视频帧生成逼真的合成动态视觉传感器数据）解决了现有挑战，为驾驶员状态监测领域提供了有价值的工具和研究基础。

---
### [[Labits: Layered Bidirectional Time Surfaces Representation for Event Camera-based Continuous Dense Trajectory Estimation]](http://arxiv.org/abs/2412.08849v1)
<!-- 2024-12-12 -->
**📅 发布日期**: 2024-12-12

*   **👥 作者**: Zhongyang Zhang, Jiacheng Qiu, Shuyang Cui, Yijun Luo, Tauhidur Rahman
*   **🎯 研究目的**: 事件相机作为传统帧基传感器的有力替代，以其高时间分辨率和低延迟特性，在捕获动态场景方面展现出巨大潜力。它们能够沿着运动物体的轨迹精确记录带时间戳的事件，从而实现平滑的连续时间估计。然而，现有工作在事件表示构建过程中往往存在信息损失，这限制了基于事件相机的连续密集轨迹估计的性能上限。当前表示方法难以同时保留精细的时间信息、稳定且有特征的2D视觉特征以及时间上一致的信息密度。因此，本研究旨在解决这一挑战，开发一种能够充分利用事件相机数据、有效保留所有关键信息的事件表示方法，以实现更精确、更鲁棒的连续密集轨迹估计。
*   **⭐ 主要发现**: 本文的核心贡献是引入了一种名为“Labits”（分层双向时间表面）的事件表示方法。Labits是一种简单而优雅的表示，旨在克服现有事件表示的局限性，即在构建过程中造成的信息损失。它被设计用于同时保留事件数据中精细的时间信息、稳定且具有特征的2D视觉特征，以及时间上一致的信息密度。通过这种创新的分层双向时间表面表示，Labits有望为基于事件相机的连续密集轨迹估计任务提供更丰富、更完整的数据基础，从而显著提升估计的精度和鲁棒性。

---
### [[Dense Depth from Event Focal Stack]](http://arxiv.org/abs/2412.08120v1)
**📅 发布日期**: 2024-12-11

*   **👥 作者**: Kenta Horikawa, Mariko Isogawa, Hideo Saito, Shohei Mori
*   **🎯 研究目的**: 针对事件相机在高速运动和高动态范围场景下具有独特优势，但其密集深度估计能力仍有待提升的问题，本文提出一种新颖的方法。该研究旨在利用事件相机在焦平面扫描过程中产生的事件流，构建“事件焦距堆栈”（event focal stack），并从中推断出高精度的密集深度图。其核心目标是克服传统基于图像的离焦深度估计方法的局限性，充分利用事件数据的特性，为事件相机提供一种鲁棒且高性能的密集深度感知解决方案。
*   **⭐ 主要发现**:
    *   **核心方法创新**: 提出了一种从“事件焦距堆栈”中估计密集深度的新方法。该堆栈由事件相机在焦平面扫描时生成的事件流组成。
    *   **深度推断机制**: 利用卷积神经网络（CNN）从构建的事件焦距堆栈中学习并推断出像素级的深度图。
    *   **合成数据生成**: 为解决训练数据稀缺问题，开发了一种基于Blender的合成事件焦距堆栈生成方法。该方法能够从任意3D场景创建多样化的合成事件流，从而为CNN训练提供丰富的、具有不同结构场景的数据。
    *   **域间隙消除**: 探索并实施了有效的方法来消除真实事件流与合成事件流之间的域间隙（domain gap），显著提高了模型在真实世界数据上的泛化能力和性能。
    *   **性能优势**: 在合成数据集和真实数据集上，所提出的方法均展现出优于传统图像域离焦深度估计（depth-from-defocus）方法的卓越性能。
    *   **潜在影响**: 该研究为事件相机在复杂动态环境下的密集深度感知提供了新的、高性能的解决方案，有望推动事件相机在机器人导航、自动驾驶、增强现实/虚拟现实以及计算摄影等领域的广泛应用。

---
### [EvRepSL: Event-Stream Representation via Self-Supervised Learning for Event-Based Vision](http://arxiv.org/abs/2412.07080v1)
**📅 发布日期**: 2024-12-10

*   **👥 作者**: Qiang Qu, Xiaoming Chen, Yuk Ying Chung, Yiran Shen
*   **🎯 研究目的**: 事件相机产生的异步事件流需要转换为格式化结构，以便传统机器学习模型应用于各种计算机视觉任务。然而，目前最先进的事件流表示方法大多是手动设计的，并且由于事件流固有的噪声特性，其表示质量难以保证。本研究旨在解决这一问题，引入一种数据驱动的方法，以提升事件流表示的质量。
*   **⭐ 主要发现**: 本文提出了一种数据驱动的方法，旨在提高事件流表示的质量。其核心贡献包括：首先，引入了一种基于时空统计的新型事件流表示方法，命名为 EvRep。其次，该方法通过自监督学习（EvRepSL）来优化和增强事件流表示的质量，克服了传统手动设计方法的局限性。此外，研究还从理论上推导了异步事件流与同步数据之间的内在关系。这些创新有望为事件相机在各种计算机视觉任务中的应用提供更鲁棒、高质量的数据基础。

---
### [[使用事件相机进行目标检测：一种基于MoE热传导的检测器和新的基准数据集]](http://arxiv.org/abs/2412.06647v1)
**📅 发布日期**: 2024-12-09

*   **👥 作者**: Xiao Wang, Yu Jin, Wentao Wu, Wei Zhang, Lin Zhu, Bo Jiang, Yonghong Tian
*   **🎯 研究目的**: 事件流中的目标检测是当前前沿的研究领域，尤其在低光照、运动模糊和快速运动等挑战性条件下表现出卓越性能。然而，现有的检测器（如基于脉冲神经网络、Transformer或卷积神经网络的方案）普遍存在性能受限、计算开销大或局部感受野有限等局限性。本研究旨在提出一种新颖的目标检测算法，以显著平衡准确性和计算效率，从而克服现有方法的不足，推动事件相机目标检测技术的发展。
*   **⭐ 主要发现**: 本文提出了一种创新的基于MoE（专家混合）热传导的目标检测算法，该算法在准确性和计算效率之间取得了显著的平衡。其核心贡献和创新点包括：
    *   **新型检测算法**: 引入了一种独特的MoE热传导机制，用于事件数据的处理和目标检测。
    *   **高效架构**: 算法首先通过一个干网络（stem network）对事件数据进行嵌入，随后通过创新的MoE-HCO（Heat Conduction-based Object）块进行处理。每个MoE-HCO块都集成了多种专家模块，以模拟热传导过程，从而有效地提取特征。
    *   **性能平衡**: 该方法旨在解决现有检测器在性能和计算成本之间的权衡问题，提供了一个更优的解决方案。
    *   **新基准数据集**: （根据标题推断）除了新的检测器，论文还引入了一个新的基准数据集，这将为事件相机目标检测领域的研究提供标准化的评估平台，促进未来算法的开发和比较。
    *   **潜在影响**: 这一研究为事件相机目标检测领域提供了一种高效且高性能的新范式，有望在低光照、高速运动等复杂环境中实现更鲁棒、更准确的目标检测。

---
### [[Frequency-Adaptive Low-Latency Object Detection Using Events and Frames]](http://arxiv.org/abs/2412.04149v2)
**📅 发布日期**: 2024-12-05

*   **👥 作者**: Haitian Zhang, Xiangyuan Wang, Chang Xu, Xinya Wang, Fang Xu, Huai Yu, Lei Yu, Wen Yang
*   **🎯 研究目的**: 在目标检测领域，融合事件相机（Event camera）和RGB图像能够结合事件相机在恶劣环境下的鲁棒性与RGB图像丰富的语义信息，具有显著优势。然而，这种融合面临两大关键挑战：一是事件数据具有低延迟特性，而RGB帧则存在高延迟；二是训练阶段的标签在时间上是稀疏的，而推理阶段的数据流却是连续的。这些不匹配严重阻碍了高频融合式目标检测的实现。本研究的核心目的正是为了解决这些挑战，从而实现高效、低延迟的事件-帧融合目标检测。
*   **⭐ 主要发现**: 为了解决上述挑战，论文提出了**频率自适应低延迟目标检测器（Frequency-Adaptive Low-Latency Object Detector, FAOD）**。FAOD的核心创新点包括：
    1.  **对齐模块（Align Module）**：该模块旨在解决事件数据与RGB帧之间的延迟不匹配问题。它通过对齐低频RGB帧与高频事件数据，增强了跨模态的风格一致性和空间邻近性，从而有效地融合了两种模态的信息。
    2.  **时间偏移（Time Shift）训练策略**：论文还提出了一种创新的训练策略，以应对训练阶段标签稀疏与推理阶段数据流连续之间的不匹配。
    这些创新共同使得FAOD能够实现高效的、高频率且低延迟的事件-帧融合目标检测，显著推动了在复杂动态环境下目标检测的性能和应用潜力。

---
### [ETAP: Event-based Tracking of Any Point](http://arxiv.org/abs/2412.00133v2)
<!-- 2024-11-28 -->
**📅 发布日期**: 2024-11-28

*   **👥 作者**: Friedhelm Hamann, Daniel Gehrig, Filbert Febryanto, Kostas Daniilidis, Guillermo Gallego
*   **🎯 研究目的**: 点跟踪（TAP）范式近期革新了运动估计领域，从关注局部模板的显著点转向利用全局图像上下文跟踪任意点。然而，现有研究主要侧重于在理想条件下提升模型精度，对于复杂光照和高速运动场景，由于传统传感器的局限性，其性能仍难以满足需求。本研究旨在解决这一核心挑战，首次提出基于事件相机的任意点跟踪（ETAP）方法，以实现对任意点在极端条件下的鲁棒、高速跟踪。
*   **⭐ 主要发现**: 本论文的核心贡献在于首次提出了基于事件相机的任意点跟踪（ETAP）方法，有效地将事件相机的高性能特性与TAP范式相结合。ETAP充分利用了事件相机的高时间分辨率和高动态范围，以实现鲁棒的高速跟踪，并巧妙地运用TAP方法中的全局上下文信息来处理事件数据固有的异步性和稀疏性。此外，该工作还进一步扩展了TAP框架，以处理由...（此处原文截断）引起的事件特征变化。这一创新为在极端光照和高速运动条件下进行精确的运动估计提供了新的解决方案，显著拓宽了点跟踪技术的应用范围和鲁棒性。

---
### [[Event USKT：事件相机知识迁移中的U型状态空间模型]](http://arxiv.org/abs/2411.15276v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2024-11-22

*   **👥 作者**: Yuhui Lin, Jiahao Zhang, Siyuan Li, Jimin Xiao, Ding Xu, Wenjun Wu, Jiaxuan Lu
*   **🎯 研究目的**: 事件相机作为一种新兴的成像技术，相较于传统RGB相机具有低能耗、高帧率等独特优势。然而，现有事件数据的数量有限，严重阻碍了其更广泛的发展和应用。本研究旨在解决事件数据稀缺的挑战，通过提出一种专门的知识迁移框架，使事件数据能够有效利用现有大量预训练的RGB模型，从而在有限数据下也能实现高性能，推动事件相机技术的发展。
*   **⭐ 主要发现**: 本文提出了一种定制化的U型状态空间模型知识迁移（USKT）框架，用于实现事件到RGB的知识迁移。该框架的核心创新在于能够生成与RGB帧兼容的输入，从而使事件数据能够有效复用预训练的RGB模型，并在仅需少量参数调整的情况下，即可实现与RGB模型相当的竞争性性能。此外，在USKT架构内部，作者还进一步提出了一种双向反向状态空间模型，该模型与传统的双向扫描机制不同，展现出独特的优势，进一步提升了框架的性能和效率。

---
### [[Noise Filtering Benchmark for Neuromorphic Satellites Observations]](http://arxiv.org/abs/2411.11233v1)
**📅 发布日期**: 2024-11-18

*   **👥 作者**: Sami Arja, Alexandre Marcireau, Nicholas Owen Ralph, Saeed Afshar, Gregory Cohen
*   **🎯 研究目的**: 事件相机以其高时间分辨率、高动态范围、低功耗和稀疏数据输出等优势，在空间态势感知（Space Situational Awareness, SSA）领域，特别是在探测望远镜视野内的常驻空间物体（Resident Space Objects, RSO）方面，展现出巨大潜力。然而，事件相机输出的数据常伴随大量背景活动噪声，尤其在低光照条件下更为显著。这种噪声会淹没卫星信号产生的稀疏事件，从而使目标检测和跟踪变得更具挑战性。现有噪声过滤算法通常针对数据密度较高的场景设计，允许一定程度的信号损失，因此在处理这种稀疏且受噪声严重干扰的卫星观测数据时效果不佳，阻碍了事件相机在该领域的应用。本研究旨在解决现有噪声过滤算法在神经形态卫星观测中面临的挑战，以期提升事件相机在空间态势感知应用中的性能和可靠性。
*   **⭐ 主要发现**: 根据提供的摘要，论文主要阐述了事件相机在空间态势感知中的应用潜力及当前面临的噪声过滤挑战，但摘要本身并未详细说明本研究的具体发现、核心贡献、创新点、实验结果或理论突破。论文标题《神经形态卫星观测的噪声过滤基准》暗示了研究将专注于评估或建立适用于此类观测的噪声过滤方法，以克服现有算法的局限性。

---
### [[SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition]](http://arxiv.org/abs/2410.16746v1)
**📅 发布日期**: 2024-10-22

*   **👥 作者**: Jiaqi Chen, Yan Yang, Shizhuo Deng, Da Teng, Liyuan Pan
*   **🎯 研究目的**: 人类行为识别（HAR）在视频分析、监控、自动驾驶、机器人和医疗保健等多个应用领域中至关重要。然而，当前主流的HAR算法大多基于RGB图像，虽然能捕捉丰富的视觉信息，但在隐私敏感环境中因记录可识别的个人特征而引发担忧。事件相机作为一种新兴技术，通过在像素级别稀疏地捕捉场景亮度变化，而不记录完整图像，为解决隐私问题提供了有前景的方案。此外，事件相机具备高动态范围，能有效应对低光或高对比度等复杂光照条件。然而，利用事件相机也带来了新的挑战，即如何有效建模其空间稀疏且时间分辨率极高的事件数据。本研究旨在解决这些挑战，开发一种创新的方法，以充分利用事件相机的优势，实现高效、隐私保护且鲁棒的人类行为识别。
*   **⭐ 主要发现**: 本论文提出了一种名为“SpikMamba”的创新框架，该框架巧妙地将脉冲神经网络（SNNs）与Mamba架构相结合，专门应用于基于事件的人类行为识别。SNNs以其固有的低功耗特性和对稀疏事件数据的自然适应性而闻名，而Mamba则是一种高效的状态空间模型，在序列建模方面展现出卓越的性能。SpikMamba通过融合这两种前沿技术，旨在克服事件相机数据在空间稀疏性和高时间分辨率建模方面的固有挑战。尽管提供的摘要未完全展开实验细节，但可以推断，SpikMamba有望在处理事件流数据方面展现出卓越的效率和性能，为在隐私敏感和复杂光照条件下的人类行为识别提供一个强大的新范式。这项工作不仅为SNN和Mamba在处理新兴传感器数据方面的融合开辟了新途径，也对未来低功耗、高效率的事件视觉应用具有重要意义。

---
### [基于事件相机的非侵入式定性振动分析](http://arxiv.org/abs/2410.14364v1)
**📅 发布日期**: 2024-10-18

*   **👥 作者**: Dwijay Bane, Anurag Gupta, Manan Suri
*   **🎯 研究目的**: 本技术报告旨在深入探讨事件视觉传感器在非侵入式定性振动分析领域的应用潜力，尤其关注频率测量和运动放大技术。研究动机在于利用事件相机高时间分辨率和宽动态范围的优势，为实时结构评估和微小运动分析提供新的解决方案，以期在实际场景中验证其可行性与局限性。
*   **⭐ 主要发现**: 本研究成功运用尖端事件视觉技术，深入探索了事件相机在振动分析中频率测量和运动放大（通过强度重建）的实际应用场景。主要发现包括：
    *   在频率测量方面，事件传感器展现出在实时结构评估中的显著潜力。
    *   然而，在运动放大方面，研究揭示了相当大的挑战，特别是在相机保持静止的场景中。
    这些发现为未来事件相机在工业检测、结构健康监测等领域的应用提供了宝贵的实践经验和方向性指导。

---
### [[Leveraging Event Streams with Deep Reinforcement Learning for End-to-End UAV Tracking]](http://arxiv.org/abs/2410.14685v1)
**📅 发布日期**: 2024-10-03

*   **👥 作者**: Ala Souissi, Hajer Fradi, Panagiotis Papadakis
*   **🎯 研究目的**: 本研究旨在提升无人机（UAV）的自主性，特别是在主动跟踪任务中的表现。针对传统视觉传感器在高速运动或高动态范围场景下的局限性，论文提出利用事件相机（event cameras）——一种具有高速响应、高动态范围和低能耗优势的成像传感器——作为视觉反馈源。核心目标是设计一个能够根据事件传感器的视觉反馈来调整无人机运动的跟踪控制器，从而实现对目标的有效追踪，最终提高无人机的自主跟踪能力。
*   **⭐ 主要发现**: 论文提出了一种创新的端到端（end-to-end）深度强化学习（DRL）框架，用于无人机的主动跟踪。该框架能够直接将事件流的原始传感器数据映射到无人机的控制动作，从而充分利用四旋翼无人机的全部运动能力以及事件传感器的独特属性。为了在高度可变和充满挑战的条件下学习到最优策略，研究团队在模拟环境中采用了域随机化（domain randomization）技术进行训练。这一方法不仅展示了利用事件相机结合DRL在无人机跟踪领域的巨大潜力，也为未来在复杂动态环境中实现更鲁棒、更自主的无人机导航和跟踪提供了新的思路和技术基础。

---
### [[FACET：基于椭圆建模的快速准确事件相机眼动追踪，用于扩展现实]](http://arxiv.org/abs/2409.15584v1)
<!-- 2024-09-23 -->
**📅 发布日期**: 2024-09-23

*   **👥 作者**: Junyuan Ding, Ziteng Wang, Chang Gao, Min Liu, Qinyu Chen
*   **🎯 研究目的**: 眼动追踪是扩展现实（XR）中实现基于凝视交互的关键技术。然而，传统的基于帧的眼动追踪系统在满足XR对高精度、低延迟和低功耗的需求方面面临挑战。事件相机凭借其高时间分辨率和低功耗，为解决这些问题提供了有前景的替代方案。本文旨在开发一种名为FACET（快速准确事件相机眼动追踪）的系统，该系统利用事件数据直接输出瞳孔椭圆参数，以实现针对XR应用的实时、高精度和低功耗眼动追踪。
*   **⭐ 主要发现**: 论文提出了FACET（快速准确事件相机眼动追踪），这是一个端到端的神经网络，能够直接从事件数据中输出瞳孔的椭圆参数。FACET经过优化，特别适用于实时XR应用，其输出的椭圆参数可以直接被后续的基于椭圆的瞳孔追踪器利用，提高了系统的兼容性和效率。为了有效训练该模型，研究团队对现有的EV-Eye数据集进行了增强，不仅扩展了标注数据量，还将原始的掩码标签精确转换为基于椭圆的标注形式。此外，论文还引入了一种新颖的三角损失函数，进一步提升了模型对瞳孔椭圆参数预测的准确性。

---
### [[EventAug: Multifaceted Spatio-Temporal Data Augmentation Methods for Event-based Learning]](http://arxiv.org/abs/2409.11813v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2024-09-18

*   **👥 作者**: Yukun Tian, Hao Chen, Yongjian Deng, Feihong Shen, Kepan Liu, Wei You, Ziyang Zhang
*   **🎯 研究目的**: 事件相机因其低时间延迟和高动态范围在多个领域取得了显著成功。然而，该领域面临数据不足和多样性有限的挑战，常导致模型过拟合和特征学习不足。值得注意的是，事件相机领域对数据增强技术的研究仍然稀缺。本研究旨在弥补这一空白，引入一种名为EventAug的系统性数据增强方案，以丰富事件数据的时空多样性，从而解决数据稀缺和多样性不足的问题，提升事件学习模型的性能。
*   **⭐ 主要发现**: 论文提出了一种名为EventAug的系统性数据增强方案，旨在显著提升事件数据的时空多样性。特别地，该方案包含以下创新方法：首先，引入了多尺度时间整合（Multi-scale Temporal Integration, MSTI）技术，旨在通过在不同时间尺度上整合事件数据，有效丰富物体运动速度的多样性。其次，提出了空间显著事件掩码（Spatial-salient Event Mask, SSEM）和时间显著事件掩码（Temporal-salient Event Mask, TSEM），这两种方法通过选择性地突出或遮蔽事件流中的显著区域，进一步丰富了物体形态和上下文变体。EventAug的引入旨在帮助事件学习模型从更丰富、更多样化的数据中进行学习，从而有效缓解过拟合问题，提升特征学习的质量，并最终增强模型在各种任务上的泛化能力和鲁棒性。

---
### [[SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation]](http://arxiv.org/abs/2409.04082v1)
**📅 发布日期**: 2024-09-06

*   **👥 作者**: Yi Tian, Juan Andrade-Cetto
*   **🎯 研究目的**: 事件相机通过捕获光强度变化生成异步且稀疏的事件流，相比传统帧式相机，它们具有高动态范围和极快数据速率等显著优势，特别适用于快速运动或挑战性光照条件下的场景。脉冲神经网络（SNNs）因其与事件相机数据相似的异步和稀疏特性，非常适合处理这类数据。受Transformer和脉冲驱动Transformer（Spikeformer）在其他计算机视觉任务中潜力的启发，本研究旨在为事件相机提出快速且鲁棒的光流估计解决方案。
*   **⭐ 主要发现**: 本文提出了两种用于事件相机快速鲁棒光流估计的解决方案：STTFlowNet 和 SDformerFlow。其中，STTFlowNet 采用了U形人工神经网络（ANN）架构。SDformerFlow的具体架构细节和实验结果在提供的摘要片段中未完全展开，但从标题推测，它可能结合了时空Swin Transformer和脉冲神经网络的优势，旨在为事件相机提供高效的光流估计能力。
### [[MouseSIS: A Frames-and-Events Dataset for Space-Time Instance Segmentation of Mice]](http://arxiv.org/abs/2409.03358v1)
**📅 发布日期**: 2024-09-05

*   **👥 作者**: Friedhelm Hamann, Hanxiong Li, Paul Mieske, Lars Lewejohann, Guillermo Gallego
*   **🎯 研究目的**: 尽管视频中的目标跟踪和分割技术取得了显著进展，但在恶劣条件和快速运动下仍面临挑战。事件相机作为一种新型传感器，凭借其高时间分辨率和高动态范围，有望解决这些问题。然而，目前缺乏用于开发基于事件流的掩码级跟踪算法的标注数据。本研究旨在填补这一空白，引入一项名为“时空实例分割”的新任务，并为此提供必要的数据基础，以推动事件相机在复杂动态场景下目标分割和跟踪技术的发展。
*   **⭐ 主要发现**: 本论文的核心贡献在于引入了一项名为“时空实例分割”（Space-Time Instance Segmentation）的新任务。这项任务旨在对传感器输入（包括准连续事件流和可选的对齐帧）的整个持续时间内的实例进行分割，类似于视频实例分割，但更侧重于事件相机的特性。为了支持这项新任务，论文发布了名为 **MouseSIS** 的数据集，这是首个为基于事件流的掩码级跟踪算法开发而设计的标注数据。MouseSIS数据集的推出，为研究人员提供了开发和评估在恶劣光照条件和快速运动场景下（传统相机难以应对）鲁棒目标分割和跟踪算法的关键资源，有望显著推动事件相机在计算机视觉领域的应用和研究。
### [Optimal OnTheFly Feedback Control of Event Sensors](http://arxiv.org/abs/2408.12976v1)
**📅 发布日期**: 2024-08-23

*   **👥 作者**: Valery Vishnevskiy, Greg Burman, Sebastian Kozerke, Diederik Paul Moeys
*   **🎯 研究目的**: 事件相机以异步事件流的形式输出数据，具有数据冗余低、微秒级时间分辨率、低功耗等显著优势，使其在机器人和计算机视觉领域具有重要应用价值。本研究旨在解决从事件数据中重建视频的问题，并为此提出一种动态反馈控制方法来优化事件传感器的激活阈值，以提高视频重建的质量和效率，并允许用户自定义目标峰值事件速率。
*   **⭐ 主要发现**: 论文的核心贡献在于提出了一种新颖的动态反馈控制方法，用于实时（OnTheFly）优化事件传感器的激活阈值。该方法引入了一个控制器网络，该网络能够分析传感器过去发出的事件数据，并预测下一时间段内最佳的激活阈值分布。一个关键创新点是，该控制网络能够根据用户定义的“目标峰值事件速率”进行条件化和优化。这意味着用户可以根据应用需求（如带宽限制或处理能力）动态调整事件生成速率，从而在保持数据质量的同时，有效管理数据流。这一方法有望显著提升从事件数据中重建视频的性能，并为事件传感器的实时数据流管理提供一个高效且可控的解决方案，进一步拓宽其在各类应用中的实用性。

---
### [[MambaEVT: Event Stream based Visual Object Tracking using State Space Model]](http://arxiv.org/abs/2408.10487v1)
**📅 发布日期**: 2024-08-20

*   **👥 作者**: Xiao Wang, Chao wang, Shiao Wang, Xixi Wang, Zhicheng Zhao, Lin Zhu, Bo Jiang
*   **🎯 研究目的**: 事件相机因其独特的成像原理和优势（低能耗、高动态范围、高时间分辨率）在近年来视觉跟踪领域受到广泛关注。然而，现有基于事件的跟踪算法，由于普遍采用Vision Transformer和静态模板进行目标定位，正逐渐遭遇性能瓶颈。本研究旨在提出一种新颖的框架，以克服这些局限性，提升事件流视觉目标跟踪的性能和效率。
*   **⭐ 主要发现**: 本论文提出了一种新颖的MambaEVT框架，用于基于事件流的视觉目标跟踪。其核心创新在于**首次将具有线性复杂度的状态空间模型（State Space Model, SSM）作为骨干网络引入视觉跟踪领域**，以替代当前算法中常见的Vision Transformer，从而有效解决了现有方法因Transformer和静态模板带来的性能瓶颈问题。在MambaEVT中，搜索区域和目标模板被同时输入到Vision Mamba网络中，进行高效的特征提取和交互。随后，搜索区域的输出令牌被送入跟踪头部以实现目标定位。这一基于Mamba的模型设计，有望在保持高精度的同时，显著提升跟踪算法的效率和实时性，为事件相机视觉跟踪领域带来新的突破。

---
### [[Evaluating Image-Based Face and Eye Tracking with Event Cameras]](http://arxiv.org/abs/2408.10395v1)
**📅 发布日期**: 2024-08-19

*   **👥 作者**: Khadija Iddrisu, Waseem Shariff, Noel E. OConnor, Joseph Lemley, Suzanne Little
*   **🎯 研究目的**: 传统相机在捕捉快速移动物体时常出现欠采样等问题，导致关键信息丢失。事件相机（又称神经形态传感器）通过异步捕捉像素级光强度变化来生成“事件”数据，从而有效缓解了这些问题。然而，利用这种独特的数据格式通常需要开发专门的手工事件表示，以便与传统的卷积神经网络（CNNs）无缝集成。本研究的核心目标是评估基于事件相机的面部和眼部追踪技术，并展示将传统算法与事件数据结合的可行性。
*   **⭐ 主要发现**: 本研究评估了基于事件相机的面部和眼部追踪技术。论文的核心贡献在于展示了将传统算法与事件数据有效整合的可行性，从而为克服传统相机在处理快速运动物体时的局限性提供了新的途径。通过利用事件相机独特的异步数据特性，该研究旨在证明即使在需要专门数据表示的情况下，也能成功地将现有计算机视觉方法应用于事件数据，从而为更鲁棒、信息更丰富的追踪系统奠定基础。

---
### [[Event Stream based Human Action Recognition: A High-Definition Benchmark Dataset and Algorithms]](http://arxiv.org/abs/2408.09764v1)
<!-- 2024-08-19 -->
**📅 发布日期**: 2024-08-19

*   **👥 作者**: Xiao Wang, Shiao Wang, Pengpeng Shao, Bo Jiang, Lin Zhu, Yonghong Tian
*   **🎯 研究目的**: 人类行为识别（HAR）是计算机视觉和人工智能领域的关键研究方向。尽管RGB摄像头在HAR研究中占据主导地位，但在实际应用中面临光照条件不佳、快速运动模糊和隐私泄露等诸多挑战。受生物启发的事件相机因其低功耗、高动态范围等优势而受到日益关注，为解决RGB摄像头的局限性提供了新的途径。然而，现有的大多数基于事件的HAR数据集分辨率较低（例如346x260），限制了高精度行为识别算法的开发。本研究旨在解决这一分辨率和规模的限制，通过构建一个大规模、高清晰度的事件流HAR数据集，以推动基于事件流的人类行为识别技术的发展。
*   **⭐ 主要发现**: 本文提出了一个名为CeleX-HAR的大规模、高清晰度（1280x800）人类行为识别数据集。该数据集基于CeleX-V事件相机采集，旨在弥补现有事件相机HAR数据集分辨率低和规模小的不足。CeleX-HAR涵盖了150种常见的人类行为，为基于事件流的人类行为识别算法研究提供了一个高质量的基准，有望促进该领域在复杂真实世界场景下的应用和创新。

---
### [[Retina-Inspired Object Motion Segmentation for Event-Cameras]](http://arxiv.org/abs/2408.09454v2)
**📅 发布日期**: 2024-08-18

*   **👥 作者**: Victoria Clerico, Shay Snyder, Arya Lohia, Md Abdullah-Al Kaiser, Gregory Schwartz, Akhilesh Jaiswal, Maryam Parsa
*   **🎯 研究目的**: 事件相机作为一种高时间分辨率的革命性技术，已超越传统主动像素相机，并从视网膜的光感受器和初始突触中汲取灵感。本研究旨在进一步探索视网膜的额外功能在提取视觉特征方面的潜力。具体来说，它致力于解决事件相机数据中自我运动补偿的问题，目标是开发一种领域无关且高效的算法，该算法基于哺乳动物视网膜中计算的“物体运动敏感性”（Object Motion Sensitivity, OMS）特性，以抑制相机自身的运动，从而避免对深度网络和学习的需求。
*   **⭐ 主要发现**: 论文的核心贡献是提出了一种低开销的算法，用于事件相机的自我运动补偿。该方法基于实验神经科学，巧妙地将OMS的生物电路机制转化为计算算法，从而有效地抑制了相机自身的运动。其创新之处在于，该算法无需依赖深度网络和机器学习，显著降低了计算开销和复杂性，提供了一种领域无关且高效的解决方案。该系统能够处理动态场景中的事件数据，以执行像素级的运动分割（摘要中未完全显示，但从标题和上下文推断）。这项工作展示了利用额外视网膜功能进行视觉特征提取的巨大潜力，为事件相机数据处理提供了一种新颖、生物启发且计算效率高的方法。

---
### [[Event-Stream Super Resolution using Sigma-Delta Neural Network]](http://arxiv.org/abs/2408.06968v1)
**📅 发布日期**: 2024-08-13

*   **👥 作者**: Waseem Shariff, Joe Lemley, Peter Corcoran
*   **🎯 研究目的**: 事件相机因其低分辨率和稀疏、异步的数据特性，在捕捉视觉场景的动态和细节方面面临独特挑战。现有事件超分辨率算法未能充分优化以适应这种独特的数据结构，导致效率低下且难以全面捕捉场景细节，并带来计算复杂性问题。为弥补这一差距，本研究旨在提出一种新方法，以提升事件相机捕获的基于亮度变化的事件像素的时空分辨率。
*   **⭐ 主要发现**: 本研究提出了一种创新方法，将二值尖峰信号与Sigma Delta神经网络（SDNNs）相结合。其核心创新在于利用一种时空约束学习机制，旨在同时学习事件的空间和时间分布。这一方法有望克服现有算法的局限性，更有效地捕捉视觉场景的完整动态和细节，并显著提高计算效率，从而实现事件流的超分辨率。

---
### [[A Framework for Pupil Tracking with Event Cameras]](http://arxiv.org/abs/2407.16665v2)
<!-- 2024-07-23 -->
**📅 发布日期**: 2024-07-23

*   **👥 作者**: Khadija Iddrisu, Waseem Shariff, Suzanne Little
*   **🎯 研究目的**: 本研究旨在开发一个基于事件相机的瞳孔追踪框架。背景是眼球扫视（saccades）作为人类最快的生理运动之一，其研究对于理解神经系统疾病具有重要意义。准确识别瞳孔位置是检测扫视并推断注视角度的必要前提。考虑到扫视的极高速度（可达700度/秒，甚至超过眨眼速度），传统的瞳孔追踪方法可能面临运动模糊和时间分辨率不足的挑战。因此，本研究的核心目的是利用事件相机独特的高时间分辨率和低延迟特性，提供一个鲁棒、精确的瞳孔追踪解决方案，从而为扫视检测和神经学研究提供可靠的基础数据。
*   **⭐ 主要发现**: 尽管摘要部分未完全展开具体的技术细节和实验结果，但根据标题和已提供的信息，本研究的核心贡献在于提出了一个**基于事件相机的瞳孔追踪框架**。这一创新性方法旨在克服传统相机在处理极高速眼球运动（如扫视）时可能遇到的挑战，例如运动模糊和帧率限制。事件相机因其异步、仅在像素亮度变化时才生成事件数据的特性，能够捕捉到传统相机难以捕捉的快速运动细节，从而有望实现更精确、更鲁棒的瞳孔位置识别。这一框架的建立，将直接提升扫视检测的准确性，并为通过眼动模式研究神经系统疾病（如神经退行性疾病）提供更可靠的数据基础，对眼科、神经科学以及人机交互领域具有潜在影响。

---
### [[Embracing Events and Frames with Hierarchical Feature Refinement Network for Object Detection]](http://arxiv.org/abs/2407.12582v2)
**📅 发布日期**: 2024-07-17

*   **👥 作者**: Hu Cao, Zehua Zhang, Yan Xia, Xinyi Li, Jiahao Xia, Guang Chen, Alois Knoll
*   **🎯 研究目的**: 传统基于帧的视觉目标检测在恶劣条件（如光照不足、快速运动等）下，由于传统相机感知能力的局限性，性能会显著下降。事件相机输出稀疏且异步的事件流，为解决这些问题提供了潜在方案。然而，如何有效地融合这两种异构模态（帧和事件）仍然是一个开放性挑战。本文旨在提出一种新颖的方法来有效融合事件和帧数据，以提升目标检测在复杂环境下的鲁棒性和性能。
*   **⭐ 主要发现**: 本文提出了一种新颖的**分层特征细化网络（Hierarchical Feature Refinement Network）**，用于有效融合事件和帧数据以进行目标检测。该网络的核心创新在于设计了一个**从粗到精的融合模块——跨模态自适应特征细化（Cross-modality Adaptive Feature Refinement, CAFR）模块**。CAFR模块首先通过**双向跨模态交互（Bidirectional Cross-modality Interaction, BCI）部分**，促进来自事件和帧两种不同模态的信息桥接。随后，通过进一步的特征细化和对齐，实现模态间的深度融合，旨在显著提升目标检测在传统相机难以应对的挑战性条件下的性能和鲁棒性。

---
### [[Motion-prior Contrast Maximization for Dense Continuous-Time Motion Estimation]](http://arxiv.org/abs/2407.10802v1)
**📅 发布日期**: 2024-07-15

*   **👥 作者**: Friedhelm Hamann, Ziyun Wang, Ioannis Asmanis, Kenneth Chaney, Guillermo Gallego, Kostas Daniilidis
*   **🎯 研究目的**: 旨在解决当前光流和点跟踪方法过度依赖合成数据集的问题，以及由于事件模拟器局限性导致现有基于帧的方法难以适应事件相机数据的问题。研究目标是利用事件相机在挑战性视觉条件下的优势，开发一种无需依赖合成数据，能有效进行密集连续时间运动估计的新方法。
*   **⭐ 主要发现**: 本文提出了一种新颖的自监督损失函数，它将对比度最大化（Contrast Maximization）框架与像素级轨迹形式的非线性运动先验相结合。此外，作者还提出了一种高效的解决方案，用于解决非线性轨迹与事件之间的高维分配问题。实验证明，该方法在密集连续时间运动估计任务中表现出卓越的有效性。特别是在真实世界数据集EVIMO2上，它显著提升了通过合成数据训练模型的零样本（zero-shot）性能，这表明其在处理真实世界事件数据方面的强大泛化能力和实用价值。

---
### [[Helios: An extremely low power event-based gesture recognition for always-on smart eyewear]](http://arxiv.org/abs/2407.05206v4)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2024-07-06

*   **👥 作者**: Prarthana Bhattacharyya, Joshua Mitton, Ryan Page, Owen Morgan, Ben Menzies, Gabriel Homewood, Kemi Jacobs, Paolo Baesso, David Trickett, Chris Mair, Taru Muhonen, Rory Clark, Louis Berridge, Richard Vigars, Iain Wallace
*   **🎯 研究目的**: 随着增强现实（AR）技术的发展，当前智能眼镜（如Meta Ray-Bans）在视觉和佩戴舒适度方面有所提升，但往往牺牲了功能性。现有的人机交互界面（HMI），例如电容触摸和语音控制，在人体工程学、隐私和功耗方面存在局限性。本研究旨在解决这些挑战，通过引入Helios系统，利用自然手部交互，为始终开启的智能眼镜提供一种更直观、更舒适的用户体验，实现超低功耗、实时、基于事件的手势识别。
*   **⭐ 主要发现**:
    *   **开创性系统**: 论文首次提出了Helios，这是一个专为全天候佩戴的智能眼镜设计的超低功耗、实时、基于事件的手部手势识别系统。
    *   **核心技术**: Helios系统利用了一个功耗极低（20mW）且尺寸紧凑（3mmx4mm）的事件相机来执行自然手部手势识别。事件相机以其高效的数据处理能力和低功耗特性，非常适合此类对功耗敏感的应用。
    *   **解决现有HMI痛点**: 通过采用自然手部交互，Helios系统有效解决了当前智能眼镜HMI在人体工程学、隐私和功耗方面的局限性，提供了一种更高效、更私密且更符合用户习惯的交互方式。
    *   **潜在影响**: 这一创新系统有望显著提升智能眼镜的用户体验和实用性，使其在全天候佩戴场景下更具吸引力，并推动AR设备向更自然、更节能的交互方式发展。

---
### [[Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input]](http://arxiv.org/abs/2406.03439v1)
**📅 发布日期**: 2024-06-05

*   **👥 作者**: Joachim Ott, Zuowen Wang, Shih-Chii Liu
*   **🎯 研究目的**: 事件相机在需要低延迟和稀疏输出响应的视觉任务中具有显著优势。然而，当前深度网络算法在事件相机领域的开发面临一大挑战：缺乏用于训练的大型标注事件相机数据集。本文的研究目的正是为了解决这一数据稀缺问题，提出一种创新方法，即通过文本输入直接生成合成事件相机数据流，从而为事件相机深度学习算法的开发提供大规模、多样化且可标注的训练数据。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种名为“Text-to-Events”的创新模型，该模型能够直接从文本提示生成合成的事件相机数据流（事件帧）。这一模型的核心创新点在于其独特的架构，它结合了两个关键组件：一个经过训练用于生成稀疏事件帧的自编码器，以及一个扩散模型架构。通过将预训练的自编码器与扩散模型相结合，该Text-to-Events模型能够生成平滑、逼真且可控的合成事件流。这一方法为解决事件相机领域长期存在的数据集稀缺问题提供了一个开创性的解决方案，极大地降低了获取大规模标注事件数据的门槛，有望加速事件相机在各种应用场景中深度学习算法的开发、训练与部署。

---
### [[EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting]](http://arxiv.org/abs/2405.14959v3)
**📅 发布日期**: 2024-05-23

*   **👥 作者**: Jiaxu Wang, Junhao He, Ziyi Zhang, Mingyuan Sun, Jingkai Sun, Renjing Xu
*   **🎯 研究目的**: 事件相机凭借其高动态范围和低延迟的优势，在挑战性光照条件和快速移动场景中展现出巨大潜力。然而，从原始事件流中重建3D场景面临严峻挑战，主要原因在于事件数据稀疏且不携带绝对颜色信息。本研究旨在克服这些限制，提出首个基于事件的通用化3D重建框架，以充分释放事件相机在3D重建领域的潜力，实现仅通过事件输入即可前向重建3D场景并泛化到未见过的案例。
*   **⭐ 主要发现**: 本文提出了EvGGS，这是首个基于事件的通用化3D重建框架。EvGGS能够仅从事件输入，以端到端（feedforward）的方式将场景重建为3D高斯，并且无需任何重新训练即可泛化到未见过的场景。该框架由三个关键子模块组成：深度估计模块、强度重建模块和高斯回归模块，这些模块以级联方式连接。通过协同训练，EvGGS有效解决了事件数据稀疏和缺乏绝对颜色信息的问题，为事件相机在复杂环境下的3D重建应用开辟了新的可能性，展现了其在通用性和鲁棒性方面的显著优势。

---
### [[A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation]](http://arxiv.org/abs/2404.17335v3)
**📅 发布日期**: 2024-04-26

*   **👥 作者**: Xin Zhang, Liangxiu Han, Tam Sobeih, Lianghao Han, Darren Dancey
*   **🎯 研究目的**: 深度估计是计算机视觉中的一项关键任务，在自动驾驶、机器人和增强现实等领域具有广泛应用。事件相机因其低延迟、高动态范围和高能效等独特优势而备受关注。然而，其非传统的脉冲输出以及标注数据集的稀缺性，对传统的基于图像的深度估计方法构成了显著挑战。本研究旨在解决这些挑战，利用事件相机的独特特性，实现高效准确的深度估计。
*   **⭐ 主要发现**: 本文提出了一种新颖的、能效高的脉冲驱动Transformer网络（Spike-Driven Transformer Network, SDT），用于通过事件相机进行深度估计。该网络充分利用了脉冲数据的独特属性，并引入了以下关键创新：
    1.  **纯脉冲驱动的Transformer架构**: 设计了一种完全由脉冲数据驱动的Transformer架构，该架构集成了基于脉冲的注意力机制，能够有效处理事件相机产生的异步二进制脉冲数据。
    2.  **跨模态知识蒸馏**: 通过跨模态知识蒸馏方法，克服了事件相机标注数据集稀缺的问题，将传统RGB图像领域的深度估计知识有效迁移到事件相机领域。
    这些创新使SDT网络能够克服现有挑战，实现能量高效的深度估计，为基于事件相机的视觉任务提供了新的解决方案，并有望推动事件相机在实际应用中的发展。

---
### [Event-Based Eye Tracking. AIS 2024 Challenge Survey](http://arxiv.org/abs/2404.11770v1)
**📅 发布日期**: 2024-04-17

*   **👥 作者**: Zuowen Wang, Chang Gao, Zongwei Wu, Marcos V. Conde, Radu Timofte, Shih-Chii Liu, Qinyu Chen, Zheng-jun Zha, Wei Zhai, Han Han, Bohao Liao, Yuliang Wu, Zengyu Wan, Zhong Wang, Yang Cao, Ganchao Tan, Jinze Chen, Yan Ru Pei, Sasskia Brüers, Sébastien Crouzet, Douglas McLelland, Oliver Coenen, Baoheng Zhang, Yizhao Gao, Jingyuan Li, Hayden Kwok-Hay So, Philippe Bich, Chiara Boretti, Luciano Prono, Mircea Lică, David Dinucu-Jianu, Cătălin Grîu, Xiaopeng Lin, Hongwei Ren, Bojun Cheng, Xinan Zhang, Valentin Vial, Anthony Yezzi, James Tsai
*   **🎯 研究目的**: 本综述旨在回顾AIS 2024事件相机眼动追踪（EET）挑战赛。该挑战赛的核心任务是处理由事件相机记录的眼球运动数据，并准确预测瞳孔中心。研究旨在强调利用事件相机实现高效眼动追踪，以在任务准确性和效率之间取得良好平衡。通过对挑战赛的总结和分析，本研究旨在推动未来事件相机眼动追踪领域的研究进展。
*   **⭐ 主要发现**: 在挑战赛期间，共有38名参与者注册了Kaggle竞赛，其中8支团队提交了挑战赛情况说明书。本综述对这些提交的新颖且多样化的方法进行了详细回顾和深入分析。这些方法致力于解决事件相机眼动追踪中效率与准确性之间的权衡问题。通过对这些创新方法的总结和分析，本研究旨在为未来事件相机眼动追踪领域的研究提供宝贵的参考和方向，从而促进该领域的进一步发展。

---
### [[A Lightweight Spatiotemporal Network for Online Eye Tracking with Event Camera]](http://arxiv.org/abs/2404.08858v1)
**📅 发布日期**: 2024-04-13

*   **👥 作者**: Yan Ru Pei, Sasskia Brüers, Sébastien Crouzet, Douglas McLelland, Olivier Coenen
*   **🎯 研究目的**: 这篇论文旨在解决在边缘计算环境中处理事件相机数据时面临的效率和低延迟挑战。鉴于事件数据在边缘设备上应用广泛，且对实时性要求高，作者提出了一种轻量级的时空卷积网络，专门用于在线眼动追踪。其核心目标是设计一个能够高效部署在资源受限的边缘硬件上的解决方案，以有效利用事件数据丰富的时序特征。
*   **⭐ 主要发现**:
    *   **核心贡献：** 论文提出了一种轻量级的因果时空卷积网络（causal spatiotemporal convolutional network），专门用于在线眼动追踪，以高效处理事件相机数据。
    *   **多重效率优化策略：** 该网络针对边缘计算环境的资源限制，通过以下创新点实现高效部署：
        *   **简洁架构：** 采用简单架构和基础操作（如卷积、ReLU激活），确保低计算开销。
        *   **在线推理优化：** 支持通过层输出缓冲进行高效的在线推理。
        *   **高激活稀疏性：** 通过训练正则化，实现了超过90%的激活稀疏度，这对于事件基处理器而言，能带来显著的效率提升。
    *   **数据增强方法：** 额外提出了一种通用的仿射增强策略，直接作用于数据，以提升模型性能和泛化能力。

---
### SpikeNVS: Enhancing Novel View Synthesis from Blurry Images via Spike Camera
<!-- 论文发布日期，格式：2024-04-10 -->
**📅 发布日期**: 2024-04-10

*   **👥 作者**: Gaole Dai, Zhenyu Wang, Qinwen Xu, Ming Lu, Wen Chen, Boxin Shi, Shanghang Zhang, Tiejun Huang
*   **🎯 研究目的**: 神经场方法（如NeRF和3DGS）在实现清晰的新视角合成（NVS）时，训练图像的质量是决定性因素。然而，传统RGB相机容易受到运动模糊的影响，这严重限制了NVS的最终效果。尽管现有研究已尝试整合事件相机来提升NVS质量，但事件-RGB方法存在训练成本高昂以及在背景区域表现不佳等局限性。本研究旨在克服这些挑战，引入一种新颖的方法，利用脉冲相机（spike camera）捕获的丰富时间信息，从模糊图像中生成更清晰、更高质量的新视角合成结果。
*   **⭐ 主要发现**: 本研究的核心贡献是提出了一种名为SpikeNVS的新方法，该方法创新性地利用脉冲相机数据来增强从模糊图像进行的新视角合成。脉冲相机与传统RGB相机不同，能够捕获更全面的时间信息，为场景提供固有的清晰表示，这些数据可以作为额外的训练输入。SpikeNVS有效解决了现有事件相机与RGB结合方法（event-RGB）的固有局限性，例如其高昂的训练成本和在处理背景区域时的不足。通过整合脉冲相机提供的精细时间细节，本方法能够显著提升NVS的质量，即使训练图像存在严重的运动模糊，也能生成更清晰、更精确的场景重建和新视角渲染。这为在复杂动态环境下实现高质量的神经场渲染提供了新的途径。

---
### [[A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation]](http://arxiv.org/abs/2404.05858v1)
**📅 发布日期**: 2024-04-08

*   **👥 作者**: Ahmed Faisal Abdelrahman, Matias Valdenegro-Toro, Maren Bennewitz, Paul G. Plöger
*   **🎯 研究目的**:
    神经形态计算（Neuromorphic computing）旨在模仿大脑的计算原理，并推动了基于事件的视觉（event-based vision）和脉冲神经网络（SNNs）等领域的研究。事件相机（Event cameras, ECs）因其卓越的功耗、响应延迟和动态范围优势而备受关注，而脉冲神经网络（SNNs）作为传统人工神经网络（ANNs）的替代方案，在视觉分类等任务中展现出降低能耗和推理时间的潜力。然而，尽管这些新兴范式具有显著优势，但在航空机器人领域之外的应用探索仍然非常有限。本研究旨在填补这一空白，深入探究受大脑启发的感知和数据处理方法（即事件相机和SNNs）在配备摄像头的机器人操作臂中进行避障任务的效用，旨在为机器人操作提供一种新型、高效且鲁棒的避障解决方案。
*   **⭐ 主要发现**:
    本研究的核心贡献在于开发了一种新颖的神经形态方法，专门用于配备摄像头的机器人操作臂的避障任务。这代表了将事件相机和脉冲神经网络等脑启发技术应用于传统上较少探索的机器人操作领域的创新尝试。通过利用事件相机在捕获局部强度变化方面的独特优势，以及脉冲神经网络在模拟生物神经元动力学和实现高效推理方面的潜力，该方法旨在克服传统避障方案在功耗、延迟和动态范围方面的局限性。尽管摘要内容有限，但其主要创新点在于将这些先进的神经形态技术引入到机器人操作这一复杂且对实时性要求高的领域，有望为机器人避障提供更低功耗、更低延迟且更鲁棒的解决方案，从而推动神经形态计算在更广泛机器人应用中的发展。

---
### [[基于超图的多视角事件相机行为识别]](http://arxiv.org/abs/2403.19316v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2024-03-28

*   **👥 作者**: Yue Gao, Jiaxuan Lu, Siqi Li, Yipeng Li, Shaoyi Du
*   **🎯 研究目的**: 视频数据中的行为识别是具有广泛应用的基础性研究领域。然而，单视角行为识别因其对单一视角的依赖而存在局限性。相比之下，多视角方法能够从不同视角捕获互补信息，从而提高识别精度。近年来，事件相机作为一种创新的仿生传感器应运而生，推动了基于事件的行为识别技术的发展。然而，现有工作主要集中在单视角场景，在多视角事件数据利用方面存在空白，尤其是在信息不足和语义错位等挑战上。为弥补这一空白，本文旨在引入HyperMV，一个多视角基于事件的行为识别框架。
*   **⭐ 主要发现**: 本文的核心贡献是提出了HyperMV，一个专门用于多视角事件相机行为识别的创新框架。该框架旨在有效利用来自多个事件相机的互补信息，以克服传统单视角方法的局限性以及多视角事件数据中固有的信息不足和语义错位问题。HyperMV的关键创新在于它能够将离散的事件数据转换为类帧表示，从而为后续处理和分析奠定基础。尽管摘要中未完全展开其具体的超图构建和信息融合机制，但该研究为基于事件的多视角行为识别领域开辟了新的研究方向，有望显著提升在复杂动态环境下的行为识别性能，并为未来事件相机在多视角感知任务中的应用提供了新的思路。

---
### [[基于事件相机的跟踪辅助目标检测]](http://arxiv.org/abs/2403.18330v3)
**📅 发布日期**: 2024-03-27

*   **👥 作者**: Ting-Kang Yen, Igor Morawski, Shusil Dangi, Kai He, Chung-Yi Lin, Jia-Fong Yeh, Hung-Ting Su, Winston Hsu
*   **🎯 研究目的**: 事件相机因其高动态范围和无运动模糊等卓越特性，在计算机视觉领域的目标检测任务中日益受到关注。然而，事件数据的异步性和稀疏性导致当目标相对于相机没有相对运动时，目标会变得“不可见”，这给事件目标检测带来了重大挑战。尽管现有工作尝试通过隐式学习记忆来保留尽可能多的时间线索，但这些隐式记忆在有效保存长期特征方面仍面临困难。本文旨在解决这一问题，将这些“不可见”目标视为“伪遮挡”目标，并通过跟踪穿越遮挡的方式来实现对它们的检测。
*   **⭐ 主要发现**: 本文提出了一种创新的方法来解决事件相机目标检测中“不可见”目标的问题。首先，论文引入了目标的“可见性属性”概念。其次，贡献了一种自动标注算法，该算法不仅能清理现有数据，还能为这些“不可见”目标生成相应的标签。核心创新在于将由于缺乏相对运动而“不可见”的目标视为一种“伪遮挡”状态，并通过设计跟踪机制来持续检测它们，即使它们在事件流中暂时消失。这种方法有效克服了事件数据在目标静止时无法产生事件的固有局限性，有望显著提升事件相机目标检测在复杂场景下（如短暂静止或缓慢移动目标）的鲁棒性和完整性。

---
### [Ev-Edge: Efficient Execution of Event-based Vision Algorithms on Commodity Edge Platforms](http://arxiv.org/abs/2403.15717v1)
**📅 发布日期**: 2024-03-23

*   **👥 作者**: Shrihari Sridharan, Surya Selvam, Kaushik Roy, Anand Raghunathan
*   **🎯 研究目的**: 事件相机因其高时间分辨率、高动态范围和可忽略的运动模糊等优势，已成为自动驾驶系统中有前景的传感模态。为了处理这类传感器产生的异步时间事件流，近期研究表明，结合人工神经网络（ANNs）、脉冲神经网络（SNNs）以及混合SNN-ANN算法对于在多种感知任务中实现高精度至关重要。然而，本研究观察到，在配备CPU、GPU和神经网络加速器等异构处理单元的商用边缘平台上执行这些工作负载时，性能表现不佳。这主要是由于事件流的非规则特性与算法的多样化特性之间存在不匹配。因此，本研究旨在解决这一效率瓶颈，实现事件视觉算法在商用边缘平台上的高效执行。
*   **⭐ 主要发现**: 论文深入分析了事件视觉算法（包括ANNs、SNNs和混合SNN-ANN算法）在商用边缘平台上执行时面临的性能挑战，指出其核心问题在于不规则的事件流数据与算法多样性在异构硬件上的映射不匹配。尽管摘要未提供具体的解决方案细节和实验结果，但根据论文标题“Ev-Edge: Efficient Execution...”，可以推断本研究的核心贡献是提出了名为“Ev-Edge”的框架或方法，旨在优化事件视觉算法在商品边缘平台上的执行效率。Ev-Edge有望通过有效管理事件流的异步性和算法的异构性，充分利用边缘平台上的CPU、GPU和神经网络加速器等资源，从而显著提升事件视觉应用的实时性能和部署可行性。

---
### [[SFOD: Spiking Fusion Object Detector]](http://arxiv.org/abs/2403.15192v1)
**📅 发布日期**: 2024-03-22

*   **👥 作者**: Yimeng Fan, Wei Zhang, Changsong Liu, Mingyang Li, Wenrui Lu
*   **🎯 研究目的**: 事件相机因其高时间分辨率、高动态范围、低功耗和高像素带宽等特性，在特定场景下的目标检测中展现出独特优势。然而，事件数据固有的稀疏性和异步性对现有目标检测算法提出了挑战。尽管受人脑信息处理方式启发的脉冲神经网络（SNNs）被视为潜在解决方案，但其在事件相机目标检测中的当前实现性能有限。本文旨在解决这些问题，提出一种简单高效的基于SNN的目标检测方法，以有效利用事件相机数据。
*   **⭐ 主要发现**: 本文提出了脉冲融合目标检测器（SFOD），这是一种简单高效的基于SNN的目标检测方法。其核心创新在于设计了一个“脉冲融合模块”（Spiking Fusion Module），该模块首次实现了对事件数据的有效融合处理。SFOD的提出旨在克服事件数据稀疏性和异步性带来的挑战，显著提升脉冲神经网络在事件相机目标检测任务中的性能，为低功耗、高效率的目标检测提供了新的解决方案。

---
### [[EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-based Detection with Recurrent Spiking Neural Networks]](http://arxiv.org/abs/2403.12574v2)
**📅 发布日期**: 2024-03-19

*   **👥 作者**: Ziming Wang, Ziling Wang, Huaning Li, Lang Qin, Runhao Jiang, De Ma, Huajin Tang
*   **🎯 研究目的**: 事件相机因其高动态范围和时间分辨率，在运动模糊和挑战性光照条件下尤其适用于目标检测。然而，现有方法大多侧重于优化时空表示和检测骨干网络，却忽视了关键的自适应事件采样问题。脉冲神经网络（SNNs）以其事件驱动和稀疏脉冲通信的特性，为解决这一挑战提供了天然的契合点。本研究旨在解决事件相机目标检测中自适应事件采样不足的问题，并探索SNNs在其中的应用潜力，以实现端到端的自适应采样和表示。
*   **⭐ 主要发现**: 本研究发现，脉冲神经元的动力学行为与理想的时间事件采样器高度吻合。受此启发，论文提出了一种新颖的自适应采样模块，该模块能够利用SNNs的内在特性对事件流进行高效的自适应采样。通过将此模块与循环脉冲神经网络相结合，研究构建了一个名为EAS-SNN的端到端系统，实现了事件数据的自适应采样和表示，并将其应用于事件基目标检测。这一创新性方法为事件相机数据处理提供了一种更高效、更符合生物学原理的范式，有望显著提升事件基检测系统在复杂动态环境下的性能。

---
### [[Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention]](http://arxiv.org/abs/2403.10173v4)
**📅 发布日期**: 2024-03-15

*   **👥 作者**: Soikat Hasan Ahmed, Jan Finkbeiner, Emre Neftci
*   **🎯 研究目的**: 事件相机因其高时间分辨率、宽动态范围和极小的运动模糊，在鲁棒对象检测方面展现出巨大潜力。然而，尽管脉冲神经网络（SNNs）在神经形态硬件上处理事件数据时具有能效和低延迟的优势，它们在精度和灵活性上往往不如人工神经网络（ANNs）。本研究旨在解决这一问题，通过结合SNN和ANN架构的优点，开发一种高效的事件基对象检测方法，以充分利用事件相机数据的独特特性，实现更优异的性能。
*   **⭐ 主要发现**:
    *   论文引入了**基于注意力机制的混合SNN-ANN骨干网络**，用于事件基对象检测，旨在融合SNN的能效和ANN的精度优势。
    *   提出了一种新颖的**基于注意力机制的SNN-ANN桥接模块**。该模块能够从SNN层捕获稀疏的空间和时间关系，并将其高效地转换为密集的特征图，供ANN部分处理，从而实现了两种网络范式之间的无缝信息传递。
    *   此外，研究还提出了一种变体，将**DWConvL-STM模块集成到ANN块中**，进一步增强了网络的特征提取能力。
    *   通过这种混合架构，论文旨在克服传统SNN在精度和灵活性上的局限性，同时利用事件相机数据的高时间分辨率和动态范围特性，实现更鲁棒和高效的对象检测。

---
### [State Space Models for Event Cameras](http://arxiv.org/abs/2402.15584v3)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2024-02-23

*   **👥 作者**: Nikola Zubić, Mathias Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 当前处理事件相机数据的最先进深度神经网络通常首先将事件的时间窗口转换为密集的、网格状的输入表示。然而，这种方法导致模型在部署到与训练时不同（特别是更高）的推理频率（即更小的时间窗口）时，泛化能力显著下降。本研究旨在解决这一挑战，通过引入新的模型架构，提高事件相机视觉模型在不同推理频率下的适应性和泛化能力，避免重新训练的需要。
*   **⭐ 主要发现**:
    *   **引入创新模型：** 论文首次将带有可学习时间尺度参数的状态空间模型（SSMs）引入事件相机视觉领域。
    *   **解决频率泛化问题：** 这种新颖的设计使得模型能够自适应地处理不同推理频率下的事件数据，而无需针对每种频率重新训练网络，显著提升了模型的泛化能力和部署灵活性。
    *   **对抗混叠效应：** 研究还深入探讨了两种有效策略，以对抗模型在更高推理频率下部署时可能出现的混叠效应。
    *   **性能验证：** 通过与基于RNN和Transformer架构的现有方法进行全面评估，证明了所提出的SSM方法在处理事件相机数据方面的有效性和优越性。

---
### [[Temporal-Spatial Processing of Event Camera Data via Delay-Loop Reservoir Neural Network]](http://arxiv.org/abs/2403.17013v1)
**📅 发布日期**: 2024-02-12

*   **👥 作者**: Richard Lau, Anthony Tylan-Tyler, Lihan Yao, Rey de Castro Roberto, Robert Taylor, Isaiah Jones
*   **🎯 研究目的**: 本文提出一种用于视频处理（特别是事件相机视频数据）的时空模型。研究动机源于作者团队先前对延迟循环储层（DLR）神经网络在视频处理方面的研究，并在此基础上提出并深入探讨了“时空猜想”（Temporal-Spatial Conjecture, TSC）。TSC的核心观点是：视频信号的时间表示中蕴含着大量重要信息，且机器学习算法若能对视频的空间和时间分量进行独立优化，将显著提升智能处理的性能。本研究的核心目的便是验证或驳斥这一时空猜想。
*   **⭐ 主要发现**: 为了验证或驳斥上述时空猜想（TSC），论文提出了一种创新的“视觉马尔可夫模型”（Visual Markov Model, VMM）。该模型的核心贡献在于能够将视频数据有效地分解为独立的空间和时间分量，并通过估计这些分量之间的“互信息”（Mutual Information, MI）来量化其信息含量和相互依赖性。尽管摘要未详细阐述实验结果，但VMM的提出为深入理解视频数据的时空特性提供了一个新的、量化的分析框架，有望为基于时空分离优化的智能视频处理算法设计奠定理论基础。

---
### [[E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning]](http://arxiv.org/abs/2401.08117v1)
**📅 发布日期**: 2024-01-16

*   **👥 作者**: Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Tongliang Liu
*   **🎯 研究目的**:
    生物启发的事件相机（或称动态视觉传感器）能够以高时间分辨率和高动态范围异步捕获逐像素的亮度变化（即事件流）。然而，这些非结构化的时空事件流难以提供对人类视觉友好的、具有丰富语义信息的直观可视化。这催生了“事件到视频”（E2V）解决方案的需求，即以事件流为输入，生成高质量的视频帧以实现直观可视化。当前大多数E2V解决方案主要依赖数据驱动，却忽视了事件流与视频帧之间潜在统计关系的先验知识，过度依赖深度神经网络的非线性和泛化能力，导致在生成高质量视频方面面临挑战。本研究旨在通过结合理论启发和模型辅助的深度学习方法，开发一种能够从事件相机数据生成高质量视频的E2V解决方案，以克服现有纯数据驱动方法的局限性。
*   **⭐ 主要发现**:
    （注：提供的摘要不完整，以下主要发现基于论文标题和已提供的摘要内容推断。）
    本研究的核心贡献在于提出了一种名为E2HQV的创新性“事件到视频”（E2V）解决方案，该方案通过结合“理论启发”和“模型辅助”的深度学习方法，旨在克服现有纯数据驱动E2V方案的局限性。与当前主流方法不同，E2HQV不再仅仅依赖深度神经网络的非线性和泛化能力，而是融入了事件流与视频帧之间潜在统计关系的先验知识和理论模型。这种理论与模型辅助的深度学习范式，预计能更有效地处理事件相机数据固有的非结构化和高动态范围特性，从而显著提升生成视频的质量。该方法有望生成具有丰富语义信息和高视觉质量的视频帧，为事件相机数据的直观可视化提供了更鲁棒和高性能的解决方案，并可能为未来事件相机数据处理的理论与实践结合提供新的方向。

---
### [[CRSOT: Cross-Resolution Object Tracking using Unaligned Frame and Event Cameras]](http://arxiv.org/abs/2401.02826v1)
**📅 发布日期**: 2024-01-05

*   **👥 作者**: Yabin Zhu, Xiao Wang, Chenglong Li, Bo Jiang, Lin Zhu, Zhixiang Huang, Yonghong Tian, Jin Tang
*   **🎯 研究目的**: 现有RGB-DVS跟踪数据集分辨率较低（346x260），难以满足实际应用需求。在许多实际系统中，仅部署可见光相机，而新型神经形态相机（如事件相机）可能具有不同的分辨率。尽管最新的神经形态传感器可以输出高分辨率事件流，但在空间和时间上实现事件流与传统帧的严格对齐非常困难。因此，本文旨在解决一个有价值但尚未被充分研究的问题：如何在神经形态相机和可见光相机未对齐的情况下实现精确的目标跟踪。该研究正式提出了利用未对齐的帧相机和事件相机进行目标跟踪的任务。
*   **⭐ 主要发现**: 本文的核心贡献在于正式提出了一个全新的研究任务：利用未对齐的神经形态相机（事件相机）和可见光相机（帧相机）进行目标跟踪。为了推动这一重要但未被充分研究的领域的发展，作者团队构建了首个专门用于未对齐帧-事件目标跟踪的数据集——CRSOT。这一数据集的发布为后续研究提供了关键的基准和资源，有望促进在实际应用中解决传感器对齐挑战下的高精度目标跟踪技术的发展。

---
### [[EvPlug: Learn a Plug-and-Play Module for Event and Image Fusion]](http://arxiv.org/abs/2312.16933v1)
**📅 发布日期**: 2023-12-28

*   **👥 作者**: Jianping Jiang, Xinyu Zhou, Peiqi Duan, Boxin Shi
*   **🎯 研究目的**: 事件相机和RGB相机在成像特性上具有互补优势：事件相机拥有高动态范围（HDR）和高时间分辨率，而RGB相机则提供丰富的纹理和色彩信息。这种互补性使得将事件相机整合到中高层基于RGB的视觉任务中具有广阔前景。然而，在多模态融合、数据标注和模型架构设计方面存在显著挑战。本研究旨在提出EvPlug，一个可学习的即插即用事件与图像融合模块。其核心目标是利用现有基于RGB模型的监督信息，学习如何将事件流与图像特征有效融合，从而赋予基于RGB的模型处理高动态范围和快速运动场景的鲁棒性，并支持高时间分辨率的推理能力。
*   **⭐ 主要发现**: 本论文的核心贡献在于提出了EvPlug，一个创新的、可学习的即插即用事件与图像融合模块。其主要创新点体现在：1) 它巧妙地利用现有基于RGB模型的监督信息来学习事件与图像的融合策略，从而有效解决了多模态数据标注困难的挑战；2) EvPlug以一种灵活的插件形式，将事件流与图像特征无缝集成到现有的基于RGB的模型中。通过这种方式，EvPlug成功地赋予了基于RGB的视觉模型处理高动态范围（HDR）和快速运动场景的强大鲁棒性，并使其能够进行高时间分辨率的推理。这一方法为在复杂动态环境下提升计算机视觉系统的性能提供了一种高效且可扩展的新范式。

---
### [[Low-power, Continuous Remote Behavioral Localization with Event Cameras]](http://arxiv.org/abs/2312.03799v2)
**📅 发布日期**: 2023-12-06

*   **👥 作者**: Friedhelm Hamann, Suman Ghosh, Ignacio Juarez Martinez, Tom Hart, Alex Kacelnik, Guillermo Gallego
*   **🎯 研究目的**: 自然科学研究对动物行为的量化需求日益增长，尽管计算机视觉方法已广泛应用于行为自动化分析，但在野外远程观测中，恶劣的光照条件、有限的电源供应和数据存储能力仍是巨大挑战。本研究旨在利用事件相机（Event Cameras）独特的低功耗和高动态范围优势，开发一种适用于远程、电池供电环境下的连续动物行为定位方法。具体而言，论文将该问题表述为时间动作检测任务，并以量化南极帽带企鹅的“狂喜展示”（ecstatic display）行为为例进行验证。
*   **⭐ 主要发现**: 该研究创新性地将事件相机引入到野生动物行为的远程监测中，利用其低功耗和高动态范围特性，有效克服了传统计算机视觉方法在野外复杂光照和电源受限条件下的局限。论文将动物行为量化问题建模为时间动作检测任务，旨在精确识别行为的起始和结束时间。通过在南极洲对帽带企鹅繁殖群落进行数周的实地记录，并对事件数据进行标注，初步验证了事件相机在连续行为定位方面的可行性和独特优势。这项工作为自然科学研究提供了一种高效、节能且可靠的动物行为量化新范式，尤其适用于对电池依赖型远程监测场景。

---
### [[Retina : Low-Power Eye Tracking with Event Camera and Spiking Hardware]](http://arxiv.org/abs/2312.00425v2)
**📅 发布日期**: 2023-12-01

*   **👥 作者**: Pietro Bonazzi, Sizhen Bian, Giovanni Lippolis, Yawei Li, Sadique Sheik, Michele Magno
*   **🎯 研究目的**: 本研究旨在提出一种创新的神经形态眼动追踪方法，该方法利用动态视觉传感器（DVS）相机捕获的纯事件数据。通过整合直接训练的脉冲神经网络（SNN）回归模型，并结合先进的低功耗边缘神经形态处理器（如Speck），本研究旨在显著提升眼动追踪系统的精度和效率，特别是在对功耗有严格要求的边缘计算场景下实现高效、低功耗的眼动追踪。
*   **⭐ 主要发现**:
    *   **提出神经形态眼动追踪方法：** 论文介绍了一种利用纯事件数据进行眼动追踪的神经形态方法，该方法基于DVS相机捕获的事件流。
    *   **构建新型数据集Ini-30：** 为支持事件驱动的眼动追踪研究，作者收集并引入了一个名为“Ini-30”的代表性事件基眼动追踪数据集。该数据集由30名志愿者佩戴两台安装在眼镜上的DVS相机收集。
    *   **开发高效SNN模型“Retina”：** 论文设计并实现了一个名为“Retina”的脉冲神经网络（SNN）模型，该模型基于积分发放（IAF）神经元。Retina模型参数量极小，仅有64k个参数，比现有最新模型少6.63倍，显著提升了效率。
    *   **实现高精度瞳孔追踪：** 在64x64 DVS输入下，Retina模型实现了仅3.24像素的瞳孔追踪误差，展现出高精度性能。
    *   **结合低功耗硬件：** 该框架集成了先进的低功耗边缘神经形态处理器Speck，共同推动了眼动追踪系统的精度和效率，使其适用于低功耗边缘应用。

---
### [[GET: Group Event Transformer for Event-Based Vision]](http://arxiv.org/abs/2310.02642v1)
**📅 发布日期**: 2023-10-04

*   **👥 作者**: Yansong Peng, Yueyi Zhang, Zhiwei Xiong, Xiaoyan Sun, Feng Wu
*   **🎯 研究目的**: 事件相机作为一种新型神经形态传感器正受到广泛关注。然而，现有的基于事件的骨干网络主要依赖于基于图像的设计，将事件转换为图像后提取空间信息，却忽视了事件的关键属性，如时间戳和极性。为解决这一问题，本文提出了一种新颖的、基于组的事件视觉Transformer骨干网络（GET），旨在整个特征提取过程中将时间-极性信息与空间信息解耦。
*   **⭐ 主要发现**: 本文的核心贡献是提出了Group Event Transformer（GET）模型，旨在更有效地利用事件相机的独特数据特性。GET的关键创新点包括：
    *   引入了一种新的事件表示方法——Group Token，它根据事件的时间戳和极性对异步事件进行分组。
    *   GET模型应用了Event Dual Self-Attention模块，进一步处理这些分组后的事件信息。
    *   通过这些设计，GET成功地在特征提取过程中将事件的时间-极性信息与空间信息解耦，从而克服了现有方法忽视事件关键属性的局限性，有望在事件视觉任务中取得更优异的性能。

---
### [[Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline]](http://arxiv.org/abs/2309.14611v1)
**📅 发布日期**: 2023-09-26

*   **👥 作者**: Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang
*   **🎯 研究目的**: 生物启发式事件相机在视觉目标追踪领域日益受到关注。然而，现有方法存在局限性：一类方法依赖于对齐的RGB和事件数据进行精确追踪，但这导致推理成本较高；另一类纯事件追踪方法则易受噪声事件或稀疏空间分辨率的影响。针对这些挑战，本研究旨在提出一种新颖的框架，该框架能够在训练阶段充分利用多模态/多视角信息进行知识迁移，从而在测试阶段仅依赖事件信号即可实现高速、低延迟的视觉目标追踪。
*   **⭐ 主要发现**:
    *   **创新框架**: 论文提出了一种新颖的**分层知识蒸馏框架**，用于事件流视觉目标追踪。该框架的核心创新在于其能够在训练阶段充分利用**多模态（如RGB帧和事件流）和多视角信息**进行知识迁移。
    *   **实现机制**: 具体而言，该方法首先训练一个基于Transformer的多模态教师追踪框架，该框架同时接收RGB帧和事件流作为输入。通过这种方式，教师模型能够学习到丰富的跨模态信息。
    *   **性能优势**: 经过知识蒸馏后，学生模型在测试阶段仅需**事件信号**即可实现**高速且低延迟**的视觉目标追踪，有效克服了现有纯事件追踪方法易受噪声和稀疏分辨率影响的问题，同时也避免了融合方法的高推理成本。
    *   **数据集与基线**: 除了提出新的追踪框架，论文还构建了一个**高分辨率的基准数据集**，并提出了一个**新的基线**，为事件流视觉目标追踪领域的研究提供了重要的资源和性能参考。

---
### [[Dense Voxel 3D Reconstruction Using a Monocular Event Camera]](http://arxiv.org/abs/2309.00385v1)
**📅 发布日期**: 2023-09-01

*   **👥 作者**: Haodong Chen, Vera Chung, Li Tan, Xiaoming Chen
*   **🎯 研究目的**: 这篇论文旨在解决单目事件相机在三维重建领域，特别是针对VR应用中，应用不足且存在密度限制的问题。事件相机作为一种受生物系统启发的传感器，以其高动态范围、高帧率和极低功耗等优势，在帧插值、语义分割、里程计和SLAM等领域展现出巨大潜力。然而，在三维重建方面，现有方法主要集中于深度图估计，且若要实现稠密三维重建通常需要多相机系统，而单目事件相机仅能生成半稠密结果。因此，本研究的核心目标是探索并实现使用单目事件相机进行稠密体素（Voxel）三维重建，以克服现有技术的局限性，并为VR应用提供更优质、更完整的环境三维数据。
*   **⭐ 主要发现**: 尽管摘要部分不完整，但结合论文标题和其提出的问题，可以推断出本研究的核心贡献在于提出了一种创新的方法，首次实现了仅使用单目事件相机进行稠密体素三维重建。这克服了以往单目事件相机三维重建方法只能生成半稠密结果的局限，也避免了传统稠密三维重建所需的多相机系统复杂性。通过开发这种新方法，论文为利用事件相机生成高精度、高密度的三维模型提供了新的途径，尤其对于需要详细环境建模的虚拟现实（VR）应用具有重要意义，有望显著提升VR体验的真实感和沉浸感。

---
### [[3ET: Efficient Event-based Eye Tracking using a Change-Based ConvLSTM Network]](http://arxiv.org/abs/2308.11771v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2023-08-22

*   **👥 作者**: Qinyu Chen, Zuowen Wang, Shih-Chii Liu, Chang Gao
*   **🎯 研究目的**: 本研究旨在为下一代可穿戴医疗技术（如AR/VR头显）开发一种高效的基于事件的眼动追踪系统。针对传统帧式相机在低延迟和稀疏数据处理方面的局限性，论文提出利用视网膜启发式事件相机的优势，即其低延迟响应和稀疏输出事件流。核心研究目的是设计并实现一个名为Change-Based Convolutional Long Short-Term Memory (CB-ConvLSTM) 的网络模型，以高效地从事件流中提取时空特征，实现精确的瞳孔追踪。
*   **⭐ 主要发现**: 论文的核心贡献在于提出了一种名为Change-Based Convolutional Long Short-Term Memory (CB-ConvLSTM) 的新型稀疏网络模型，专为基于事件的眼动追踪设计。该架构能够高效地从事件流中提取时空特征，实现精确的瞳孔追踪。实验结果表明，CB-ConvLSTM在瞳孔追踪性能上优于传统的卷积神经网络（CNN）结构。其关键创新在于利用了delta编码的循环路径，显著增强了激活的稀疏性。在对标记瞳孔的v2e生成事件数据集进行测试时，该方法在不损失准确性的前提下，将算术运算量减少了约4.7倍。这种显著的效率提升对于AR/VR头显等对计算资源和功耗有严格要求的下一代可穿戴设备至关重要，为实现更高效、更实用的眼动追踪技术奠定了基础。

---
### [[SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition]](http://arxiv.org/abs/2308.04369v3)
**📅 发布日期**: 2023-08-08

*   **👥 作者**: Xiao Wang, Yao Rong, Zongzhen Wu, Lin Zhu, Bo Jiang, Jin Tang, Yonghong Tian
*   **🎯 研究目的**: 事件相机（Event Camera）模式识别是近年来新兴的研究领域。现有研究通常将事件流转换为图像、图或体素，然后采用深度神经网络进行分类。然而，这些方法在简单事件识别数据集上虽能取得良好性能，但仍面临两个主要局限：
    1.  它们仅利用空间稀疏的事件流进行识别，可能无法充分捕获颜色和详细纹理信息。
    2.  它们要么采用脉冲神经网络（SNN）以实现能效，但性能不佳；要么采用人工神经网络（ANN）以实现高性能，但能耗较高。
    本研究旨在解决现有方法在事件相机识别中面临的这些挑战，特别是寻求在能效和识别性能之间取得平衡。

*   **⭐ 主要发现**: 为了解决上述问题，本研究提出了名为SSTFormer的模型，旨在实现帧-事件融合的识别。SSTFormer创新性地结合了脉冲神经网络（SNN）和记忆支持Transformer（Memory Support Transformer）。这一设计旨在：
    1.  同时利用事件流的稀疏性与帧数据的丰富纹理和颜色信息，弥补仅使用事件流时信息不足的缺陷。
    2.  通过将SNN的能效优势与Transformer在高性能识别方面的能力相结合，SSTFormer致力于在能耗和识别准确性之间找到最佳平衡点，克服了现有方法在能效与性能之间难以兼顾的困境。
    尽管摘要未提供具体实验结果，但可以推断，SSTFormer有望在事件相机模式识别任务中展现出更优异的综合性能和能效表现，为该领域提供了一种新的、更全面的解决方案。

---
### [[Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems]](http://arxiv.org/abs/2307.13600v1)
**📅 发布日期**: 2023-07-25

*   **👥 作者**: Muhammad Ali Farooq, Waseem Shariff, Mehdi Sefidgar Dilmaghani, Wang Yao, Moazam Soomro, Peter Corcoran
*   **🎯 研究目的**: 本文旨在探讨和分析各种光学技术，以设计和开发先进的车载系统，特别是最先进的车外前向视觉系统和车内驾驶员监控系统。研究背景是光学传感器在关键应用中获取现实世界数据的重要性，这些数据与机器学习算法结合能够提供有意义的信息，从而显著增强人类视觉能力。论文的核心目标是利用不同光学模态（如长波热成像、近红外、神经形态/事件相机、可见光CMOS相机和深度相机）的独特优势，为实时环境中的潜在应用提供深入讨论。
*   **⭐ 主要发现**: 本文的核心贡献在于对多种光学传感技术在先进车载系统中的应用进行了深入探讨。论文详细介绍了长波热成像（LWIR）相机、近红外（NIR）相机、神经形态/事件相机、可见光CMOS相机和深度相机等关键光学传感器。主要发现是，通过整合这些不同模态光学传感器的独特优势，可以设计和开发出最先进的车外前向视觉系统和车内驾驶员监控系统。论文进一步讨论了如何利用这些传感器的独特能力，在实时环境中实现多种潜在应用，从而为关键车载系统提供决策性数据，显著增强其感知和信息处理能力。

---
### [[Best of Both Worlds: Hybrid SNN-ANN Architecture for Event-based Optical Flow Estimation]](http://arxiv.org/abs/2306.02960v2)
**📅 发布日期**: 2023-06-05

*   **👥 作者**: Shubham Negi, Deepika Sharma, Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 在机器人领域，事件相机因其稀疏和异步的事件输出，正成为传统帧相机在捕获高速运动和高动态范围场景时的低功耗替代方案。脉冲神经网络（SNNs）凭借其异步事件驱动计算，在从这些事件流中提取时空特征方面展现出巨大潜力。然而，标准模拟神经网络（ANNs）却无法有效处理事件数据。尽管SNNs前景广阔，但其训练面临诸多挑战，包括额外的可训练参数（如阈值和泄漏）、在深层网络中出现的脉冲消失问题，以及不可微分的二值激活函数。本研究旨在探索一种混合SNN-ANN架构，以结合两者的优势，克服SNN训练的固有难题，并有效应用于事件相机数据的处理，特别是事件光流估计任务。
*   **⭐ 主要发现**: 论文提出了一种创新的混合SNN-ANN架构，旨在实现“两全其美”。该架构成功地结合了SNN在处理事件数据（如低功耗和异步特性）方面的固有优势，与ANN在训练稳定性和性能优化上的成熟性。通过这种混合方法，该研究有效克服了纯SNN在训练过程中面临的挑战，例如深层网络中的脉冲消失问题和不可微分激活函数带来的梯度传播困难。这一创新模型被成功应用于事件光流估计任务，为高效处理事件相机数据提供了一种新的范式，有望在机器人和计算机视觉领域推动基于事件的感知技术发展。

---
### [[Deformable Convolutions and LSTM-based Flexible Event Frame Fusion Network for Motion Deblurring]](http://arxiv.org/abs/2306.00834v1)
**📅 发布日期**: 2023-06-01

*   **👥 作者**: Dan Yang, Mehmet Yamac
*   **🎯 研究目的**: 传统RGB相机以固定帧率捕获图像，而事件相机则异步记录场景中的亮度变化，产生稀疏且异步的数据流。尽管事件数据包含对RGB图像运动去模糊有用的信息，但如何有效融合事件与图像信息仍是一个重大挑战。现有最先进的基于CNN的去模糊方案通常通过在一段时间内累积事件数据来生成多个2D事件帧，但这些方法大多采用固定且预定义的事件帧数量，这在快速移动物体或长时间曝光等场景下会显著降低时间分辨率。本研究旨在解决这一问题，开发一种更灵活的事件数据融合机制，以提高运动去模糊的性能。
*   **⭐ 主要发现**: 本文提出了一种基于可变形卷积（Deformable Convolutions）和长短期记忆网络（LSTM）的灵活事件帧融合网络（Flexible Event Frame Fusion Network），用于运动去模糊。该网络的核心创新在于克服了现有方法中事件帧数量固定预设的局限性。通过引入灵活的融合机制，该网络能够更好地处理事件数据的异步性和稀疏性，并自适应地融合不同时间尺度的事件信息，从而显著提高在动态场景下（特别是存在快速移动物体或长时间曝光时）的运动去模糊效果。具体而言，可变形卷积允许网络自适应地采样特征，而LSTM则能有效建模事件数据的时间序列依赖性，使得网络能够更有效地利用事件信息来恢复模糊图像的细节。

---
### [[Spiking-Fer: Spiking Neural Network for Facial Expression Recognition With Event Cameras]](http://arxiv.org/abs/2304.10211v1)
**📅 发布日期**: 2023-04-20

*   **👥 作者**: Sami Barchid, Benjamin Allaert, Amel Aissaoui, José Mennesson, Chaabane Djéraba
*   **🎯 研究目的**: 面部表情识别（FER）是一个活跃的研究领域，深度学习模型在此领域取得了显著进展。然而，这些模型通常能耗巨大，难以在边缘设备上部署。为了解决这一问题，结合事件相机的脉冲神经网络（SNNs）提供了一种有前景的替代方案，它们能够以更低的能耗处理稀疏和异步事件。本研究旨在首次将事件相机应用于FER任务（称为“基于事件的FER”），并为此提出一种新型的SNN模型。
*   **⭐ 主要发现**:
    *   本研究首次确立了“基于事件的FER”（Event-based FER）这一概念，开创性地将事件相机引入面部表情识别领域。
    *   为推动该新领域的发展，论文首次创建了相关的基准数据集，通过将流行的视频FER数据集转换为事件流。
    *   针对这一新任务，作者提出了一种名为“Spiking-FER”的深度卷积脉冲神经网络（SNN）模型。
    *   该模型旨在利用SNN的低能耗特性和事件相机的稀疏异步数据处理能力，为边缘设备上的FER应用提供高效解决方案，并与类似的传统人工神经网络（ANNs）进行了比较。

---
### [[Neuromorphic Optical Flow and Real-time Implementation with Event Cameras]](http://arxiv.org/abs/2304.07139v2)
**📅 发布日期**: 2023-04-14

*   **👥 作者**: Yannick Schnider, Stanislaw Wozniak, Mathias Gehrig, Jules Lecomte, Axel von Arnim, Luca Benini, Davide Scaramuzza, Angeliki Pantazi
*   **🎯 研究目的**: 光流信息是许多计算机视觉流程中的重要组成部分，用于提供相对运动信息。尽管神经网络在光流估计方面表现出高精度，但其固有的复杂性往往使其难以应用于对效率和延迟要求严苛的边缘设备或机器人中。为应对这一挑战，本研究旨在利用事件相机视觉和脉冲神经网络（SNN）的最新发展，提出一种高效且低延迟的光流估计方法，从而在保证精度的同时，实现实时部署。
*   **⭐ 主要发现**:
    *   **新型网络架构**: 论文提出了一种受Timelens启发的全新网络架构，该架构在脉冲（spiking）和非脉冲（non-spiking）两种操作模式下，均显著提升了自监督光流的准确性，达到了当前最先进（state-of-the-art）的水平。
    *   **实时实现方法**: 为实现与物理事件相机的实时管道，研究提出了一种基于活动和延迟分析的系统化模型简化方法。这种方法能够有效地优化模型，使其满足边缘设备的计算和时间限制。
    *   **高速光流演示**: 实验证明，所提出的方法能够实现高速光流估计，这对于需要快速响应的机器人和边缘应用至关重要。这些创新为在资源受限环境下部署高性能光流系统提供了新的途径。
### [[Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution]](http://arxiv.org/abs/2303.13767v2)
**📅 发布日期**: 2023-03-24

*   **👥 作者**: Yunfan Lu, Zipeng Wang, Minjie Liu, Hongjian Wang, Lin Wang
*   **🎯 研究目的**:
    事件相机能够异步感知亮度变化，生成具有高动态范围和低延迟的事件流，这启发了利用事件流来指导极具挑战性的视频超分辨率（VSR）任务的研究。本文首次尝试解决一个新颖的问题：利用事件流的高时间分辨率特性，实现任意尺度的视频超分辨率。然而，在指导VSR时，如何有效表示事件流的时空信息是一个主要难点。本研究旨在提出一个统一的框架来解决这一问题，从而充分利用事件数据在VSR中的潜力。
*   **⭐ 主要发现**:
    为了克服在VSR中表示事件时空信息的困难，本文提出了一个新颖的框架，该框架将事件流的时空插值与视频超分辨率任务统一起来。其核心思想是通过学习隐式神经表示（Implicit Neural Representations），从查询的时空坐标以及RGB帧和事件流中提取的特征来生成超分辨率视频。这项工作为利用事件相机的高时间分辨率特性实现任意尺度VSR提供了一种开创性的方法，有望在事件引导的视频处理领域取得显著进展。

---
### [[Unsupervised Domain Adaptation for Training Event-Based Networks Using Contrastive Learning and Uncorrelated Conditioning]](http://arxiv.org/abs/2303.12424v1)
**📅 发布日期**: 2023-03-22

*   **👥 作者**: Dayuan Jian, Mohammad Rostami
*   **🎯 研究目的**: 事件相机在高动态范围环境和快速运动场景中为计算机视觉任务提供了可靠的测量能力。然而，由于事件相机技术的新兴性，将深度学习应用于事件视觉面临着标注数据稀缺的挑战。为了解决这一问题，从传统相机标注数据中获取并迁移知识成为一个切实可行的解决方案。本研究旨在开发一种无监督域适应算法，用于训练基于事件数据的图像分类深度网络。
*   **⭐ 主要发现**: 本论文的核心贡献在于提出了一种新颖的无监督域适应算法，该算法结合了对比学习（contrastive learning）和数据不相关条件化（uncorrelated conditioning）技术，以训练用于事件数据图像分类的深度网络。实验结果表明，所提出的解决方案在性能上超越了现有同类算法。这一成果为解决事件相机领域标注数据稀缺的难题提供了一条高效途径，有望加速深度学习在事件视觉应用中的发展。

---
### [[Taming Contrast Maximization for Learning Sequential, Low-latency, Event-based Optical Flow]](http://arxiv.org/abs/2303.05214v2)
**📅 发布日期**: 2023-03-09

*   **👥 作者**: Federico Paredes-Vallés, Kirk Y. W. Scheper, Christophe De Wagter, Guido C. H. E. de Croon
*   **🎯 研究目的**: 事件相机因其在解决复杂计算机视觉问题上提供低延迟和低功耗解决方案的潜力而备受关注。然而，现有方法多受限于传统基于帧的范式，未能充分发挥事件数据的独特优势，难以兑现事件相机在低延迟和低功耗方面的承诺。本研究旨在开发一种新颖的自监督学习流程，用于事件序列数据的光流估计，使其模型能够扩展到高推理频率，从而真正释放事件相机的潜能。
*   **⭐ 主要发现**: 本文提出了一种新颖的自监督学习流程，用于事件序列数据的光流估计，能够实现模型在高推理频率下的扩展。该流程的核心是一个持续运行的有状态神经网络模型。其训练过程利用了对比度最大化（Contrast Maximization）的一种新颖公式，该方法经过“驯服”（taming），使其能够有效学习事件数据，克服了传统对比度最大化方法在处理事件数据时可能遇到的挑战，从而实现低延迟、高精度的光流估计，为事件相机在实时、低功耗应用中的部署奠定了基础。

---
### EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision
**📅 发布日期**: 2023-03-06

*   **👥 作者**: Jianping Jiang, Jiahe Li, Baowen Zhang, Xiaoming Deng, Boxin Shi
*   **🎯 研究目的**: 事件相机在3D手部姿态估计领域展现出巨大潜力，尤其擅长以低功耗方式应对快速运动和高动态范围的挑战。然而，由于其异步差分成像机制，存在两大难题：一是难以设计有效的事件表示来编码手部运动信息，特别是在手部静止时（导致运动模糊）；二是难以对时间密集的事件流进行完整标注。本文旨在提出EvHandPose框架，通过创新的手部流表示来解决上述挑战，实现准确的3D手部姿态估计，并缓解运动模糊问题，同时在稀疏标注条件下也能有效工作。

*   **⭐ 主要发现**: 本文提出了EvHandPose框架，用于基于事件的3D手部姿态估计，并取得了以下主要发现和贡献：
    *   **创新手部流表示**: 在Event-to-Pose模块中引入了新颖的手部流表示，有效编码手部运动信息。这一创新显著提高了手部姿态估计的准确性，并成功缓解了手部静止时常见的运动模糊问题。
    *   **解决稀疏标注问题**: 为了克服事件数据难以进行密集标注的挑战，EvHandPose在Pose-to-IWE（Image with Warped Events）模块中设计了对比度最大化（contrast maximization）和手部边缘约束（hand-edge constraints）机制。这些机制使得模型能够在仅有稀疏标注的情况下进行有效训练。
    *   **综合解决方案**: EvHandPose通过结合Event-to-Pose和Pose-to-IWE模块，提供了一个端到端的解决方案，能够利用事件相机的优势，在低功耗、高动态范围和快速运动场景下实现鲁棒且准确的3D手部姿态估计，克服了传统相机和事件相机自身在这一任务中的局限性。

---
### [[CERiL: Continuous Event-based Reinforcement Learning]](http://arxiv.org/abs/2302.07667v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2023-02-15

*   **👥 作者**: Celyn Walters, Simon Hadfield
*   **🎯 研究目的**: 本文旨在探索事件相机在实现连续时间强化学习方面的潜力。研究团队将连续时间强化学习问题形式化，其中利用连续、非同步的观测流来生成相应的环境输出动作流。这种非同步性极大地增强了系统的反应能力。研究的核心目标是开发一种方法，能够在从标准强化学习环境中导出的事件流上进行训练，从而解决所提出的连续时间强化学习问题，并证明事件流相比传统RGB图像在RL任务中的优势。
*   **⭐ 主要发现**: 论文提出了一种名为CERiL（Continuous Event-based Reinforcement Learning）的算法，该算法能够直接在事件流上进行训练，解决了连续时间强化学习问题。CERiL算法的关键创新在于使用了专门的网络层，这些网络层能够直接处理事件流，而不是将事件聚合到量化的图像帧中，从而避免了传统基于帧的方法所固有的延迟和信息损失。实验结果表明，与使用频率较低的RGB图像相比，事件流具有显著优势，能够提供更强的反应能力和更丰富的信息。所提出的CERiL系统在性能上超越了强化学习中常用的网络，甚至成功解决了传统方法难以处理的任务。这为开发更具反应性和效率的强化学习系统开辟了新途径，尤其适用于需要高实时性和低延迟的应用场景。

---
### [[Neuromorphic High-Frequency 3D Dancing Pose Estimation in Dynamic Environment]](http://arxiv.org/abs/2301.06648v2)
**📅 发布日期**: 2023-01-17

*   **👥 作者**: Zhongyang Zhang, Kaidong Chai, Haowen Yu, Ramzi Majaj, Francesca Walsh, Edward Wang, Upal Mahbub, Hava Siegelmann, Donghyun Kim, Tauhidur Rahman
*   **🎯 研究目的**: 当前，舞蹈作为一项全球性的运动，正日益融入传统和虚拟现实游戏平台，这为技术辅助的舞蹈空间带来了新机遇。这些平台主要依赖被动和连续的人体姿态估计作为输入捕获机制。然而，现有的解决方案（主要基于RGB或RGB-深度摄像头）存在显著局限：RGB摄像头在低光照条件下受运动模糊和低灵敏度影响；RGB-深度摄像头则功耗高、帧率低且工作距离有限。为了克服这些挑战，本研究旨在探索事件相机在舞蹈姿态估计中的潜力，利用其超低延迟、高能效和宽动态范围的特性，开发一种基于事件相机的高频率三维舞蹈姿态估计算法和系统。
*   **⭐ 主要发现**: 本研究的核心贡献是提出了名为“YeLan”的系统，这是一个基于事件相机的高频率三维舞蹈姿态估计算法。该系统旨在利用事件相机固有的超低延迟、高能效和宽动态范围特性，以克服传统RGB或RGB-深度摄像头在舞蹈姿态估计中面临的挑战，例如低光照下的运动模糊、低灵敏度、高功耗、低帧率和有限的工作距离。通过引入事件相机技术，YeLan有望为舞蹈游戏、VR/AR应用以及其他需要高精度人体运动追踪的领域提供一个更鲁棒、更实时、更适应动态环境的先进解决方案。

---
### [[Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric]](http://arxiv.org/abs/2211.11010v2)
**📅 发布日期**: 2022-11-20

*   **👥 作者**: Chuanming Tang, Xiao Wang, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang, Yaowei Wang, Yonghong Tian
*   **🎯 研究目的**: 将彩色相机和事件相机（DVS）结合进行鲁棒目标跟踪是近年来新兴的研究课题。然而，现有的彩色-事件跟踪框架通常包含多个分散的模块（如特征提取、融合、匹配、交互式学习等），这导致效率低下和计算复杂度高。本文的研究目的在于解决这些问题，提出一个统一的单阶段网络，以同时实现上述功能，从而提高跟踪的效率和鲁棒性。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一个名为**CEUTrack（Color-Event Unified Tracking）**的单阶段骨干网络，该网络能够同时实现特征提取、模态融合、匹配以及交互式学习等功能，显著解决了现有框架模块分散、效率低下的问题。其创新点包括：
    *   **统一网络架构**: CEUTrack将彩色数据和事件数据进行统一处理。具体而言，它首先将事件点转换为体素表示，并分别为两种模态裁剪模板和搜索区域。
    *   **Transformer骨干**: 这些区域随后被投影为token，并并行输入到统一的Transformer骨干网络中进行处理，从而实现了高效且紧密的跨模态信息融合。
    *   **更广泛的贡献（根据标题推断）**: 论文不仅提出了统一的网络，还可能引入了新的数据集和评估指标（尽管摘要主要聚焦于网络），这对于推动彩色-事件跟踪领域的发展具有重要意义。通过这种统一的方法，CEUTrack有望提高彩色-事件目标跟踪的效率、鲁棒性和整体性能。

---
### [[HARDVS: Revisiting Human Activity Recognition with Dynamic Vision Sensors]](http://arxiv.org/abs/2211.09648v1)
**📅 发布日期**: 2022-11-17

*   **👥 作者**: Xiao Wang, Zongzhen Wu, Bo Jiang, Zhimin Bao, Lin Zhu, Guoqi Li, Yaowei Wang, Yonghong Tian
*   **🎯 研究目的**: 当前主流的人体活动识别（HAR）算法主要基于RGB摄像头开发，但这些摄像头存在光照敏感、对快速运动处理不佳、隐私保护不足以及能耗高等问题。与此同时，受生物学启发的事件相机（动态视觉传感器）因其高动态范围、密集时间但稀疏空间分辨率、低延迟和低功耗等独特优势而备受关注。然而，作为一种新兴传感器，目前缺乏用于HAR的真实大规模事件相机数据集。鉴于事件相机在HAR领域的巨大应用潜力，本研究旨在解决这一数据鸿沟，推动基于事件相机的人体活动识别技术发展。
*   **⭐ 主要发现**: 为了弥补事件相机HAR领域缺乏大规模数据集的空白，本研究提出了一个名为HARDVS的大规模基准数据集。HARDVS数据集包含300个人体活动类别，并拥有超过10万条事件序列，是目前针对动态视觉传感器HAR领域规模最大、最真实的基准数据集之一。研究团队在该数据集上评估并报告了多种流行HAR算法的性能，为未来的研究提供了广泛的基线（baseline），极大地促进了基于事件相机的人体活动识别算法的开发和比较。这一数据集的发布有望加速事件相机在智能监控、人机交互等对实时性、隐私性和能耗有高要求的场景中的应用。

---
### [[Frequency Cam: Imaging Periodic Signals in Real-Time]](http://arxiv.org/abs/2211.00198v1)
**📅 发布日期**: 2022-11-01

*   **👥 作者**: Bernd Pfrommer
*   **🎯 研究目的**: 事件相机因其高时间分辨率和宽动态范围，在分析图像中的时间周期性信号方面具有独特优势。基于此，本研究旨在开发一种高效且完全异步的事件相机算法，用于实时检测图像像素的闪烁基频，解决现有方法在处理高频噪声时的鲁棒性问题。
*   **⭐ 主要发现**:
    *   **创新算法:** 提出了一种高效且完全异步的事件相机算法，该算法采用二阶数字无限脉冲响应（IIR）滤波器进行近似的逐像素亮度重建。
    *   **鲁棒性提升:** 相比于基线方法，该算法对高频噪声表现出更高的鲁棒性。
    *   **精度优化策略:**
        *   研究发现，使用信号的下降沿进行周期估计比使用上升沿能获得更准确的结果。
        *   对于某些特定信号，通过插值零电平交叉点可以进一步提高周期估计的精度。
    *   **潜在影响:** 这些发现和算法的提出，显著提升了事件相机在实时周期信号成像方面的能力和准确性。

---
### [[Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking Neural Networks with Learnable Neuronal Dynamics]](http://arxiv.org/abs/2209.11741v2)
**📅 发布日期**: 2022-09-21

*   **👥 作者**: Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**: 事件相机因其异步捕获丰富时间信息的能力，在高速运动估计方面展现出巨大潜力。脉冲神经网络（SNNs）凭借其受神经启发、事件驱动的处理方式，能够高效处理这类异步数据，而像漏积分发放（LIF）这样的神经元模型能有效追踪输入中关键的时序信息。SNNs通过在神经元内存中维持动态状态，保留重要信息并随时间遗忘冗余数据。因此，研究者提出SNNs在序列回归任务（如光流估计）上应优于同等规模的模拟神经网络（ANNs）。然而，深度SNNs由于“脉冲消失”等问题而难以训练。本文旨在利用SNNs处理事件数据的固有优势，并通过引入可学习的神经元动态来克服其训练难题，从而实现高性能的基于事件的光流估计。
*   **⭐ 主要发现**: 本文提出了Adaptive-SpikeNet，这是一种创新的脉冲神经网络模型，专门用于基于事件相机数据的光流估计。其核心创新在于引入了“可学习神经元动态”（Learnable Neuronal Dynamics），有效解决了深度SNN训练中常见的“脉冲消失”难题，使得网络能够更好地捕捉和利用事件数据中丰富的时序信息。实验结果表明，Adaptive-SpikeNet在处理异步事件流时，在光流估计任务上展现出优越的性能，不仅能够高效利用事件相机的特性，而且在性能上超越了同等规模的模拟神经网络（ANNs），为高速、低功耗的运动估计提供了新的解决方案。

---
### [EDeNN: Event Decay Neural Networks for low latency vision](http://arxiv.org/abs/2209.04362v2)
<!-- 论文发布日期，格式：2022-09-09 -->
**📅 发布日期**: 2022-09-09

*   **👥 作者**: Celyn Walters, Simon Hadfield
*   **🎯 研究目的**: 尽管神经网络在计算机视觉任务中取得了巨大成功，但其数字“神经元”与生物神经元仍有显著差异。当前的学习方法主要针对数字设备和图像帧等数字数据表示设计，而生物视觉系统通常比最先进的数字计算机视觉算法更强大、更高效。事件相机作为一种新兴的传感器技术，通过异步激发像素来模仿生物视觉，摒弃了图像帧的概念。然而，为了利用现代学习技术，许多基于事件的算法被迫将事件累积回图像帧，这在一定程度上浪费了事件相机的优势。本文旨在开发一种新的神经网络类型——EDeNN（事件衰减神经网络），以遵循相反的范式，直接利用事件相机的优势，实现低延迟视觉。
*   **⭐ 主要发现**: 该论文提出了EDeNN（事件衰减神经网络），这是一种新型的神经网络架构，旨在直接处理事件相机产生的异步事件数据，而无需将其转换回传统的图像帧。通过采用与现有方法相反的范式，EDeNN旨在充分发挥事件相机的低延迟和高效率优势。这种方法模仿了生物视觉系统处理信息的方式，通过事件衰减机制直接对事件流进行操作，有望在计算机视觉任务中实现更快的响应速度和更高的效率，尤其适用于对延迟敏感的应用，如自动驾驶、机器人导航等。

---
### [[Visual Odometry with Neuromorphic Resonator Networks]](http://arxiv.org/abs/2209.02000v3)
**📅 发布日期**: 2022-09-05

*   **👥 作者**: Alpha Renner, Lazar Supic, Andreea Danielescu, Giacomo Indiveri, E. Paxon Frady, Friedrich T. Sommer, Yulia Sandamirskaya
*   **🎯 研究目的**: 移动机器人通过视觉传感器估计自身运动的视觉里程计（VO）方法，相较于惯性传感器或轮式编码器等基于积分测量的里程计，具有不累积误差（无漂移）的优势。然而，传统的基于图像的VO计算量巨大，限制了其在对延迟、内存和能耗有严格要求的场景中的应用。尽管神经形态硬件为许多视觉和AI问题提供了低功耗解决方案，但为其设计算法通常复杂且需要从头开始。本研究旨在解决VO的计算瓶颈以及神经形态硬件算法设计的复杂性，探索一种在神经形态硬件上实现高效VO的新范式。
*   **⭐ 主要发现**: 为克服传统VO的计算密集性以及神经形态硬件算法设计的复杂性，论文提出了一种创新方法：利用向量符号架构（Vector Symbolic Architecture, VSA）作为高层抽象层来设计与神经形态硬件兼容的算法。这一方法极大地简化了神经形态算法的开发过程，避免了从零开始构建的复杂性。具体而言，研究基于其在场景分析方面的VSA模型，将该抽象层应用于视觉里程计，旨在实现低功耗、低延迟的VO解决方案。这一工作为在资源受限环境下部署高性能视觉里程计提供了新的设计范式和潜在途径。

---
### [[Training Robust Spiking Neural Networks on Neuromorphic Data with Spatiotemporal Fragments]](http://arxiv.org/abs/2207.11659v3)
**📅 发布日期**: 2022-07-24

*   **👥 作者**: Haibo Shen, Yihao Luo, Xiang Cao, Liangqi Zhang, Juyu Xiao, Tianjiang Wang
*   **🎯 研究目的**: 神经形态视觉传感器（事件相机）为脉冲神经网络（SNNs）提供了独特的时空特性数据。然而，由于这些数据的非传统时空性质，传统的几何变换等数据增强方法可能不再适用，需要开发新的增强技术来有效处理。本研究的核心目的在于提出一种新颖的数据增强方法，以应对神经形态数据的挑战，并最终训练出更具鲁棒性的脉冲神经网络。
*   **⭐ 主要发现**: 论文提出了一种名为“事件时空片段（Event SpatioTemporal Fragments, ESTF）”的新颖数据增强方法。ESTF通过对时空事件流中的片段进行漂移或反转操作，来模拟亮度变化等干扰，同时巧妙地保持了神经形态数据的时空连续性。这种方法旨在提高SNNs在处理事件相机数据时的鲁棒性。在主流神经形态数据集上进行的广泛实验验证了ESTF的有效性。结果表明，ESTF相比于单纯的几何变换方法，能够显著提升模型的性能和鲁棒性。这一创新方法成功地训练出了更具鲁棒性的脉冲神经网络，为处理事件相机产生的非传统视觉信号提供了新的有效途径，并有望推动神经形态计算领域的发展。

---
### [[融合帧和事件视觉实现边缘应用的高速光流]](http://arxiv.org/abs/2207.10720v1)
**📅 发布日期**: 2022-07-21

*   **👥 作者**: Ashwin Sanjay Lele, Arijit Raychowdhury
*   **🎯 研究目的**: 现有基于帧的相机光流计算虽然精度高，但速度受限于算法模型大小或相机帧率，不适用于高速场景。事件相机虽然能提供连续异步事件流，克服了帧率限制，但其算法要么为了速度牺牲精度，要么为了精度而引入类似帧的处理方式，导致速度受限。本文旨在融合帧相机和事件相机各自在精度和速度上的互补优势，以实现高速光流计算，同时保持较低的错误率，特别适用于边缘应用。
*   **⭐ 主要发现**: 论文提出了一种仿生网络（bio-mimetic network），有效融合了帧视觉和事件视觉数据，从而结合了帧相机的高精度和事件相机的高速度优势。在MVSEC数据集上的验证表明，该网络在实现4倍速度提升的同时，错误率仅增加19%（即错误降级19%），证明了其在高速下仍能保持较低错误率的能力。此外，该系统还在高速无人机飞行场景中得到了验证，展示了其在实际边缘应用中的潜力。

---
### [[How Many Events do You Need? Event-based Visual Place Recognition Using Sparse But Varying Pixels]](http://arxiv.org/abs/2206.13673v3)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2022-06-28

*   **👥 作者**: Tobias Fischer, Michael Milford
*   **🎯 研究目的**: 事件相机因其高动态范围、低延迟、几乎无运动模糊和高能效等理想特性而持续受到关注。这些特性使其在机器人定位的视觉地点识别（即将查询观测与数据库中对应的参考地点进行匹配）等潜在应用中具有显著优势。本文旨在探索从少量像素（几十到几百个）产生的事件流的独特性，并研究在地点识别任务中，到底需要多少事件数据才能有效完成。核心目标是验证是否可以通过利用参考数据集中显示出较大变化的稀疏像素点的事件信息，实现高效且鲁棒的地点识别。
*   **⭐ 主要发现**: 本文证明，当利用在参考数据集中显示出较大变化的像素时，仅在这些像素位置累积的事件数量的绝对差值，就足以完成视觉地点识别任务。研究表明，即使是稀疏（在图像坐标上）的事件数据，如果像素选择得当（即选择那些具有高变异性的像素），也能提供足够的判别力。这一发现挑战了传统观念，即地点识别需要密集的视觉信息，为开发更高效、低带宽、低计算量的事件相机视觉地点识别系统提供了新的可能性和方法。
### [[E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations]](http://arxiv.org/abs/2206.07578v2)
**📅 发布日期**: 2022-06-15

*   **👥 作者**: Jongwan Kim, DongJin Lee, Byunggook Na, Seongsik Park, Jeonghee Jo, Sungroh Yoon
*   **🎯 研究目的**: 事件相机以其对场景亮度变化的异步、独立像素响应特性，展现出高动态范围（HDR）、高时间分辨率和低功耗等显著优势。然而，为了将事件数据应用于计算机视觉任务，需要将其转换为合适的表示形式。当前面临的主要挑战是，事件数据通常伴随噪声，并在事件稀疏区域表现不佳。尽管近年来众多研究致力于从事件数据重建视频，但由于事件数据的非规则性和不连续性，现有方法往往难以生成高质量的视频，尤其缺乏充分的时序信息。本文旨在克服这些困难，提出一种新颖的方法，以实现从异步事件数据中快速、连续地重建高质量视频。
*   **⭐ 主要发现**: 为了解决从事件数据重建高质量视频所面临的非规则性、不连续性以及时序信息不足的难题，本文引入了一种名为 E2V-SDE 的新型模型。E2V-SDE 的核心创新在于其在潜在空间中利用神经随机微分方程（Neural Stochastic Differential Equations, SDE）来建模数据的动态变化。这种方法能够有效地处理事件数据的内在不确定性和不规则性，从而弥补传统方法在时序信息捕获上的不足。通过在潜在空间中引入由随机微分方程控制的动力学，E2V-SDE 能够从离散、异步的事件流中推断出连续的视频帧，从而实现高质量、连续的视频重建。这一创新为从事件相机数据生成适用于计算机视觉任务的表示提供了一条新途径，并有望显著提升事件相机在复杂场景下的应用性能。

---
### [EventMix: An Efficient Augmentation Strategy for Event-Based Data](http://arxiv.org/abs/2205.12054v1)
**📅 发布日期**: 2022-05-24

*   **👥 作者**: Guobin Shen, Dongcheng Zhao, Yi Zeng
*   **🎯 研究目的**: 事件相机生成的高动态范围、低能耗事件流数据，对于构建高效的类脑事件驱动机制至关重要。然而，与传统基于帧的数据相比，事件流数据集的规模较小且获取难度大，这严重制约了神经形态计算领域的发展。为了解决这一数据稀缺性问题，并提升现有数据的质量与多样性，本研究旨在提出一种高效的数据增强策略，以促进神经形态计算的进步。
*   **⭐ 主要发现**: 本论文的核心贡献是提出了一种名为 EventMix 的高效事件流数据增强策略。EventMix 的创新之处在于，它利用高斯混合模型（Gaussian Mixture Model, GMM）精心设计了不同事件流的混合过程。通过生成随机的3D掩码，EventMix 能够在时空维度上实现事件流的任意形状混合，从而有效扩充数据集的规模和多样性。这种方法有望显著改善事件相机数据的质量和数量，为神经形态计算和类脑机制的设计提供更丰富、更具挑战性的训练数据，从而加速该领域的研究与应用。

---
### [[TimeReplayer: Unlocking the Potential of Event Cameras for Video Interpolation]](http://arxiv.org/abs/2203.13859v1)
**📅 发布日期**: 2022-03-25

*   **👥 作者**: Weihua He, Kaichao You, Zhendong Qiao, Xu Jia, Ziyang Zhang, Wenhui Wang, Huchuan Lu, Yaoyuan Wang, Jianxing Liao
*   **🎯 研究目的**: 录制高帧率（FPS）视频通常需要昂贵的高速摄像机。作为替代方案，从低帧率视频中插帧以生成高帧率视频受到了广泛关注。然而，当仅有低帧率视频可用时，传统的插帧方法需要对运动进行假设（如线性或二次），这在面对复杂运动时会失效。事件相机作为一种新型传感器，其像素能以微秒（μs）级的时间分辨率产生亮度变化事件，这使其成为在存在任意复杂运动的情况下实现视频插帧的颠覆性设备。鉴于事件相机是一种新兴传感器，由于缺乏相应的处理算法，其潜力尚未完全发挥。本研究旨在开发新的算法，以充分利用事件相机在视频插帧领域的独特优势，尤其是在处理复杂、快速运动场景中的能力，从而克服传统方法的局限性。
*   **⭐ 主要发现**: 本论文介绍了一种名为 TimeReplayer 的新型方法，旨在充分发挥事件相机在视频插帧方面的潜力。研究发现，事件相机凭借其微秒级的时间分辨率，能够捕捉传统帧式相机难以捕捉的精细运动细节，从而有效解决传统插帧方法在处理复杂运动时因依赖简单运动假设而失效的问题。通过开发专门的处理算法，TimeReplayer 成功地将事件数据转化为高质量的中间帧，显著提升了视频插帧的精度和鲁棒性，尤其是在快速和复杂运动场景下。这项工作为事件相机在计算机视觉领域的应用开辟了新的途径，证明了其在替代昂贵高速摄像机、实现高帧率视频生成方面的巨大潜力，对视频处理和传感器融合领域具有重要影响。

---
### [[ESS: Learning Event-based Semantic Segmentation from Still Images]](http://arxiv.org/abs/2203.10016v2)
**📅 发布日期**: 2022-03-18

*   **👥 作者**: Zhaoning Sun, Nico Messikommer, Daniel Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 图像算法在处理高动态范围（HDR）和高速运动场景下的语义信息时，由于严重的图像退化，难以获得准确的语义分割结果。事件相机因其固有的高动态范围和对运动模糊的免疫力，有望解决这些挑战。然而，事件相机的语义分割领域仍处于起步阶段，主要障碍在于缺乏高质量的标注数据集。本研究旨在解决这一核心问题，通过引入ESS（Event-based Semantic Segmentation）框架，实现将语义分割任务从现有已标注的图像数据集，通过无监督域适应（UDA）方法，直接迁移到未标注的事件数据上，从而为事件相机赋能语义理解能力。
*   **⭐ 主要发现**: 论文提出了ESS（Event-based Semantic Segmentation）这一创新框架，其核心贡献在于有效解决了事件相机语义分割领域长期存在的标注数据稀缺问题。ESS通过采用无监督域适应（UDA）策略，巧妙地将传统图像数据集中丰富的语义标注知识，迁移应用于未标注的事件数据。与现有UDA方法不同，ESS的方法特别注重对事件数据固有的循环性和运动不变性特征进行对齐，从而更有效地桥接了图像域和事件域之间的鸿沟。这一突破性方法为事件相机在极端高动态范围和高速运动等挑战性条件下实现准确的语义分割提供了可行途径，有望显著提升自动驾驶、机器人导航等应用在复杂动态环境中的感知鲁棒性和准确性。
### [[Real-Time Event-Based Tracking and Detection for Maritime Environments]](http://arxiv.org/abs/2202.04231v1)
**📅 发布日期**: 2022-02-09

*   **👥 作者**: Stephanie Aelmore, Richard C. Ordonez, Shibin Parameswaran, Justin Mauger
*   **🎯 研究目的**: 该研究旨在解决在海洋环境中利用事件相机进行实时目标追踪和检测的挑战。事件相机因其低延迟和数据冗余低等优点，非常适合追踪快速移动物体。然而，现有基于事件的聚类和特征追踪方法在陆地环境表现良好，却难以适应独特的海洋环境。海洋环境的主要挑战在于海浪会产生大量事件，这些事件往往占据了绝大部分计算资源，并干扰对船只等目标的识别。因此，本研究的核心目标是开发一种能够有效识别船只特征、输出置信度分数（表示该特征由船只产生的可能性），并能触发后续警报或分类系统的实时船只检测和追踪系统。
*   **⭐ 主要发现**: 尽管摘要内容不完整，但根据其描述，该论文的核心贡献在于提出并开发了一种针对海洋环境的实时事件相机船只检测与追踪方法。其主要发现和创新点在于：
    *   **针对海洋环境的独特适应性：** 论文旨在解决现有事件相机方法在海洋环境中遇到的挑战，特别是海浪产生大量事件导致计算负担重、目标识别困难的问题。这表明其方法将专注于有效区分船只事件与背景（海浪）事件。
    *   **引入基于置信度的特征识别：** 该系统被设计为能够识别船只特征，并输出一个置信度分数，以量化该特征由船只产生的可能性。这一机制对于后续自动触发警报或激活更复杂的分类系统至关重要。
    *   **实时应用潜力：** 充分利用事件相机在捕获快速移动物体、降低延迟和数据冗余方面的固有优势，旨在实现对海上船只的实时检测和追踪，从而提升海洋态势感知和安全预警能力。

---
### [3D-FlowNet: Event-based optical flow estimation with 3D representation](http://arxiv.org/abs/2201.12265v1)
**📅 发布日期**: 2022-01-28

*   **👥 作者**: Haixin Sun, Minh-Quan Dao, Vincent Fremont
*   **🎯 研究目的**: 事件相机在低光照条件下的高速运动检测等重要任务中，能够克服传统帧式相机的局限性，特别适用于自动驾驶等场景。它们的高时间分辨率和高动态范围使其在快速运动和极端光照下表现出色。然而，传统的计算机视觉方法（如深度神经网络）由于事件数据的异步性和离散性，难以有效处理。此外，传统的2D事件数据编码方法牺牲了时间分辨率。本研究旨在解决这些问题，以更好地利用事件相机数据进行光流估计。
*   **⭐ 主要发现**: 论文首先改进了事件数据的2D编码表示，将其扩展为三维形式，以更好地保留事件的时间分布信息。其次，提出了一种新颖的网络架构——3D-FlowNet，旨在利用这种3D表示进行事件驱动的光流估计。这种方法旨在克服传统方法在处理异步事件数据方面的局限性，并充分利用事件相机的高时间分辨率。

---
### [Formulating Event-based Image Reconstruction as a Linear Inverse Problem with Deep Regularization using Optical Flow](http://arxiv.org/abs/2112.06242v3)
**📅 发布日期**: 2021-12-12

*   **👥 作者**: Zelin Zhang, Anthony Yezzi, Guillermo Gallego
*   **🎯 研究目的**: 事件相机是一种新型的仿生传感器，能够异步测量每个像素的亮度差异，其输出的事件流具有高动态范围（HDR）和高速度特性。从事件流中恢复亮度信息（即图像重建）对于机器人视觉应用和生成慢动作HDR视频具有重要价值。然而，当前最先进的方法通常依赖于训练事件到图像的循环神经网络（RNN），这类方法缺乏可解释性且难以调优。本研究旨在提出一种新的、更具解释性和易于调优的事件图像重建方法，特别是通过将运动估计与亮度估计相结合，从而避免使用专门的图像重建RNN。
*   **⭐ 主要发现**: 本文首次展示了如何将运动（光流）和亮度估计的组合问题，转化为事件图像重建的线性逆问题。这一创新性的公式使得图像重建过程无需训练一个专门的图像重建RNN即可解决，这与现有依赖复杂RNN的方法形成了鲜明对比。通过将问题重新定义为线性逆问题，该方法可能利用更传统的优化技术，并结合深度正则化，从而在保持事件相机固有优势的同时，提高解决方案的可解释性和可调性。
### [Research on Event Accumulator Settings for Event-Based SLAM](http://arxiv.org/abs/2112.00427v4)
**📅 发布日期**: 2021-12-01

*   **👥 作者**: Kun Xiao, Guohui Wang, Yi Chen, Yongfeng Xie, Hong Li, Sen Li
*   **🎯 研究目的**: 本文旨在深入研究事件相机在基于事件的同步定位与建图（SLAM）中的事件累积器设置。事件相机作为一种区别于传统传感器的新型相机，其每个像素在亮度变化（增量或减量超过特定阈值）时异步触发事件，并输出相应的事件。相较于传统相机，事件相机具有高动态范围和无运动模糊的显著优势。在基于事件的SLAM中，将事件累积成帧并利用传统SLAM算法是一种直接且高效的方法。然而，不同的事件累积器设置，例如事件流的切片方法、对无运动情况的处理方式、是否使用极性信息、衰减函数以及事件贡献度等，都可能导致截然不同的累积结果。因此，本研究的核心目标是探讨这些不同事件累积器设置对累积结果的影响，旨在为基于事件的SLAM提供更有效、更优化的事件累积策略。
*   **⭐ 主要发现**: 提供的摘要部分主要介绍了事件相机的基本特性、其在基于事件的SLAM中的应用背景以及研究动机，即不同事件累积器设置对累积结果的显著影响。摘要明确指出，本文旨在对如何进行事件累积展开研究。然而，**提供的摘要并未详细阐述具体的实验结果、不同设置的性能比较、或最终得出的最佳实践和理论突破。** 因此，根据现有信息，无法列出论文的具体“主要发现”。论文的核心贡献应体现在其对各种事件累积器设置进行深入探究后所揭示的规律、性能影响以及可能提出的优化建议，以指导未来基于事件的SLAM算法开发。

---
### [[Lifelong Learning from Event-based Data]](http://arxiv.org/abs/2111.08458v1)
**📅 发布日期**: 2021-11-11

*   **👥 作者**: Vadym Gryshchuk, Cornelius Weber, Chu Kiong Loo, Stefan Wermter
*   **🎯 研究目的**: 终身学习是人工智能体在动态环境中长期追求的目标，要求智能体能够增量地积累知识，同时不遗忘先前学到的表示。然而，在增量学习中，模型常常面临灾难性遗忘（catastrophic forgetting）的挑战。本文旨在解决这一问题，特别关注从事件相机（event cameras）生成的数据中进行学习，并探索和比较旨在减轻遗忘的技术，以实现知识的持续积累。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种创新的模型架构，该模型结合了特征提取和持续学习模块，旨在高效处理事件相机数据。更重要的是，论文引入了一种新颖的、基于习惯化（habituation-based）的方法来有效减轻灾难性遗忘。实验结果有力地证明，通过结合这些不同的技术，所提出的模型能够成功地避免灾难性遗忘，从而在从特征提取模块提供的特征中进行增量学习时，实现知识的持续积累，为终身学习领域提供了新的解决方案。

---
### [[A New Look at Spike-Timing-Dependent Plasticity Networks for Spatio-Temporal Feature Learning]](http://arxiv.org/abs/2111.00791v4)
**📅 发布日期**: 2021-11-01

*   **👥 作者**: Ali Safa, Ilja Ocket, André Bourdoux, Hichem Sahli, Francky Catthoor, Georges Gielen
*   **🎯 研究目的**: 现有的脉冲神经网络（SNNs）中无监督的脉冲时间依赖可塑性（STDP）学习，其参数调整大多依赖于经验性搜索，耗时且效率不高。本研究旨在为SNNs中的无监督STDP学习提供新的理论基础，并为SNN和STDP的参数调优提供新颖的理论依据，以显著缩短设计时间。最终目标是利用所提出的通用框架，从事件相机数据中学习时空特征。
*   **⭐ 主要发现**:
    *   本研究为脉冲神经网络（SNNs）中的无监督脉冲时间依赖可塑性（STDP）学习奠定了新的理论基础。
    *   与以往多数工作依赖经验性参数搜索不同，论文提供了SNN和STDP参数调优的新颖理论依据，显著缩短了设计时间。
    *   基于这一通用框架，论文提出了一类全局的、基于动作的、卷积型的SNN-STDP架构，专门用于从事件相机数据中学习时空特征。
    *   研究方法在N-MNIST、CIFAR10-DVS和IBM DVS128 Gesture等真实事件相机数据集上进行了评估。
    *   实验结果表明，与传统的SOTA事件基特征描述符相比，所提出的方法在分类准确率上取得了显著提升。

---
### [[Moving Object Detection for Event-based vision using Graph Spectral Clustering]](http://arxiv.org/abs/2109.14979v3)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2021-09-30

* **👥 作者**: Anindya Mondal, Shashant R, Jhony H. Giraldo, Thierry Bouwmans, Ananda S. Chowdhury
* **🎯 研究目的**: 本研究聚焦于利用神经形态视觉传感器（NVS）数据进行运动物体检测。NVS是一种仿生传感器，通过捕获异步事件流来模拟人眼工作，相较于传统帧式相机，具有高动态范围、低延迟、低功耗和减少运动模糊等显著优势。然而，NVS数据也面临噪声高、分辨率低以及仅捕获亮度相对变化（缺乏传统视觉信息）等挑战。因此，本研究旨在探索并提出一种有效的方法，以克服这些挑战，实现基于事件相机的鲁棒运动物体检测，从而在自动驾驶、视频监控、安全执法等关键应用中发挥作用。
* **⭐ 主要发现**: 论文提出了一种基于图谱聚类（Graph Spectral Clustering）的创新方法，专门用于事件视觉中的运动物体检测。该方法旨在利用图谱聚类在处理复杂数据结构方面的优势，有效地从高噪声、低分辨率且仅包含亮度变化信息的事件流中识别并分离出运动物体事件。通过将事件数据建模为图结构并应用谱聚类技术，该研究有望克服事件相机数据的固有挑战，实现对运动目标的准确检测，为事件视觉在实际应用中的推广提供了新的思路和技术支持，尤其是在需要低延迟和高动态范围的场景下。
### [StereoSpike: Depth Learning with a Spiking Neural Network](http://arxiv.org/abs/2109.13751v3)
**📅 发布日期**: 2021-09-28

*   **👥 作者**: Ulysse Rançon, Javier Cuadrado-Anibarro, Benoit R. Cottereau, Timothée Masquelier
*   **🎯 研究目的**: 深度估计是计算机视觉领域一项重要的任务，尤其在自动驾驶车辆的导航和机器人操作（如物体抓取）中具有关键作用。本研究旨在通过一种端到端的神经形态方法来解决这一问题，即结合事件相机和脉冲神经网络（SNN）进行深度学习，以实现高效且鲁棒的深度预测。
*   **⭐ 主要发现**:
    *   **核心贡献与架构创新**: 论文提出了一种名为“StereoSpike”的端到端神经形态深度学习方法。该方法创新性地结合了两个事件相机和一个基于脉冲神经网络（SNN）的编码器-解码器架构（类似于U-Net的修改版）。
    *   **训练与数据集**: StereoSpike在Multi Vehicle Stereo Event Camera Dataset (MVSEC)数据集上进行监督学习训练，该数据集提供了深度真值，并利用代理梯度下降法（surrogate gradient descent）进行优化。
    *   **关键技术突破**: 论文提出了一种新颖的读出范式（readout paradigm），能够从解码器产生的脉冲中获取每个像素的密集模拟深度预测，从而将离散的脉冲信号转化为连续的深度信息。
    *   **实验结果与泛化能力**: 实验证明，StereoSpike架构具有出色的泛化能力，其性能甚至优于（摘要中未完全展示，但暗示超越）其他方法，为基于事件相机和SNN的深度学习在实际应用中开辟了新途径。

---
### [[SiamEvent: Event-based Object Tracking via Edge-aware Similarity Learning with Siamese Networks]](http://arxiv.org/abs/2109.13456v1)
**📅 发布日期**: 2021-09-28

*   **👥 作者**: Yujeong Chae, Lin Wang, Kuk-Jin Yoon
*   **🎯 研究目的**:
    事件相机是一种新型传感器，能够感知像素级的亮度变化并输出异步事件流。相较于传统相机，它们在高动态范围（HDR）和无运动模糊方面展现出显著优势。现有研究表明，仅凭事件数据即可通过运动补偿或预测实现目标跟踪。然而，现有方法普遍存在局限性，例如假设目标始终处于运动状态且是独立个体，并且在固定场景下无法有效跟踪停止或非独立运动的物体。为解决这些挑战，本文提出了一种新颖的、基于事件的目标跟踪框架——SiamEvent，该框架利用Siamese网络并通过边缘感知相似度学习来实现目标跟踪。
*   **⭐ 主要发现**:
    本文的核心贡献是提出了SiamEvent框架，一个新颖的事件相机目标跟踪解决方案。该框架创新性地结合了Siamese网络与边缘感知相似度学习。特别地，为了找到与目标具有最相似边缘结构的部分，SiamEvent提出了一种关联嵌入式事件数据的方法。该方法旨在通过比对嵌入式事件数据，精确识别出与目标边缘结构最为相似的区域，从而有效解决了现有方法无法跟踪停止或非独立运动物体的问题，显著提升了事件相机在复杂场景下目标跟踪的鲁棒性和准确性。

---
### [[VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows]](http://arxiv.org/abs/2108.05015v4)
**📅 发布日期**: 2021-08-11

*   **👥 作者**: Xiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li, Yaowei Wang, Yonghong Tian, Feng Wu
*   **🎯 研究目的**: 传统可见光相机逐帧记录强度图像，擅长捕捉纹理细节和慢速运动；而仿生事件相机则产生异步、稀疏的事件流，具有极低延迟、无运动模糊和高动态范围的优势，在快速运动和低光照条件下表现出色。鉴于这两种传感器在感知能力上的互补性，将它们结合有望实现更可靠的目标跟踪。然而，当前该领域面临一个关键挑战：缺乏一个真实且大规模的数据集来支持可见光与事件流协同的目标跟踪研究。因此，本研究旨在解决这一数据鸿沟，通过构建一个大规模的可见光-事件基准数据集，以促进该领域的技术发展和应用。
*   **⭐ 主要发现**: 本文的核心贡献是提出了一个名为VisEvent的大规模可见光-事件基准数据集，旨在弥补当前研究中缺乏真实且大规模数据集的空白。VisEvent数据集包含820对视频，这些视频是在低光照、高速运动和背景杂乱等复杂场景下捕获的。这一创新性数据集为研究人员提供了丰富多样的实验数据，有望推动可见光与事件流融合的目标跟踪技术在更具挑战性的实际应用场景中取得突破。

---
### [[EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing And Following]](http://arxiv.org/abs/2106.15045v1)
<!-- 2021-06-29 -->
**📅 发布日期**: 2021-06-29

*   **👥 作者**: Nitin J. Sanket, Chahat Deep Singh, Chethan M. Parameshwara, Cornelia Fermüller, Guido C. H. E. de Croon, Yiannis Aloimonos
*   **🎯 研究目的**: 随着无人机（UAVs）的日益普及，其对公共安全和隐私构成了潜在威胁。大多数商用或定制无人机都是多旋翼飞行器，包含多个高速旋转的螺旋桨。传统相机在捕捉这些高速运动部件时会产生严重的运动模糊，难以直接“看到”它们。本研究旨在利用事件相机（Event Camera）的独特优势——高时间分辨率、低延迟和高动态范围——来克服传统相机的局限性。核心目标是开发一种能够从事件相机数据中有效检测无人机螺旋桨的方法，为实现无人机的空中着陆和跟踪等高级应用奠定基础。
*   **⭐ 主要发现**: 本论文提出了一种新颖的方法，利用事件相机来解决高速旋转螺旋桨的检测难题。研究人员首次对螺旋桨的几何形状进行了精确建模，并基于此模型生成了大量的模拟事件数据。利用这些模拟数据，他们成功训练了一个名为EVPropNet的深度神经网络，使其能够从事件相机数据中准确识别和检测无人机的螺旋桨。这项技术为未来在空中精确识别、跟踪和潜在拦截无人机提供了关键技术支持，对于提升安全监控和反无人机能力具有重要意义。

---
### [[Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks]](http://arxiv.org/abs/2106.01862v2)
**📅 发布日期**: 2021-06-03

*   **👥 作者**: Jesse Hagenaars, Federico Paredes-Vallés, Guido de Croon
*   **🎯 研究目的**: 神经形态计算领域承诺实现极低功耗和低延迟的感知与处理能力。然而，将传统人工神经网络（ANNs）的学习算法迁移到脉冲神经网络（SNNs）面临挑战，这阻碍了SNNs在大型、复杂的回归任务中的应用。此外，实现一个真正异步且完全神经形态的管线（即事件相机直接将脉冲信号逐个传递给SNN，所有时间信息的整合都必须在网络内部完成），以最大化地发挥神经形态计算的优势，也是一个亟待解决的问题。本文旨在解决这两个核心问题，并专注于利用SNNs实现事件相机数据的光流估计这一复杂感知任务。
*   **⭐ 主要发现**: 本文的核心贡献在于提出了一种创新的自监督学习框架，利用脉冲神经网络（SNNs）实现对事件相机数据的光流估计。这一方法成功解决了将传统学习算法应用于SNNs进行大规模、复杂回归任务的挑战，并实现了真正异步、全神经形态的感知管线。通过在SNN内部直接处理事件相机产生的脉冲数据并完成时间信息整合，该研究最大化地发挥了神经形态计算在低功耗和低延迟方面的固有优势，为未来基于事件的感知系统提供了新的范式。

---
### [[生物启发式视觉注意力：基于脉冲神经网络应用于模式分类的硅视网膜]](http://arxiv.org/abs/2105.14753v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2021-05-31

*   **👥 作者**: Amélie Gruel, Jean Martinet
*   **🎯 研究目的**: 视觉注意力作为一种行为和认知过程，通过选择性地聚焦于感官线索的特定方面，同时忽略其他可感知信息，在生物系统中发挥着关键作用。这种生物机制，尤其是在显著性检测方面，长期以来被用于多媒体索引，以驱动对图像或视频相关部分的分析，从而进行进一步处理。然而，随着硅视网膜（或事件相机——测量像素亮度变化并输出相应异步事件的传感器）的兴起，如何将注意力机制和显著性检测应用于这种非常规的传感器输出成为了一个新问题。硅视网膜旨在重现生物视网膜的行为，它们产生时间上的点状事件。本研究的核心目的在于探索并开发一种生物启发式的视觉注意力模型，该模型基于脉冲神经网络（SNN），专门用于处理硅视网膜的独特事件数据，并将其应用于模式分类任务，以解决事件相机数据处理中注意力机制的适应性问题，提高信息处理的效率和准确性。
*   **⭐ 主要发现**: 本研究提出了一种基于脉冲神经网络（SNN）的生物启发式视觉注意力模型，以适应硅视网膜（事件相机）的独特异步事件输出。该模型旨在模拟生物视网膜的注意力机制，通过智能地选择和关注数据流中的关键信息，从而有效过滤冗余信息，并为后续的模式分类任务提供优化的输入。这项工作解决了将传统注意力机制应用于新型事件相机数据所面临的挑战，为事件驱动型视觉系统提供了一种高效且生物学上更合理的感知范式。通过这种方法，有望显著提高基于事件的视觉系统在复杂环境下的数据处理效率和模式识别准确性，为未来事件相机在各种应用场景中的部署奠定基础。

---
### [[Superevents: Towards Native Semantic Segmentation for Event-based Cameras]](http://arxiv.org/abs/2105.06091v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2021-05-13

*   **👥 作者**: Weng Fei Low, Ankit Sonthalia, Zhi Gao, André van Schaik, Bharath Ramesh
*   **🎯 研究目的**:
    大多数成功的计算机视觉模型都将低级特征（如Gabor滤波器响应）转换为更丰富的中间或中级复杂表示，以用于后续的视觉任务。然而，对于事件相机，这种中级表示尚未被充分探索。事件相机的数据流在视觉上通常稀疏且空间上不连续，这使得传统的中级表示方法难以直接应用。本研究旨在解决这一问题，提出并探索一种新的、本地一致的中间表示——“超事件”（superevents），以克服事件相机数据固有的稀疏性和不连续性挑战。通过引入超事件，研究目标是显著提升事件相机在语义分割、视觉跟踪和深度估计等多种视觉任务上的性能，使其能够更有效地处理和理解动态场景。
*   **⭐ 主要发现**:
    本论文的核心贡献是首次为事件相机引入了“超事件”（superevents）这一概念，作为一种创新的、本地一致且感知上一致的中间表示。超事件被定义为能够描绘场景中物体部分的感知上一致的局部单元，有效地将事件流中稀疏且不连续的空间信息组织成更有意义的结构。这一创新弥补了传统中级表示在事件相机领域应用的空白。研究表明，通过利用超事件，能够显著提升事件相机在多种关键视觉任务上的性能，包括但不限于语义分割（作为论文标题强调的主要应用）、视觉跟踪和深度估计。尽管摘要被截断，但论文方法受近期深度学习架构启发，暗示了其可能结合了深度学习技术来生成和利用这些超事件，为事件相机的原生语义分割及其他视觉任务提供了新的范式和强大的工具。
### Instantaneous Stereo Depth Estimation of Real-World Stimuli with a Neuromorphic Stereo-Vision Setup
**📅 发布日期**: 2021-04-06

*   **👥 作者**: Nicoletta Risi, Enrico Calabrese, Giacomo Indiveri
*   **🎯 研究目的**: 立体匹配问题，即通过匹配两个不同视角中的对应特征来重建深度信息，在生物视觉中能高效解决，但在传统机器视觉方法中仍是计算瓶颈。近年来，利用事件相机的特性，新提出的脉冲神经网络（SNN）立体视觉架构有望简化这一问题。尽管已存在一些结合事件相机和脉冲神经形态处理器的解决方案，但它们大多停留在数字硬件仿真阶段，或仅在简化刺激上进行测试。本研究旨在利用动态视觉传感器3D人体姿态数据集（DHP19）这一真实世界的复杂刺激，验证一个在混合信号神经形态硬件上实现的、受大脑启发的事件基立体匹配架构，以实现对真实世界场景的瞬时深度估计。

*   **⭐ 主要发现**: 本研究的核心贡献在于首次在真实的混合信号神经形态处理器上，使用复杂的DHP19数据集（而非简化或仿真数据），成功验证了一个受大脑启发的事件基立体匹配架构。这一工作克服了现有神经形态立体视觉方案仅限于数字仿真或简单刺激的局限性，展示了神经形态系统处理真实世界复杂数据的潜力。通过利用事件相机的异步特性和神经形态硬件的并行处理能力，该架构能够实现对真实世界刺激的瞬时立体深度估计，显著提高了深度感知的速度和效率。这一成果为开发更接近生物视觉、低功耗且能实时处理复杂环境的机器视觉系统奠定了基础，对机器人、自动驾驶和虚拟现实等领域具有重要的潜在影响。

---
### [[Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor Fusion and Deep Fused Spiking-Analog Network Architectures]](http://arxiv.org/abs/2103.10592v1)
**📅 发布日期**: 2021-03-19

*   **👥 作者**: Chankyu Lee, Adarsh Kumar Kosta, Kaushik Roy
*   **🎯 研究目的**:
    传统基于帧的相机在高速运动下容易受到运动模糊影响，且在高动态范围场景中难以准确感知。事件相机虽然能通过异步检测像素强度变化来克服这些限制，但其数据稀疏（仅提供运动像素信息），导致难以估计整体密集的像素行为。为了解决这两种传感器在光流估计中各自的局限性，本研究旨在提出一个传感器融合框架Fusion-FlowNet，利用帧相机和事件相机互补的特性，实现能量高效的光流估计。
*   **⭐ 主要发现**:
    本研究提出了Fusion-FlowNet，一个创新的传感器融合框架，用于能量高效的光流估计。该框架通过结合帧相机和事件相机的数据，有效利用了它们各自的优势和互补特性，克服了单一传感器在高速或高动态范围场景下进行光流估计的挑战。论文还提出了一种深度融合的脉冲-模拟（Spiking-Analog）网络架构，这种新颖的网络设计有望进一步提升系统的能效，为机器人、自动驾驶等需要实时、鲁棒和低功耗光流估计的应用提供了有前景的解决方案。

---
### [[Event-based Synthetic Aperture Imaging with a Hybrid Network]](http://arxiv.org/abs/2103.02376v3)
**📅 发布日期**: 2021-03-03

*   **👥 作者**: Xiang Zhang, Wei Liao, Lei Yu, Wen Yang, Gui-Song Xia
*   **🎯 研究目的**: 合成孔径成像（SAI）能够通过模糊离焦前景遮挡物，并从多视角图像中重建聚焦的被遮挡目标，从而实现“透视”效果。然而，基于传统帧式摄像机的SAI在面对非常密集的遮挡物和极端光照条件（如过曝或欠曝）时，会遇到显著的干扰，导致性能下降。为了解决这些问题，本文提出了一种基于事件相机的SAI新系统。事件相机能够产生具有极低延迟和高动态范围的异步事件。因此，该系统能够通过几乎连续的视角测量来消除密集遮挡的干扰，并同时解决过曝/欠曝问题。其核心目标是利用事件相机的数据，结合所提出的混合编码器-解码器网络，有效重建被遮挡的目标。
*   **⭐ 主要发现**: 本文提出了一种新颖的基于事件相机的合成孔径成像（SAI）系统，旨在克服传统帧式相机在密集遮挡和极端光照条件下的局限性。该系统利用事件相机生成异步事件的特性，这些事件具有极低的延迟和高动态范围，从而能够实现近乎连续的视角测量。这一特性使得系统能够有效消除密集前景遮挡物带来的干扰，并同时应对图像过曝或欠曝的问题。为了从事件数据中重建被遮挡的目标，研究人员设计并提出了一种混合编码器-解码器网络。这项工作显著提升了在复杂和挑战性环境下合成孔径成像的鲁棒性和性能，为未来在恶劣条件下进行视觉感知和目标重建提供了新的途径。

---
### [[Learning Monocular Dense Depth from Events]](http://arxiv.org/abs/2010.08350v2)
**📅 发布日期**: 2020-10-16

*   **👥 作者**: Javier Hidalgo-Carrió, Daniel Gehrig, Davide Scaramuzza
*   **🎯 研究目的**:
    事件相机是一种新型传感器，它以异步事件流的形式输出亮度变化，与传统图像传感器相比，具有高时间分辨率、高动态范围、无运动模糊和低带宽等显著优势。近年来，基于学习的方法已被应用于事件数据，并在单目深度预测等任务中取得了显著进展。然而，现有的大多数方法采用标准的馈入式（feed-forward）架构来生成网络预测，未能充分利用事件流中固有的时间一致性。本研究旨在解决这一问题，通过提出一种新的架构来更好地利用事件流的时间特性，从而提升单目深度预测的性能。
*   **⭐ 主要发现**:
    本论文的核心贡献是提出了一种用于从事件数据学习单目密集深度的新型循环（recurrent）架构。与大多数现有方法采用的未能充分利用事件流时间一致性的标准馈入式架构不同，该研究提出的循环架构能够有效捕捉并利用事件数据固有的时间信息。实验结果表明，与传统的馈入式方法相比，本研究提出的循环架构在单目深度预测任务上取得了显著的性能提升。这一发现不仅为事件相机在深度感知领域的应用开辟了新途径，也证明了利用数据时间特性对于提升学习模型性能的重要性。

---
### [[Real-Time Face & Eye Tracking and Blink Detection using Event Cameras]](http://arxiv.org/abs/2010.08278v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2020-10-16

*   **👥 作者**: Cian Ryan, Brian O Sullivan, Amr Elrasad, Joe Lemley, Paul Kielty, Christoph Posch, Etienne Perot
*   **🎯 研究目的**: 本文旨在利用事件相机（一种新兴的神经形态视觉传感器）的独特优势，解决传统帧式相机在驾驶员监控系统（DMS）中可能面临的挑战。事件相机具有低能耗、高时间分辨率、高动态范围和低延迟等显著优点，使其特别适用于需要实时、鲁棒感知的DMS。研究的核心目标是提出一种新颖的方法，能够同步检测和跟踪驾驶员的面部和眼睛，并进行眨眼检测，从而有效感知和理解驾驶员的物理和认知状态，提升车内安全系统的性能。
*   **⭐ 主要发现**: 论文的核心贡献在于提出了一种新颖的方法，能够实时、同步地检测和跟踪驾驶员的面部和眼睛，并有望实现眨眼检测，以满足驾驶员监控系统的严苛要求。为实现这一目标，研究团队设计并引入了一种独特的、完全卷积的循环神经网络（FCRNN）架构。这种架构的提出是利用事件相机异步事件流进行高效视觉信息处理的关键创新点，有望显著提升基于事件相机的DMS在低延迟、高动态范围和复杂光照条件下的性能和可靠性。

---
### [[Learning to Detect Objects with a 1 Megapixel Event Camera]](http://arxiv.org/abs/2009.13436v2)
<!-- 2020-09-28 -->
**📅 发布日期**: 2020-09-28

*   **👥 作者**: Etienne Perot, Pierre de Tournemire, Davide Nitti, Jonathan Masci, Amos Sironi
*   **🎯 研究目的**: 事件相机以其高时间精度、低数据率和高动态范围的特性，特别适用于高运动、挑战性光照条件和需要低延迟的场景。然而，由于该领域的相对新颖性，基于事件的系统在许多视觉任务上的性能仍低于传统的基于帧的解决方案。造成这种性能差距的主要原因包括：事件传感器的空间分辨率较低；缺乏大规模的训练数据集；以及缺乏成熟的、适用于事件处理的深度学习架构。本研究旨在解决这些问题，特别是在基于事件的目标检测任务背景下，以提升事件相机在该领域的应用性能。
*   **⭐ 主要发现**: 尽管提供的摘要并未完全展开论文的具体方法和实验结果，但其明确指出本研究旨在解决基于事件的目标检测任务中存在的关键挑战：即事件传感器空间分辨率低、缺乏大规模训练数据集以及缺乏成熟的深度学习架构。因此，可以推断本论文的核心贡献将围绕以下方面展开：
    *   **创新方法/架构：** 论文很可能提出一种新的深度学习架构或处理方法，能够有效利用1百万像素事件相机的数据，克服传统基于帧方法的局限性。
    *   **数据处理/数据集：** 为解决数据集缺乏的问题，研究可能引入新的数据处理技术或构建新的大规模数据集，以支持基于事件的目标检测模型的训练。
    *   **性能提升：** 预计通过所提出的方法，在目标检测任务上实现性能的显著提升，尤其是在高运动、极端光照等传统相机难以应对的场景下，展示事件相机的独特优势。
    *   **潜在影响：** 本研究的成果有望推动事件相机在自动驾驶、机器人视觉、监控等对实时性、鲁棒性要求高的应用领域的进一步发展，为未来基于事件的视觉系统奠定基础。

---
### [[Real-time Classification from Short Event-Camera Streams using Input-filtering Neural ODEs]](http://arxiv.org/abs/2004.03156v1)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2020-04-07

*   **👥 作者**: Giorgio Giannone, Asha Anoosheh, Alessio Quaglino, Pierluca D'Oro, Marco Gallieri, Jonathan Masci
*   **🎯 研究目的**: 事件相机作为一种受人类视觉系统启发的新型高效传感器，能生成异步的、像素级的事件数据流。然而，目前从这类数据中学习通常需要大量的预处理和将事件集成到图像中，这不仅需要缓冲可能很长的序列，还会限制推理系统的响应时间。本研究旨在解决这一问题，提出一种直接利用DVS相机产生的原始事件流（即强度变化及其空间坐标序列）进行实时分类的方法。其核心目标是开发一种新型的异步类RNN架构——输入过滤神经ODE（INODE），以避免传统方法的效率低下和响应延迟，从而实现从短事件相机流中进行高效的实时分类。
*   **⭐ 主要发现**: 本论文的核心贡献是引入了输入过滤神经ODE（INODE）模型，这是一种新颖的、受动力系统和滤波理论启发的异步类RNN架构，它是神经ODE（NODE）的扩展，允许连续地接收输入信号。与传统方法不同，INODE能够直接处理DVS相机产生的原始事件流，无需进行繁重的预处理或将事件集成到图像中。这一创新使得模型能够从短事件相机流中实现实时分类，显著减少了对长序列缓冲的需求，并提升了推理系统的响应速度。通过直接利用事件数据，INODE克服了现有方法在处理异步事件数据时的效率瓶颈和实时性限制，为事件相机数据的实时应用开辟了新的途径。

---
### [[Exploration of Reinforcement Learning for Event Camera using Car-like Robots]](http://arxiv.org/abs/2004.00801v1)
**📅 发布日期**: 2020-04-02

*   **👥 作者**: Riku Arakawa, Shintaro Shiba
*   **🎯 研究目的**: 现有基于视觉的机器人强化学习应用依赖于传统相机，其固有的高延迟限制了机器人控制的速度。本文旨在解决这一问题，首次探索将低延迟的事件相机与强化学习相结合，以实现显著更快的机器人控制。核心目标是验证事件相机在强化学习中的应用潜力，并展示其在快速响应任务中的优势。
*   **⭐ 主要发现**: 本文首次展示了强化学习在配备事件相机的机器人上的应用。为了有效处理事件相机产生的事件流数据以进行强化学习，研究人员引入了一种“类图像特征”表示方法。实验验证了在模拟器中训练智能体的可行性，并在“快速避撞”和“障碍物跟踪”两项任务中取得了成功。更重要的是，研究团队将模拟器中训练的智能体成功迁移到现实世界的机器人上，实现了对随机抛掷物体的快速有效避障。这些发现证明了事件相机在强化学习应用中的巨大潜力，预示着未来机器人能够实现比现有视觉系统更低延迟、更快速的控制和响应能力，为高速、动态环境下的机器人自主导航和操作开辟了新的研究方向。

---
### [[Learning to Exploit Multiple Vision Modalities by Using Grafted Networks]](http://arxiv.org/abs/2003.10959v3)
**📅 发布日期**: 2020-03-24

*   **👥 作者**: Yuhuang Hu, Tobi Delbruck, Shih-Chii Liu
*   **🎯 研究目的**: 新型视觉传感器（如热成像、高光谱、偏振和事件相机）能够提供传统强度相机无法获取的独特信息。然而，将这些传感器与当前强大的深度神经网络结合使用面临一个主要障碍：缺乏大规模的标注训练数据集。本文旨在解决这一数据稀缺性问题，提出一种有效的方法，使得深度学习模型能够利用新型视觉模态的数据，从而充分发挥这些传感器的潜力，而无需为每种新模态从头开始收集和标注大量数据。
*   **⭐ 主要发现**: 本文的核心贡献是提出了网络嫁接算法（Network Grafting Algorithm, NGA）。NGA允许将由非常规视觉输入驱动的新型网络前端，替换预训练深度网络中处理强度图像的前端。其创新之处在于，它采用自监督训练方式，仅利用同步记录的强度帧和新型传感器数据，来最大化预训练网络与嫁接网络之间的特征相似性。这种方法有效克服了新型传感器数据标注稀缺的挑战，通过知识迁移的方式，使得模型能够从强度图像的丰富标注数据中学习到的特征表示，泛化到新的视觉模态。实验结果表明，经过NGA增强的嫁接网络在平均精度（AP50）方面达到了具有竞争力的表现，证明了该方法在无需大量标注数据的情况下，也能有效利用多模态视觉信息的能力，为未来多模态感知系统的开发提供了新的途径。

---
### [Event-based Asynchronous Sparse Convolutional Networks](http://arxiv.org/abs/2003.09148v2)
**📅 发布日期**: 2020-03-20

*   **👥 作者**: Nico Messikommer, Daniel Gehrig, Antonio Loquercio, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机是一种仿生传感器，能够以异步和稀疏的“事件”形式响应像素亮度变化。当前，模式识别算法（特别是基于学习的方法）在处理事件相机数据时，通常将这些异步事件转换为同步、密集的图像式表示，然后应用为标准相机开发的传统机器学习方法。然而，这种转换方式牺牲了事件数据固有的空间和时间稀疏性，导致更高的计算复杂度和延迟。本研究旨在解决这一问题，提出一个通用框架，将训练在同步图像式事件表示上的模型转换为异步模型，从而直接利用事件数据固有的异步和稀疏特性，以降低计算成本和延迟。
*   **⭐ 主要发现**: 论文的核心贡献在于提出了一个通用的框架，能够将那些在同步、图像式事件表示上训练的现有模型，转换为能够直接处理异步事件数据的模型。这一转换过程确保了模型输出的一致性，同时关键性地利用了事件数据固有的异步和稀疏特性。这意味着，该方法避免了传统方法中将稀疏事件数据强制转换为密集帧所带来的计算开销和延迟，从而实现了更高效、更低延迟的事件数据处理。通过直接利用事件数据的原始特性，该工作为事件相机在实时应用中的模式识别和计算机视觉任务开辟了新的途径，有望显著提升系统性能和资源效率。
### [[Spike-FlowNet: Event-based Optical Flow Estimation with Energy-Efficient Hybrid Neural Networks]](http://arxiv.org/abs/2003.06696v3)
**📅 发布日期**: 2020-03-14

*   **👥 作者**: Chankyu Lee, Adarsh Kumar Kosta, Alex Zihao Zhu, Kenneth Chaney, Kostas Daniilidis, Kaushik Roy
*   **🎯 研究目的**: 事件相机在高速运动检测和弱光环境导航等任务中展现出巨大潜力，因其高时间分辨率、高动态范围和低功耗而优于传统帧基相机。然而，传统的计算机视觉方法以及深度模拟神经网络（ANNs）难以有效处理事件相机输出的异步和离散特性。尽管脉冲神经网络（SNNs）是处理事件相机数据的理想范式，但深度SNNs却面临“脉冲消失现象”导致的性能下降问题。本研究旨在克服这些挑战，提出一种新型神经网络架构，以高效地利用事件相机数据进行光流估计。
*   **⭐ 主要发现**: 本文提出了Spike-FlowNet，一种深度混合神经网络架构，其核心创新在于巧妙地整合了脉冲神经网络（SNNs）和模拟神经网络（ANNs）。通过这种混合设计，Spike-FlowNet能够有效处理事件相机的异步和离散数据流，同时成功克服了深度SNNs中“脉冲消失现象”导致的性能瓶颈。这一方法不仅实现了基于事件相机数据的高效光流估计，而且提供了能效更高的解决方案，为利用事件相机进行高级计算机视觉任务开辟了新的途径。

---
### [[Event-Based Angular Velocity Regression with Spiking Networks]](http://arxiv.org/abs/2003.02790v1)
**📅 发布日期**: 2020-03-05

*   **👥 作者**: Mathias Gehrig, Sumit Bam Shrestha, Daniel Mouritzen, Davide Scaramuzza
*   **🎯 研究目的**: 本研究旨在探索脉冲神经网络（SNNs）在处理事件相机数据方面的潜力，特别是在角速度回归任务上的应用。尽管SNNs具有生物启发性、能直接处理事件数据、功耗极低等优势，且与神经形态硬件高度兼容，但它们尚未像传统人工神经网络那样普及，部分原因在于其独特的输入格式和应用挑战。本研究的目的是克服这些挑战，展示SNNs如何有效利用事件数据，实现高效、低功耗的角速度估计，从而推动SNNs在实时、资源受限系统中的实际应用。
*   **⭐ 主要发现**: 本论文的核心贡献在于提出了一个基于脉冲神经网络（SNNs）的框架，用于直接从事件相机数据中回归角速度。研究克服了SNNs在实际应用中的挑战，设计并实现了一种能够高效处理异步事件流的SNN模型。尽管摘要未提供具体实验结果，但根据研究目的和SNNs的固有优势，该工作预计展示了SNN模型在处理事件数据时的准确性和效率，特别是在功耗和延迟方面展现出显著优势，使其非常适合部署在低功耗的神经形态硬件上。这为SNNs在机器人、自动驾驶等领域中利用事件相机进行实时感知和控制提供了新的途径，并证明了SNNs在特定任务上超越传统人工神经网络的潜力。

---
### [[Matching Neuromorphic Events and Color Images via Adversarial Learning]](http://arxiv.org/abs/2003.00636v1)
<!-- 2020-03-02 -->
**📅 发布日期**: 2020-03-02

*   **👥 作者**: Fang Xu, Shijie Lin, Wen Yang, Lei Yu, Dengxin Dai, Gui-song Xia
*   **🎯 研究目的**: 事件相机因其高动态范围、低延迟、低功耗和低内存使用等特性，能够捕捉场景的动态变化和几乎“连续”的运动，是对传统帧相机的重要补充。然而，与能反映场景完整外观的帧相机不同，事件相机舍弃了物体的纹理和颜色等详细特征。为了充分利用这两种模态的优势，将事件相机与帧相机结合起来执行各种机器视觉任务变得至关重要。在此背景下，神经形态事件与彩色图像之间的跨模态匹配扮演着核心角色。本文旨在解决这一关键问题，并首次提出了基于事件的图像检索（Event-Based Image Retrieval, EBIR）问题。
*   **⭐ 主要发现**: 本文的核心贡献在于首次提出了“基于事件的图像检索（Event-Based Image Retrieval, EBIR）”这一新问题。该研究旨在探索神经形态事件与彩色图像之间的跨模态匹配，以充分利用事件相机在动态捕捉方面的优势与帧相机在提供详细外观信息方面的优势。尽管摘要片段未能详细展开论文在对抗学习方法、具体实验设计、实验结果、理论突破以及对领域潜在影响方面的具体发现，但提出EBIR问题本身就为结合两种视觉模态、解决跨模态数据检索提供了新的研究方向和挑战。

---
### [[Inceptive Event Time-Surfaces for Object Classification Using Neuromorphic Cameras]](http://arxiv.org/abs/2002.11656v1)
**📅 发布日期**: 2020-02-26

*   **👥 作者**: R Wes Baldwin, Mohammed Almatrafi, Jason R Kaufman, Vijayan Asari, Keigo Hirakawa
*   **🎯 研究目的**: 在神经形态相机数据处理领域，对象分类是一个具有挑战性的问题。传统的时空表面（time-surfaces）方法存在局限性，例如对噪声的鲁棒性不足、空间一致性差以及对运动边缘的时间定位不精确。本研究旨在提出一种名为“初始事件时空表面”（Inceptive Event Time-Surfaces, IETS）的新型方法，以有效处理神经形态相机数据中的高层对象，并克服现有方法的不足。最终目标是利用IETS提高基于事件相机数据的对象分类性能。
*   **⭐ 主要发现**: 论文的核心贡献是提出了“初始事件时空表面”（IETS）这一新颖方法。IETS通过融合低层降维方法，为神经形态相机数据中的高层对象识别提供了一种有效途径。与传统时空表面方法相比，IETS显著提升了对噪声的鲁棒性，增强了空间一致性，并改进了（运动）边缘的时间定位能力。研究表明，将IETS与迁移学习（transfer learning）相结合，能够在利用事件相机数据进行对象分类的挑战性问题上，实现超越现有最佳水平（state-of-the-art）的性能。这表明IETS为神经形态相机数据的高效处理和高级视觉任务（如对象分类）提供了新的范式和显著的性能提升。

---
### [[大规模事件相机车载检测数据集]](http://arxiv.org/abs/2001.08499v3)
**📅 发布日期**: 2020-01-23

*   **👥 作者**: Pierre de Tournemire, Davide Nitti, Etienne Perot, Davide Migliore, Amos Sironi
*   **🎯 研究目的**: 事件相机作为一种新型传感器，在自动驾驶等领域展现出巨大潜力，但其应用和算法开发受限于缺乏大规模、高质量的标注数据集。现有数据集通常规模较小或场景单一，难以支撑复杂环境下的目标检测等任务。本研究旨在填补这一空白，构建并发布首个针对车载场景的大规模事件相机检测数据集，以推动事件视觉领域在目标检测、分类等关键任务上的发展。
*   **⭐ 主要发现**: 本文的核心贡献是发布了首个大规模事件相机车载检测数据集。该数据集具有以下显著特点和潜在影响：
    *   **规模庞大**: 包含超过39小时的汽车驾驶记录，数据量远超现有同类数据集。
    *   **传感器信息**: 数据采集自304x240 ATIS事件相机。
    *   **场景多样性**: 涵盖了城市、高速公路、郊区和乡村等开放道路场景，以及不同的天气和光照条件，极大地增加了数据的复杂性和真实性。
    *   **高质量标注**: 对记录中的汽车和行人进行了手动边界框标注，标注频率在1到4Hz之间，总计超过255,000个标签。
    *   **推动领域发展**: 这一大规模标注数据集的可用性，预计将极大地促进事件视觉领域在目标检测、分类等任务上的重大进展，并对光流、运动结构恢复等其他任务产生积极影响，为自动驾驶等应用提供关键数据支持。

---
### [[Exploiting Event Cameras for Spatio-Temporal Prediction of Fast-Changing Trajectories]](http://arxiv.org/abs/2001.01248v2)
<!-- 论文发布日期，格式：YYYY-MM-DD -->
**📅 发布日期**: 2020-01-05

*   **👥 作者**: Marco Monforte, Ander Arriandiaga, Arren Glover, Chiara Bartolozzi
*   **🎯 研究目的**: 本文旨在改进机器人与快速移动目标（例如捕捉弹跳球）的交互能力，通过准确预测其轨迹。研究指出，对于意外的、高度非线性的轨迹，传统的基于回归的拟合方法难以有效预测，因此需要探索更先进的机器学习方法和感知技术来解决这一挑战。
*   **⭐ 主要发现**: 为解决非线性轨迹预测难题，论文应用了基于长短期记忆（LSTM）架构的先进机器学习方法。此外，研究强调了事件相机在感知快速移动目标方面的独特优势，因其能根据空间变化异步生成数据，而非传统相机的固定时间间隔输出。核心创新在于探索了如何将LSTM模型适应于事件相机数据，并特别研究了利用异步采样数据进行轨迹预测所带来的显著益处，为机器人处理高速、复杂运动目标提供了新的解决方案。

---
### [EvAn: Neuromorphic Event-based Anomaly Detection](http://arxiv.org/abs/1911.09722v2)
<!-- 2019-11-21 -->
**📅 发布日期**: 2019-11-21

*   **👥 作者**: Lakshmi Annamalai, Anirban Chakraborty, Chetan Singh Thakur
*   **🎯 研究目的**: 传统相机在低功耗、高动态范围和运动模糊方面存在局限性。事件相机作为一种仿生新型传感器，通过异步记录光照变化事件，克服了这些缺点，并能生成稀疏数据结构，非常适合运动分析任务。本研究旨在首次将事件相机的这些优势应用于关键的视觉应用——视频异常检测，以解决传统相机在复杂场景下（如快速运动、光照变化）进行异常检测的挑战。
*   **⭐ 主要发现**: 本文首次在事件数据分析领域利用事件相机进行视频异常检测。研究提出了一种基于双判别器条件生成对抗网络（GAN）的方法，用于在事件域中建模运动动力学。通过利用事件相机仅编码相对运动而非静态背景的特性，该方法能够处理稀疏数据，从而在低功耗、高动态范围和无运动模糊的条件下实现高效的异常检测。这为事件相机在监控、自动驾驶等需要实时、鲁棒异常检测的应用中开辟了新的可能性。

---

### [Event-based Vision: A Survey](http://arxiv.org/abs/1904.08405v3)
<!-- 2019-04-17 -->
**📅 发布日期**: 2019-04-17

*   **👥 作者**: Guillermo Gallego, Tobi Delbruck, Garrick Orchard, Chiara Bartolozzi, Brian Taba, Andrea Censi, Stefan Leutenegger, Andrew Davison, Joerg Conradt, Kostas Daniilidis, Davide Scaramuzza
*   **🎯 研究目的**: 传统帧相机以固定帧率捕获图像，在高速运动、高动态范围和低功耗场景下存在局限性。事件相机作为一种仿生传感器，通过异步测量像素亮度变化并输出事件流，具有微秒级时间分辨率、超高动态范围、低功耗和无运动模糊等显著优势。本研究旨在对事件相机及其在机器人和计算机视觉领域的应用进行全面综述，识别其潜力以及当前处理其独特数据流所面临的挑战，并为未来的研究方向提供指导。
*   **⭐ 主要发现**: 本文对事件视觉领域进行了首次全面综述，详细阐述了事件相机的工作原理、独特属性（如高时间分辨率、高动态范围、低功耗、无运动模糊）及其与传统相机的区别。文章系统地总结了现有处理事件数据的方法，并讨论了事件相机在机器人和计算机视觉中，尤其是在低延迟、高速和高动态范围等挑战性场景下的巨大应用潜力。这篇综述为研究人员和工程师提供了理解事件视觉技术现状、挑战和未来发展方向的宝贵资源。

---

### [Focus Is All You Need: Loss Functions For Event-based Vision](http://arxiv.org/abs/1904.07235v1)
<!-- 2019-04-15 -->
**📅 发布日期**: 2019-04-15

*   **👥 作者**: Guillermo Gallego, Mathias Gehrig, Davide Scaramuzza
*   **🎯 研究目的**: 事件相机作为一种新型视觉传感器，能够异步输出像素级别的亮度变化事件，具有高时间分辨率、超高动态范围和无运动模糊等优势。为了充分利用这些传感器的潜力，运动补偿方法至关重要。本研究旨在为事件相机运动补偿方法中的事件对齐分析，提出并分类一系列客观函数（即“焦点损失函数”），从而将成熟的计算机视觉工具引入事件相机领域，并评估它们的准确性和运行时性能。
*   **⭐ 主要发现**: 本文提出了一个包含22种客观函数的集合和分类，用于分析事件相机运动补偿中的事件对齐。这些函数被称为“焦点损失函数”，因为它们与传统形状-从-焦点（shape-from-focus）应用中使用的函数有很强的关联。通过引入这些损失函数，研究成功地将传统计算机视觉中成熟的工具引入到事件相机的数据处理中。实验结果比较了这些损失函数的准确性和运行时性能，为事件相机运动补偿算法的设计和优化提供了重要的理论基础和实践指导，有助于解锁事件传感器在各种应用中的潜力。

---

### [Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling](http://arxiv.org/abs/1904.03375v1)
<!-- 2019-04-06 -->
**📅 发布日期**: 2019-04-06

*   **👥 作者**: Jiancheng Yang, Qiang Zhang, Bingbing Ni, Linguo Li, Jinxian Liu, Mengdie Zhou, Qi Tian
*   **🎯 研究目的**: 随着3D传感器的普及，几何深度学习变得越来越重要。点云作为一种重要的3D数据表示，其处理面临挑战，特别是如何有效地建模其无序性和可变大小的特性。受自然语言处理领域自注意力机制最新进展的启发，本研究旨在将自注意力Transformer引入点云处理，并提出一种端到端可学习且与任务无关的点云子集采样方法，以克服现有启发式采样方法的局限性。
*   **⭐ 主要发现**: 本文提出了点注意力Transformer（Point Attention Transformers, PATs），通过使用参数高效的组混洗注意力（Group Shuffle Attention, GSA）替代成本较高的多头注意力，成功地将自注意力机制应用于点云处理。PATs能够处理大小可变的输入，并被证明具有排列等变性。此外，研究首次提出了一种端到端可学习且与任务无关的采样操作——Gumbel子集采样（Gumbel Subset Sampling, GSS），用于选择具有代表性的输入点子集，克服了以往依赖启发式（如最远点采样）的局限性。这些创新显著提升了点云建模的效率和灵活性，为几何深度学习带来了新的范式。

---

### [EventNet: Asynchronous Recursive Event Processing](http://arxiv.org/abs/1812.07045v2)
<!-- 2018-12-07 -->
**📅 发布日期**: 2018-12-07

*   **👥 作者**: Yusuke Sekikawa, Kosuke Hara, Hideo Saito
*   **🎯 研究目的**: 事件相机作为一种仿生视觉传感器，通过异步报告像素强度变化来模拟视网膜，而非以固定间隔输出图像。这种新范式带来了稀疏且非冗余的数据表示优势。然而，现有的大多数人工神经网络架构（如CNN）需要密集的同步输入数据，无法有效利用事件数据的稀疏性。本研究旨在设计一种新型神经网络EventNet，以实现对异步事件流的实时、递归和事件级处理，从而充分利用事件数据的固有优势。
*   **⭐ 主要发现**: 本文提出了EventNet，一个专为实时处理异步事件流而设计的神经网络。EventNet通过一种新颖的时间编码方案，以递归和事件级的方式建模输出对数万个因果事件的依赖关系。与传统CNN需要密集同步输入不同，EventNet能够直接处理稀疏的事件数据，从而充分利用事件相机在数据表示上的优势。这一创新使得EventNet能够高效地处理事件流，为事件相机在需要低延迟、高效率处理的实时应用中提供了强大的深度学习解决方案。

---

### [Event-based Vision meets Deep Learning on Steering Prediction for Self-driving Cars](http://arxiv.org/abs/1804.01310v1)
<!-- 2018-04-04 -->
**📅 发布日期**: 2018-04-04

*   **👥 作者**: Ana I. Maqueda, Antonio Loquercio, Guillermo Gallego, Narciso Garcia, Davide Scaramuzza
*   **🎯 研究目的**: 自动驾驶汽车的转向预测是一项具有挑战性的运动估计任务，传统相机在恶劣光照条件和高速运动下表现不佳。事件相机作为一种仿生视觉传感器，能够自然地捕捉场景动态并过滤冗余信息，有望克服传统相机的局限性。本研究旨在探索事件相机与深度学习结合的潜力，以实现鲁棒的车辆转向角度预测，尤其是在传统相机失效的挑战性场景下。
*   **⭐ 主要发现**: 本文提出了一种深度神经网络方法，成功地将事件相机应用于自动驾驶汽车的转向角度预测任务。研究将最先进的卷积网络架构适配到事件传感器的输出，并在一个大型公开事件相机数据集（约1000公里）上进行了广泛的性能评估。结果表明，事件相机即使在传统相机失效的挑战性光照条件和快速运动情况下，也能实现鲁棒的转向预测。论文通过定性和定量分析，解释了事件相机在此类任务中表现优异的原因，为自动驾驶领域在复杂环境下的感知和决策提供了新的解决方案。

---

### [NullHop: A Flexible Convolutional Neural Network Accelerator Based on Sparse Representations of Feature Maps](http://arxiv.org/abs/1706.01406v2)
<!-- 2017-06-05 -->
**📅 发布日期**: 2017-06-05

*   **👥 作者**: Alessandro Aimar, Hesham Mostafa, Enrico Calabrese, Antonio Rios-Navarro, Ricardo Tapiador-Morales, Iulia-Alexandra Lungu, Moritz B. Milde, Federico Corradi, Alejandro Linares-Barranco, Shih-Chii Liu, Tobi Delbruck
*   **🎯 研究目的**: 卷积神经网络（CNN）在视觉处理任务中占据主导地位，但其在GPU上的部署通常功耗较高（低于10 GOp/s/W），不适用于低功耗和低延迟的应用场景。本研究旨在设计一种灵活高效的CNN加速器架构，通过利用CNN中神经元激活的稀疏性来加速计算并减少内存需求，从而实现适用于低功耗和低延迟场景的最先进CNN模型。
*   **⭐ 主要发现**: 本文提出了一种名为NullHop的灵活高效CNN加速器架构。NullHop通过利用CNN中神经元激活的稀疏性来显著加速计算并减少内存需求。其灵活的架构设计允许在1x1到7x7的各种卷积核尺寸下实现计算资源的高利用率。NullHop能够处理多达128个输入和128个输出特征图，并在各种CNN模型上表现出卓越的性能。与GPU相比，NullHop在功耗效率方面有显著提升，使其成为低功耗、低延迟应用场景中部署最先进CNN的理想选择，为边缘计算和嵌入式AI设备提供了强大的硬件支持。

---

---

## 生成说明
- 本报告由AI模型自动生成，摘要内容仅供参考。
- 如有错误或遗漏，请以原始论文为准。
